

<!DOCTYPE html>
<!-- source: docs/source/_modules/mlflow/openai/autolog -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.openai.autolog</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/_modules/mlflow/openai/autolog.html">
  
  
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  

  

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    
  
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=AW-16857946923"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'AW-16857946923');
  </script>
  <!-- Eng gtag -->

  

  
  <meta name="docsearch:docusaurus_tag" content="docs-default-current" data-rh="true">
  <meta name="docusaurus_tag" content="docs-default-current" data-rh="true">

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../search.html"/>
    <link rel="top" title="MLflow 3.2.0 documentation" href="../../../index.html"/>
        <link rel="up" title="Module code" href="../../index.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../_static/documentation_options.js"></script>
<script type="text/javascript" src="../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../_static/tabs.js"></script>
<script type="text/javascript" src="../../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../../../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <div class="header-container">
  <style scoped>
    .header-container {
      display: flex;
      flex-direction: row;
      align-items: center;
      justify-content: space-between;
      padding: 8px 16px;

      background-color: #fff;
      box-shadow: 0 1px 2px 0 #0000001a;
    }

    .logo-container {
      display: flex;
      gap: 12px;
      flex-direction: row;
      white-space: nowrap;
      align-items: center;
      justify-content: center;
    }

    a:hover {
      text-decoration: none;
      color: #0194e2;
    }
  </style>
  <div class="logo-container">
    <i
      data-toggle="wy-nav-top"
      class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"
    ></i>
    <a href="../../../index.html" class="wy-nav-top-logo">
      <img
        src="../../../_static/MLflow-logo-final-black.png"
        alt="MLflow"
      />
    </a>
    <a
      style="overflow: hidden; text-overflow: ellipsis"
      class="header-link"
      href="/docs/latest"
      >Main Docs</a
    >
    <span style="overflow: hidden; text-overflow: ellipsis" class="header-link"
      >API Documentation</span
    >
  </div>
  <span class="header-link">3.2.0</span>
</div>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../index.html">Home</a>
    

    
      

      
        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auth/python-api.html">MLflow Authentication Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auth/rest-api.html">MLflow Authentication REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../index.html">Module code</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.openai.autolog</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/_modules/mlflow/openai/autolog" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <h1>Source code for mlflow.openai.autolog</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">importlib.metadata</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">AsyncIterator</span><span class="p">,</span> <span class="n">Iterator</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">packaging.version</span><span class="w"> </span><span class="kn">import</span> <span class="n">Version</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpanType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.span</span><span class="w"> </span><span class="kn">import</span> <span class="n">LiveSpan</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.span_event</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpanEvent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.span_status</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpanStatusCode</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="n">MlflowException</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.openai.constant</span><span class="w"> </span><span class="kn">import</span> <span class="n">FLAVOR_NAME</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.openai.utils.chat_schema</span><span class="w"> </span><span class="kn">import</span> <span class="n">set_span_chat_attributes</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracing.constant</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">STREAM_CHUNK_EVENT_NAME_FORMAT</span><span class="p">,</span>
    <span class="n">STREAM_CHUNK_EVENT_VALUE_KEY</span><span class="p">,</span>
    <span class="n">SpanAttributeKey</span><span class="p">,</span>
    <span class="n">TokenUsageKey</span><span class="p">,</span>
    <span class="n">TraceMetadataKey</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracing.fluent</span><span class="w"> </span><span class="kn">import</span> <span class="n">start_span_no_context</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracing.trace_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">InMemoryTraceManager</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracing.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">TraceJSONEncoder</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.annotations</span><span class="w"> </span><span class="kn">import</span> <span class="n">experimental</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.autologging_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">autologging_integration</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.autologging_utils.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoLoggingConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.autologging_utils.safety</span><span class="w"> </span><span class="kn">import</span> <span class="n">safe_patch</span>

<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="autolog"><a class="viewcode-back" href="../../../python_api/mlflow.openai.html#mlflow.openai.autolog">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;2.14.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">autolog</span><span class="p">(</span>
    <span class="n">disable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">disable_for_unsupported_versions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">silent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log_traces</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enables (or disables) and configures autologging from OpenAI to MLflow.</span>
<span class="sd">    Raises :py:class:`MlflowException &lt;mlflow.exceptions.MlflowException&gt;`</span>
<span class="sd">    if the OpenAI version &lt; 1.0.</span>

<span class="sd">    Args:</span>
<span class="sd">        disable: If ``True``, disables the OpenAI autologging integration. If ``False``,</span>
<span class="sd">            enables the OpenAI autologging integration.</span>
<span class="sd">        exclusive: If ``True``, autologged content is not logged to user-created fluent runs.</span>
<span class="sd">            If ``False``, autologged content is logged to the active fluent run,</span>
<span class="sd">            which may be user-created.</span>
<span class="sd">        disable_for_unsupported_versions: If ``True``, disable autologging for versions of</span>
<span class="sd">            OpenAI that have not been tested against this version of the MLflow</span>
<span class="sd">            client or are incompatible.</span>
<span class="sd">        silent: If ``True``, suppress all event logs and warnings from MLflow during OpenAI</span>
<span class="sd">            autologging. If ``False``, show all events and warnings during OpenAI</span>
<span class="sd">            autologging.</span>
<span class="sd">        log_traces: If ``True``, traces are logged for OpenAI models. If ``False``, no traces are</span>
<span class="sd">            collected during inference. Default to ``True``.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">importlib</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">version</span><span class="p">(</span><span class="s2">&quot;openai&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">major</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span><span class="s2">&quot;OpenAI autologging is only supported for openai &gt;= 1.0.0&quot;</span><span class="p">)</span>

    <span class="c1"># This needs to be called before doing any safe-patching (otherwise safe-patch will be no-op).</span>
    <span class="c1"># TODO: since this implementation is inconsistent, explore a universal way to solve the issue.</span>
    <span class="n">_autolog</span><span class="p">(</span>
        <span class="n">disable</span><span class="o">=</span><span class="n">disable</span><span class="p">,</span>
        <span class="n">exclusive</span><span class="o">=</span><span class="n">exclusive</span><span class="p">,</span>
        <span class="n">disable_for_unsupported_versions</span><span class="o">=</span><span class="n">disable_for_unsupported_versions</span><span class="p">,</span>
        <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">,</span>
        <span class="n">log_traces</span><span class="o">=</span><span class="n">log_traces</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Tracing OpenAI Agent SDK. This has to be done outside the function annotated with</span>
    <span class="c1"># `@autologging_integration` because the function is not executed when `disable=True`.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.openai._agent_tracer</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">add_mlflow_trace_processor</span><span class="p">,</span>
            <span class="n">remove_mlflow_trace_processor</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">log_traces</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">disable</span><span class="p">:</span>
            <span class="n">add_mlflow_trace_processor</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">remove_mlflow_trace_processor</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">pass</span></div>


<span class="c1"># This is required by mlflow.autolog()</span>
<span class="n">autolog</span><span class="o">.</span><span class="n">integration_name</span> <span class="o">=</span> <span class="n">FLAVOR_NAME</span>


<span class="c1"># NB: The @autologging_integration annotation must be applied here, and the callback injection</span>
<span class="c1"># needs to happen outside the annotated function. This is because the annotated function is NOT</span>
<span class="c1"># executed when disable=True is passed. This prevents us from removing our callback and patching</span>
<span class="c1"># when autologging is turned off.</span>
<span class="nd">@autologging_integration</span><span class="p">(</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_autolog</span><span class="p">(</span>
    <span class="n">disable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">disable_for_unsupported_versions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">silent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log_traces</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.chat.completions</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncCompletions</span> <span class="k">as</span> <span class="n">AsyncChatCompletions</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.chat.completions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Completions</span> <span class="k">as</span> <span class="n">ChatCompletions</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.completions</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncCompletions</span><span class="p">,</span> <span class="n">Completions</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.embeddings</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncEmbeddings</span><span class="p">,</span> <span class="n">Embeddings</span>

    <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="p">(</span><span class="n">ChatCompletions</span><span class="p">,</span> <span class="n">Completions</span><span class="p">,</span> <span class="n">Embeddings</span><span class="p">):</span>
        <span class="n">safe_patch</span><span class="p">(</span><span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">task</span><span class="p">,</span> <span class="s2">&quot;create&quot;</span><span class="p">,</span> <span class="n">patched_call</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="p">(</span><span class="n">AsyncChatCompletions</span><span class="p">,</span> <span class="n">AsyncCompletions</span><span class="p">,</span> <span class="n">AsyncEmbeddings</span><span class="p">):</span>
        <span class="n">safe_patch</span><span class="p">(</span><span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">task</span><span class="p">,</span> <span class="s2">&quot;create&quot;</span><span class="p">,</span> <span class="n">async_patched_call</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.beta.chat.completions</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncCompletions</span><span class="p">,</span> <span class="n">Completions</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">safe_patch</span><span class="p">(</span><span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">Completions</span><span class="p">,</span> <span class="s2">&quot;parse&quot;</span><span class="p">,</span> <span class="n">patched_call</span><span class="p">)</span>
        <span class="n">safe_patch</span><span class="p">(</span><span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">AsyncCompletions</span><span class="p">,</span> <span class="s2">&quot;parse&quot;</span><span class="p">,</span> <span class="n">async_patched_call</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.responses</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncResponses</span><span class="p">,</span> <span class="n">Responses</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">safe_patch</span><span class="p">(</span><span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">Responses</span><span class="p">,</span> <span class="s2">&quot;create&quot;</span><span class="p">,</span> <span class="n">patched_call</span><span class="p">)</span>
        <span class="n">safe_patch</span><span class="p">(</span><span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">AsyncResponses</span><span class="p">,</span> <span class="s2">&quot;create&quot;</span><span class="p">,</span> <span class="n">async_patched_call</span><span class="p">)</span>

    <span class="c1"># Patch Swarm agent to generate traces</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">swarm</span><span class="w"> </span><span class="kn">import</span> <span class="n">Swarm</span>

        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Autologging for OpenAI Swarm is deprecated and will be removed in a future release. &quot;</span>
            <span class="s2">&quot;OpenAI Agent SDK is drop-in replacement for agent building and is supported by &quot;</span>
            <span class="s2">&quot;MLflow autologging. Please refer to the OpenAI Agent SDK documentation &quot;</span>
            <span class="s2">&quot;(https://github.com/openai/openai-agents-python) for more details.&quot;</span><span class="p">,</span>
            <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">safe_patch</span><span class="p">(</span>
            <span class="n">FLAVOR_NAME</span><span class="p">,</span>
            <span class="n">Swarm</span><span class="p">,</span>
            <span class="s2">&quot;get_chat_completion&quot;</span><span class="p">,</span>
            <span class="n">patched_agent_get_chat_completion</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">safe_patch</span><span class="p">(</span>
            <span class="n">FLAVOR_NAME</span><span class="p">,</span>
            <span class="n">Swarm</span><span class="p">,</span>
            <span class="s2">&quot;run&quot;</span><span class="p">,</span>
            <span class="n">patched_swarm_run</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">pass</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_get_span_type</span><span class="p">(</span><span class="n">task</span><span class="p">:</span> <span class="nb">type</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.chat.completions</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncCompletions</span> <span class="k">as</span> <span class="n">AsyncChatCompletions</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.chat.completions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Completions</span> <span class="k">as</span> <span class="n">ChatCompletions</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.completions</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncCompletions</span><span class="p">,</span> <span class="n">Completions</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.embeddings</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncEmbeddings</span><span class="p">,</span> <span class="n">Embeddings</span>

    <span class="n">span_type_mapping</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">ChatCompletions</span><span class="p">:</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">CHAT_MODEL</span><span class="p">,</span>
        <span class="n">AsyncChatCompletions</span><span class="p">:</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">CHAT_MODEL</span><span class="p">,</span>
        <span class="n">Completions</span><span class="p">:</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">LLM</span><span class="p">,</span>
        <span class="n">AsyncCompletions</span><span class="p">:</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">LLM</span><span class="p">,</span>
        <span class="n">Embeddings</span><span class="p">:</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">EMBEDDING</span><span class="p">,</span>
        <span class="n">AsyncEmbeddings</span><span class="p">:</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">EMBEDDING</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Only available in openai&gt;=1.40.0</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.beta.chat.completions</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">AsyncCompletions</span> <span class="k">as</span> <span class="n">BetaAsyncChatCompletions</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.beta.chat.completions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Completions</span> <span class="k">as</span> <span class="n">BetaChatCompletions</span>

        <span class="n">span_type_mapping</span><span class="p">[</span><span class="n">BetaChatCompletions</span><span class="p">]</span> <span class="o">=</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">CHAT_MODEL</span>
        <span class="n">span_type_mapping</span><span class="p">[</span><span class="n">BetaAsyncChatCompletions</span><span class="p">]</span> <span class="o">=</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">CHAT_MODEL</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Responses API only available in openai&gt;=1.66.0</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">openai.resources.responses</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncResponses</span><span class="p">,</span> <span class="n">Responses</span>

        <span class="n">span_type_mapping</span><span class="p">[</span><span class="n">Responses</span><span class="p">]</span> <span class="o">=</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">CHAT_MODEL</span>
        <span class="n">span_type_mapping</span><span class="p">[</span><span class="n">AsyncResponses</span><span class="p">]</span> <span class="o">=</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">CHAT_MODEL</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">return</span> <span class="n">span_type_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">SpanType</span><span class="o">.</span><span class="n">UNKNOWN</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_try_parse_raw_response</span><span class="p">(</span><span class="n">response</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    As documented at https://github.com/openai/openai-python/tree/52357cff50bee57ef442e94d78a0de38b4173fc2?tab=readme-ov-file#accessing-raw-response-data-eg-headers,</span>
<span class="sd">    a `LegacyAPIResponse` (https://github.com/openai/openai-python/blob/52357cff50bee57ef442e94d78a0de38b4173fc2/src/openai/_legacy_response.py#L45)</span>
<span class="sd">    object is returned when the `create` method is invoked with `with_raw_response`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">openai._legacy_response</span><span class="w"> </span><span class="kn">import</span> <span class="n">LegacyAPIResponse</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Failed to import `LegacyAPIResponse` from `openai._legacy_response`&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">LegacyAPIResponse</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># `parse` returns either a `pydantic.BaseModel` or a `openai.Stream` object</span>
            <span class="c1"># depending on whether the request has a `stream` parameter set to `True`.</span>
            <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">parse</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s2"> (type: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">response</span>


<span class="k">def</span><span class="w"> </span><span class="nf">patched_call</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">AutoLoggingConfig</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">flavor_name</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">openai</span><span class="o">.</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
    <span class="n">active_run</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">active_run</span><span class="p">()</span>
    <span class="n">run_id</span> <span class="o">=</span> <span class="n">active_run</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">run_id</span> <span class="k">if</span> <span class="n">active_run</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">log_traces</span><span class="p">:</span>
        <span class="n">span</span> <span class="o">=</span> <span class="n">_start_span</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">run_id</span><span class="p">)</span>

    <span class="c1"># Execute the original function</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">raw_result</span> <span class="o">=</span> <span class="n">original</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">log_traces</span><span class="p">:</span>
            <span class="n">_end_span_on_exception</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
        <span class="k">raise</span>

    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">log_traces</span><span class="p">:</span>
        <span class="n">_end_span_on_success</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">raw_result</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">raw_result</span>


<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">async_patched_call</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">AutoLoggingConfig</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">flavor_name</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">openai</span><span class="o">.</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
    <span class="n">active_run</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">active_run</span><span class="p">()</span>
    <span class="n">run_id</span> <span class="o">=</span> <span class="n">active_run</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">run_id</span> <span class="k">if</span> <span class="n">active_run</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">log_traces</span><span class="p">:</span>
        <span class="n">span</span> <span class="o">=</span> <span class="n">_start_span</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">run_id</span><span class="p">)</span>

    <span class="c1"># Execute the original function</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">raw_result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">original</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">log_traces</span><span class="p">:</span>
            <span class="n">_end_span_on_exception</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
        <span class="k">raise</span>

    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">log_traces</span><span class="p">:</span>
        <span class="n">_end_span_on_success</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">raw_result</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">raw_result</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_start_span</span><span class="p">(</span>
    <span class="n">instance</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">run_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">):</span>
    <span class="c1"># Record input parameters to attributes</span>
    <span class="n">attributes</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;messages&quot;</span><span class="p">,</span> <span class="s2">&quot;input&quot;</span><span class="p">)}</span>

    <span class="c1"># If there is an active span, create a child span under it, otherwise create a new trace</span>
    <span class="n">span</span> <span class="o">=</span> <span class="n">start_span_no_context</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">instance</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
        <span class="n">span_type</span><span class="o">=</span><span class="n">_get_span_type</span><span class="p">(</span><span class="n">instance</span><span class="o">.</span><span class="vm">__class__</span><span class="p">),</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
        <span class="n">attributes</span><span class="o">=</span><span class="n">attributes</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Associate run ID to the trace manually, because if a new run is created by</span>
    <span class="c1"># autologging, it is not set as the active run thus not automatically</span>
    <span class="c1"># associated with the trace.</span>
    <span class="k">if</span> <span class="n">run_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tm</span> <span class="o">=</span> <span class="n">InMemoryTraceManager</span><span class="p">()</span><span class="o">.</span><span class="n">get_instance</span><span class="p">()</span>
        <span class="n">tm</span><span class="o">.</span><span class="n">set_trace_metadata</span><span class="p">(</span><span class="n">span</span><span class="o">.</span><span class="n">trace_id</span><span class="p">,</span> <span class="n">TraceMetadataKey</span><span class="o">.</span><span class="n">SOURCE_RUN</span><span class="p">,</span> <span class="n">run_id</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">span</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_end_span_on_success</span><span class="p">(</span><span class="n">span</span><span class="p">:</span> <span class="n">LiveSpan</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">raw_result</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncStream</span><span class="p">,</span> <span class="n">Stream</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">_try_parse_raw_response</span><span class="p">(</span><span class="n">raw_result</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">Stream</span><span class="p">):</span>
        <span class="c1"># If the output is a stream, we add a hook to store the intermediate chunks</span>
        <span class="c1"># and then log the outputs as a single artifact when the stream ends</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">_stream_output_logging_hook</span><span class="p">(</span><span class="n">stream</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">stream</span><span class="p">):</span>
                <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_process_chunk</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span><span class="p">))</span>
                <span class="k">yield</span> <span class="n">chunk</span>
            <span class="n">_process_last_chunk</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

        <span class="n">result</span><span class="o">.</span><span class="n">_iterator</span> <span class="o">=</span> <span class="n">_stream_output_logging_hook</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">_iterator</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">AsyncStream</span><span class="p">):</span>

        <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_stream_output_logging_hook</span><span class="p">(</span><span class="n">stream</span><span class="p">:</span> <span class="n">AsyncIterator</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncIterator</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
                <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_process_chunk</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">),</span> <span class="n">chunk</span><span class="p">))</span>
                <span class="k">yield</span> <span class="n">chunk</span>
            <span class="n">_process_last_chunk</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

        <span class="n">result</span><span class="o">.</span><span class="n">_iterator</span> <span class="o">=</span> <span class="n">_stream_output_logging_hook</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">_iterator</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">set_span_chat_attributes</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
            <span class="n">span</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">result</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Encountered unexpected error when ending trace: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_process_last_chunk</span><span class="p">(</span><span class="n">span</span><span class="p">:</span> <span class="n">LiveSpan</span><span class="p">,</span> <span class="n">chunk</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">output</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">]):</span>
    <span class="k">if</span> <span class="n">_is_responses_final_event</span><span class="p">(</span><span class="n">chunk</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">response</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="c1"># For ChatCompletion, the usage info is stored in the last chunk and only when</span>
        <span class="c1"># `stream_options={&quot;include_usage&quot;: True}` is specified by the user.</span>
        <span class="k">if</span> <span class="n">usage</span> <span class="o">:=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="s2">&quot;usage&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">usage_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">TokenUsageKey</span><span class="o">.</span><span class="n">INPUT_TOKENS</span><span class="p">:</span> <span class="n">usage</span><span class="o">.</span><span class="n">prompt_tokens</span><span class="p">,</span>
                <span class="n">TokenUsageKey</span><span class="o">.</span><span class="n">OUTPUT_TOKENS</span><span class="p">:</span> <span class="n">usage</span><span class="o">.</span><span class="n">completion_tokens</span><span class="p">,</span>
                <span class="n">TokenUsageKey</span><span class="o">.</span><span class="n">TOTAL_TOKENS</span><span class="p">:</span> <span class="n">usage</span><span class="o">.</span><span class="n">total_tokens</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">span</span><span class="o">.</span><span class="n">set_attribute</span><span class="p">(</span><span class="n">SpanAttributeKey</span><span class="o">.</span><span class="n">CHAT_USAGE</span><span class="p">,</span> <span class="n">usage_dict</span><span class="p">)</span>

    <span class="n">_end_span_on_success</span><span class="p">(</span><span class="n">span</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_is_responses_final_event</span><span class="p">(</span><span class="n">chunk</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">openai.types.responses</span><span class="w"> </span><span class="kn">import</span> <span class="n">ResponseCompletedEvent</span>

        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">ResponseCompletedEvent</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_end_span_on_exception</span><span class="p">(</span><span class="n">span</span><span class="p">:</span> <span class="n">LiveSpan</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="ne">Exception</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">span</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="n">SpanEvent</span><span class="o">.</span><span class="n">from_exception</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
        <span class="n">span</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="n">status</span><span class="o">=</span><span class="n">SpanStatusCode</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">inner_e</span><span class="p">:</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Encountered unexpected error when ending trace: </span><span class="si">{</span><span class="n">inner_e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_process_chunk</span><span class="p">(</span><span class="n">span</span><span class="p">:</span> <span class="n">LiveSpan</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">chunk</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse the chunk and log it as a span event in the trace.&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai.types.chat.chat_completion_chunk</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatCompletionChunk</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">openai.types.completion</span><span class="w"> </span><span class="kn">import</span> <span class="n">Completion</span>

    <span class="c1"># `chunk.choices` can be empty: https://github.com/mlflow/mlflow/issues/13361</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">Completion</span><span class="p">)</span> <span class="ow">and</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">:</span>
        <span class="n">parsed</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">ChatCompletionChunk</span><span class="p">)</span> <span class="ow">and</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">:</span>
        <span class="n">choice</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">parsed</span> <span class="o">=</span> <span class="p">(</span><span class="n">choice</span><span class="o">.</span><span class="n">delta</span> <span class="ow">and</span> <span class="n">choice</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">parsed</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

    <span class="n">span</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span>
        <span class="n">SpanEvent</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">STREAM_CHUNK_EVENT_NAME_FORMAT</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">),</span>
            <span class="c1"># OpenTelemetry SpanEvent only support str-str key-value pairs for attributes</span>
            <span class="n">attributes</span><span class="o">=</span><span class="p">{</span><span class="n">STREAM_CHUNK_EVENT_VALUE_KEY</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">TraceJSONEncoder</span><span class="p">)},</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">parsed</span>


<span class="k">def</span><span class="w"> </span><span class="nf">patched_agent_get_chat_completion</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Patch the `get_chat_completion` method of the ChatCompletion object.</span>
<span class="sd">    OpenAI autolog already handles the raw completion request, but tracing</span>
<span class="sd">    the swarm&#39;s method is useful to track other parameters like agent name.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;agent&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Patch agent&#39;s functions to generate traces. Function calls only happen</span>
    <span class="c1"># after the first completion is generated because of the design of</span>
    <span class="c1"># function calling. Therefore, we can safely patch the tool functions here</span>
    <span class="c1"># within get_chat_completion() hook.</span>
    <span class="c1"># We cannot patch functions during the agent&#39;s initialization because the</span>
    <span class="c1"># agent&#39;s functions can be modified after the agent is created.</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">function_wrapper</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="k">if</span> <span class="s2">&quot;context_variables&quot;</span> <span class="ow">in</span> <span class="n">fn</span><span class="o">.</span><span class="vm">__code__</span><span class="o">.</span><span class="n">co_varnames</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                <span class="c1"># NB: Swarm uses `func.__code__.co_varnames` to inspect if the provided</span>
                <span class="c1"># tool function includes &#39;context_variables&#39; parameter in the signature</span>
                <span class="c1"># and ingest the global context variables if so. Wrapping the function</span>
                <span class="c1"># with mlflow.trace() will break this.</span>
                <span class="c1"># The co_varnames is determined based on the local variables of the</span>
                <span class="c1"># function, so we workaround this by declaring it here as a local variable.</span>
                <span class="n">context_variables</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;context_variables&quot;</span><span class="p">,</span> <span class="p">{})</span>  <span class="c1"># noqa: F841</span>
                <span class="k">return</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
                    <span class="n">fn</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">agent</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">fn</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">span_type</span><span class="o">=</span><span class="n">SpanType</span><span class="o">.</span><span class="n">TOOL</span><span class="p">,</span>
                <span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
                    <span class="n">fn</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">agent</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">fn</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">span_type</span><span class="o">=</span><span class="n">SpanType</span><span class="o">.</span><span class="n">TOOL</span><span class="p">,</span>
                <span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">wrapped</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)(</span><span class="n">wrapper</span><span class="p">)</span>
        <span class="n">wrapped</span><span class="o">.</span><span class="n">_is_mlflow_traced</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Marker to avoid double tracing</span>
        <span class="k">return</span> <span class="n">wrapped</span>

    <span class="n">agent</span><span class="o">.</span><span class="n">functions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">function_wrapper</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s2">&quot;_is_mlflow_traced&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">fn</span>
        <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">agent</span><span class="o">.</span><span class="n">functions</span>
    <span class="p">]</span>

    <span class="n">traced_fn</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
        <span class="n">original</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">agent</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.get_chat_completion&quot;</span><span class="p">,</span> <span class="n">span_type</span><span class="o">=</span><span class="n">SpanType</span><span class="o">.</span><span class="n">CHAIN</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">traced_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">patched_swarm_run</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Patched version of `run` method of the Swarm object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">traced_fn</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">span_type</span><span class="o">=</span><span class="n">SpanType</span><span class="o">.</span><span class="n">AGENT</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">traced_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

              </div>
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../',
      VERSION:'3.2.0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>