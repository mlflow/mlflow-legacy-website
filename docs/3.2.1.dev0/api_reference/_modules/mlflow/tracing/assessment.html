

<!DOCTYPE html>
<!-- source: docs/source/_modules/mlflow/tracing/assessment -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.tracing.assessment</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/_modules/mlflow/tracing/assessment.html">
  
  
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  

  

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    
  
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=AW-16857946923"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'AW-16857946923');
  </script>
  <!-- Eng gtag -->

  

  
  <meta name="docsearch:docusaurus_tag" content="default" data-rh="true">
  <meta name="docusaurus_tag" content="default" data-rh="true">
  <meta name="docusaurus_version" content="current" data-rh="true">
  <meta name="docsearch:version" content="current" data-rh="true">
  <meta name="docusaurus_locale" content="en" data-rh="true">
  <meta name="docsearch:language" content="en" data-rh="true">

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../search.html"/>
    <link rel="top" title="MLflow 3.2.1.dev0 documentation" href="../../../index.html"/>
        <link rel="up" title="Module code" href="../../index.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../_static/documentation_options.js"></script>
<script type="text/javascript" src="../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../_static/tabs.js"></script>
<script type="text/javascript" src="../../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../../../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <div class="header-container">
  <style scoped>
    .header-container {
      display: flex;
      flex-direction: row;
      align-items: center;
      justify-content: space-between;
      padding: 8px 16px;

      background-color: #fff;
      box-shadow: 0 1px 2px 0 #0000001a;
    }

    .logo-container {
      display: flex;
      gap: 12px;
      flex-direction: row;
      white-space: nowrap;
      align-items: center;
      justify-content: center;
    }

    a:hover {
      text-decoration: none;
      color: #0194e2;
    }
  </style>
  <div class="logo-container">
    <i
      data-toggle="wy-nav-top"
      class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"
    ></i>
    <a href="../../../index.html" class="wy-nav-top-logo">
      <img
        src="../../../_static/MLflow-logo-final-black.png"
        alt="MLflow"
      />
    </a>
    <a
      style="overflow: hidden; text-overflow: ellipsis"
      class="header-link"
      href="/docs/latest"
      >Main Docs</a
    >
    <span style="overflow: hidden; text-overflow: ellipsis" class="header-link"
      >API Documentation</span
    >
  </div>
  <span class="header-link">3.2.1.dev0</span>
</div>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../index.html">Home</a>
    

    
      

      
        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../typescript_api/index.html">TypeScript API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auth/python-api.html">MLflow Authentication Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auth/rest-api.html">MLflow Authentication REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../index.html">Module code</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.tracing.assessment</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/_modules/mlflow/tracing/assessment" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <h1>Source code for mlflow.tracing.assessment</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.assessment</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">DEFAULT_FEEDBACK_NAME</span><span class="p">,</span>
    <span class="n">Assessment</span><span class="p">,</span>
    <span class="n">AssessmentError</span><span class="p">,</span>
    <span class="n">Expectation</span><span class="p">,</span>
    <span class="n">Feedback</span><span class="p">,</span>
    <span class="n">FeedbackValueType</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.assessment_source</span><span class="w"> </span><span class="kn">import</span> <span class="n">AssessmentSource</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="n">MlflowException</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracing.client</span><span class="w"> </span><span class="kn">import</span> <span class="n">TracingClient</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.annotations</span><span class="w"> </span><span class="kn">import</span> <span class="n">experimental</span>


<div class="viewcode-block" id="get_assessment"><a class="viewcode-back" href="../../../python_api/mlflow.html#mlflow.get_assessment">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_assessment</span><span class="p">(</span><span class="n">trace_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">assessment_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Assessment</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get an assessment entity from the backend store.</span>

<span class="sd">    Args:</span>
<span class="sd">        trace_id: The ID of the trace.</span>
<span class="sd">        assessment_id: The ID of the assessment to get.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :py:class:`~mlflow.entities.Assessment`: The Assessment object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">TracingClient</span><span class="p">()</span><span class="o">.</span><span class="n">get_assessment</span><span class="p">(</span><span class="n">trace_id</span><span class="p">,</span> <span class="n">assessment_id</span><span class="p">)</span></div>


<div class="viewcode-block" id="log_assessment"><a class="viewcode-back" href="../../../python_api/mlflow.html#mlflow.log_assessment">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;2.21.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">log_assessment</span><span class="p">(</span><span class="n">trace_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">assessment</span><span class="p">:</span> <span class="n">Assessment</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Assessment</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Logs an assessment to a Trace. The assessment can be an expectation or a feedback.</span>

<span class="sd">    - Expectation: A label that represents the expected value for a particular operation.</span>
<span class="sd">        For example, an expected answer for a user question from a chatbot.</span>
<span class="sd">    - Feedback: A label that represents the feedback on the quality of the operation.</span>
<span class="sd">        Feedback can come from different sources, such as human judges, heuristic scorers,</span>
<span class="sd">        or LLM-as-a-Judge.</span>

<span class="sd">    The following code annotates a trace with a feedback provided by LLM-as-a-Judge.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.entities import Feedback</span>

<span class="sd">        feedback = Feedback(</span>
<span class="sd">            name=&quot;faithfulness&quot;,</span>
<span class="sd">            value=0.9,</span>
<span class="sd">            rationale=&quot;The model is faithful to the input.&quot;,</span>
<span class="sd">            metadata={&quot;model&quot;: &quot;gpt-4o-mini&quot;},</span>
<span class="sd">        )</span>

<span class="sd">        mlflow.log_assessment(trace_id=&quot;1234&quot;, assessment=feedback)</span>

<span class="sd">    The following code annotates a trace with human-provided ground truth with source information.</span>
<span class="sd">    When the source is not provided, the default source is set to &quot;default&quot; with type &quot;HUMAN&quot;</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.entities import AssessmentSource, AssessmentSourceType, Expectation</span>

<span class="sd">        # Specify the annotator information as a source.</span>
<span class="sd">        source = AssessmentSource(</span>
<span class="sd">            source_type=AssessmentSourceType.HUMAN,</span>
<span class="sd">            source_id=&quot;john@example.com&quot;,</span>
<span class="sd">        )</span>

<span class="sd">        expectation = Expectation(</span>
<span class="sd">            name=&quot;expected_answer&quot;,</span>
<span class="sd">            value=42,</span>
<span class="sd">            source=source,</span>
<span class="sd">        )</span>

<span class="sd">        mlflow.log_assessment(trace_id=&quot;1234&quot;, assessment=expectation)</span>

<span class="sd">    The expectation value can be any JSON-serializable value. For example, you may</span>
<span class="sd">     record the full LLM message as the expectation value.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.entities.assessment import Expectation</span>

<span class="sd">        expectation = Expectation(</span>
<span class="sd">            name=&quot;expected_message&quot;,</span>
<span class="sd">            # Full LLM message including expected tool calls</span>
<span class="sd">            value={</span>
<span class="sd">                &quot;role&quot;: &quot;assistant&quot;,</span>
<span class="sd">                &quot;content&quot;: &quot;The answer is 42.&quot;,</span>
<span class="sd">                &quot;tool_calls&quot;: [</span>
<span class="sd">                    {</span>
<span class="sd">                        &quot;id&quot;: &quot;1234&quot;,</span>
<span class="sd">                        &quot;type&quot;: &quot;function&quot;,</span>
<span class="sd">                        &quot;function&quot;: {&quot;name&quot;: &quot;add&quot;, &quot;arguments&quot;: &quot;40 + 2&quot;},</span>
<span class="sd">                    }</span>
<span class="sd">                ],</span>
<span class="sd">            },</span>
<span class="sd">        )</span>
<span class="sd">        mlflow.log_assessment(trace_id=&quot;1234&quot;, assessment=expectation)</span>

<span class="sd">    You can also log an error information during the feedback generation process. To do so,</span>
<span class="sd">    provide an instance of :py:class:`~mlflow.entities.AssessmentError` to the `error`</span>
<span class="sd">    parameter, and leave the `value` parameter as `None`.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.entities import AssessmentError, Feedback</span>

<span class="sd">        error = AssessmentError(</span>
<span class="sd">            error_code=&quot;RATE_LIMIT_EXCEEDED&quot;,</span>
<span class="sd">            error_message=&quot;Rate limit for the judge exceeded.&quot;,</span>
<span class="sd">        )</span>

<span class="sd">        feedback = Feedback(</span>
<span class="sd">            trace_id=&quot;1234&quot;,</span>
<span class="sd">            name=&quot;faithfulness&quot;,</span>
<span class="sd">            error=error,</span>
<span class="sd">        )</span>
<span class="sd">        mlflow.log_assessment(trace_id=&quot;1234&quot;, assessment=feedback)</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">TracingClient</span><span class="p">()</span><span class="o">.</span><span class="n">log_assessment</span><span class="p">(</span><span class="n">trace_id</span><span class="p">,</span> <span class="n">assessment</span><span class="p">)</span></div>


<div class="viewcode-block" id="log_expectation"><a class="viewcode-back" href="../../../python_api/mlflow.html#mlflow.log_expectation">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">log_expectation</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">trace_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">value</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">source</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AssessmentSource</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">span_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Assessment</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Logs an expectation (e.g. ground truth label) to a Trace. This API only takes keyword arguments.</span>

<span class="sd">    Args:</span>
<span class="sd">        trace_id: The ID of the trace.</span>
<span class="sd">        name: The name of the expectation assessment e.g., &quot;expected_answer</span>
<span class="sd">        value: The value of the expectation. It can be any JSON-serializable value.</span>
<span class="sd">        source: The source of the expectation assessment. Must be an instance of</span>
<span class="sd">                :py:class:`~mlflow.entities.AssessmentSource`. If not provided,</span>
<span class="sd">                default to CODE source type.</span>
<span class="sd">        metadata: Additional metadata for the expectation.</span>
<span class="sd">        span_id: The ID of the span associated with the expectation, if it needs be</span>
<span class="sd">                associated with a specific span in the trace.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :py:class:`~mlflow.entities.Assessment`: The created expectation assessment.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            import mlflow</span>
<span class="sd">            from mlflow.entities import AssessmentSource, AssessmentSourceType</span>

<span class="sd">            # Log simple expected answer</span>
<span class="sd">            expectation = mlflow.log_expectation(</span>
<span class="sd">                trace_id=&quot;tr-1234567890abcdef&quot;,</span>
<span class="sd">                name=&quot;expected_answer&quot;,</span>
<span class="sd">                value=&quot;The capital of France is Paris.&quot;,</span>
<span class="sd">                source=AssessmentSource(</span>
<span class="sd">                    source_type=AssessmentSourceType.HUMAN, source_id=&quot;annotator@company.com&quot;</span>
<span class="sd">                ),</span>
<span class="sd">                metadata={&quot;question_type&quot;: &quot;factual&quot;, &quot;difficulty&quot;: &quot;easy&quot;},</span>
<span class="sd">            )</span>

<span class="sd">            # Log expected classification label</span>
<span class="sd">            mlflow.log_expectation(</span>
<span class="sd">                trace_id=&quot;tr-1234567890abcdef&quot;,</span>
<span class="sd">                name=&quot;expected_category&quot;,</span>
<span class="sd">                value=&quot;positive&quot;,</span>
<span class="sd">                source=AssessmentSource(</span>
<span class="sd">                    source_type=AssessmentSourceType.HUMAN, source_id=&quot;data_labeler_001&quot;</span>
<span class="sd">                ),</span>
<span class="sd">                metadata={&quot;labeling_session&quot;: &quot;batch_01&quot;, &quot;confidence&quot;: 0.95},</span>
<span class="sd">            )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">assessment</span> <span class="o">=</span> <span class="n">Expectation</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
        <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="n">span_id</span><span class="o">=</span><span class="n">span_id</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">TracingClient</span><span class="p">()</span><span class="o">.</span><span class="n">log_assessment</span><span class="p">(</span><span class="n">trace_id</span><span class="p">,</span> <span class="n">assessment</span><span class="p">)</span></div>


<div class="viewcode-block" id="update_assessment"><a class="viewcode-back" href="../../../python_api/mlflow.html#mlflow.update_assessment">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;2.21.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update_assessment</span><span class="p">(</span>
    <span class="n">trace_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">assessment_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">assessment</span><span class="p">:</span> <span class="n">Assessment</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Assessment</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates an existing expectation (ground truth) in a Trace.</span>

<span class="sd">    Args:</span>
<span class="sd">        trace_id: The ID of the trace.</span>
<span class="sd">        assessment_id: The ID of the expectation or feedback assessment to update.</span>
<span class="sd">        assessment: The updated assessment.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :py:class:`~mlflow.entities.Assessment`: The updated feedback or expectation assessment.</span>

<span class="sd">    Example:</span>

<span class="sd">    The following code updates an existing expectation with a new value.</span>
<span class="sd">    To update other fields, provide the corresponding parameters.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.entities import Expectation, ExpectationValue</span>

<span class="sd">        # Create an expectation with value 42.</span>
<span class="sd">        response = mlflow.log_assessment(</span>
<span class="sd">            trace_id=&quot;1234&quot;,</span>
<span class="sd">            assessment=Expectation(name=&quot;expected_answer&quot;, value=42),</span>
<span class="sd">        )</span>
<span class="sd">        assessment_id = response.assessment_id</span>

<span class="sd">        # Update the expectation with a new value 43.</span>
<span class="sd">        mlflow.update_assessment(</span>
<span class="sd">            trace_id=&quot;1234&quot;,</span>
<span class="sd">            assessment_id=assessment.assessment_id,</span>
<span class="sd">            assessment=Expectation(name=&quot;expected_answer&quot;, value=43),</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">TracingClient</span><span class="p">()</span><span class="o">.</span><span class="n">update_assessment</span><span class="p">(</span>
        <span class="n">assessment_id</span><span class="o">=</span><span class="n">assessment_id</span><span class="p">,</span>
        <span class="n">trace_id</span><span class="o">=</span><span class="n">trace_id</span><span class="p">,</span>
        <span class="n">assessment</span><span class="o">=</span><span class="n">assessment</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="delete_assessment"><a class="viewcode-back" href="../../../python_api/mlflow.html#mlflow.delete_assessment">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;2.21.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">delete_assessment</span><span class="p">(</span><span class="n">trace_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">assessment_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Deletes an assessment associated with a trace.</span>

<span class="sd">    Args:</span>
<span class="sd">        trace_id: The ID of the trace.</span>
<span class="sd">        assessment_id: The ID of the assessment to delete.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">TracingClient</span><span class="p">()</span><span class="o">.</span><span class="n">delete_assessment</span><span class="p">(</span><span class="n">trace_id</span><span class="o">=</span><span class="n">trace_id</span><span class="p">,</span> <span class="n">assessment_id</span><span class="o">=</span><span class="n">assessment_id</span><span class="p">)</span></div>


<div class="viewcode-block" id="log_feedback"><a class="viewcode-back" href="../../../python_api/mlflow.html#mlflow.log_feedback">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;2.21.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">log_feedback</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">trace_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">DEFAULT_FEEDBACK_NAME</span><span class="p">,</span>
    <span class="n">value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FeedbackValueType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AssessmentSource</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">error</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="ne">Exception</span><span class="p">,</span> <span class="n">AssessmentError</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">rationale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">span_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Assessment</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Logs feedback to a Trace. This API only takes keyword arguments.</span>

<span class="sd">    Args:</span>
<span class="sd">        trace_id: The ID of the trace.</span>
<span class="sd">        name: The name of the feedback assessment e.g., &quot;faithfulness&quot;. Defaults to</span>
<span class="sd">            &quot;feedback&quot; if not provided.</span>
<span class="sd">        value: The value of the feedback. Must be one of the following types:</span>
<span class="sd">            - float</span>
<span class="sd">            - int</span>
<span class="sd">            - str</span>
<span class="sd">            - bool</span>
<span class="sd">            - list of values of the same types as above</span>
<span class="sd">            - dict with string keys and values of the same types as above</span>
<span class="sd">        source: The source of the feedback assessment. Must be an instance of</span>
<span class="sd">                :py:class:`~mlflow.entities.AssessmentSource`. If not provided, defaults to</span>
<span class="sd">                CODE source type</span>
<span class="sd">        error: An error object representing any issues encountered while computing the</span>
<span class="sd">            feedback, e.g., a timeout error from an LLM judge. Accepts an exception</span>
<span class="sd">            object, or an :py:class:`~mlflow.entities.AssessmentError` object. Either</span>
<span class="sd">            this or `value` must be provided.</span>
<span class="sd">        rationale: The rationale / justification for the feedback.</span>
<span class="sd">        metadata: Additional metadata for the feedback.</span>
<span class="sd">        span_id: The ID of the span associated with the feedback, if it needs be</span>
<span class="sd">                associated with a specific span in the trace.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :py:class:`~mlflow.entities.Assessment`: The created feedback assessment.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            import mlflow</span>
<span class="sd">            from mlflow.entities import AssessmentSource, AssessmentSourceType</span>

<span class="sd">            # Log simple feedback score</span>
<span class="sd">            feedback = mlflow.log_feedback(</span>
<span class="sd">                trace_id=&quot;tr-1234567890abcdef&quot;,</span>
<span class="sd">                name=&quot;relevance&quot;,</span>
<span class="sd">                value=0.9,</span>
<span class="sd">                source=AssessmentSource(source_type=AssessmentSourceType.LLM, source_id=&quot;gpt-4&quot;),</span>
<span class="sd">                rationale=&quot;Response directly addresses the user&#39;s question&quot;,</span>
<span class="sd">            )</span>

<span class="sd">            # Log detailed feedback with structured data</span>
<span class="sd">            mlflow.log_feedback(</span>
<span class="sd">                trace_id=&quot;tr-1234567890abcdef&quot;,</span>
<span class="sd">                name=&quot;quality_metrics&quot;,</span>
<span class="sd">                value={&quot;accuracy&quot;: 0.95, &quot;completeness&quot;: 0.88, &quot;clarity&quot;: 0.92, &quot;overall&quot;: 0.92},</span>
<span class="sd">                source=AssessmentSource(</span>
<span class="sd">                    source_type=AssessmentSourceType.HUMAN, source_id=&quot;expert_evaluator&quot;</span>
<span class="sd">                ),</span>
<span class="sd">                rationale=&quot;High accuracy and clarity, slightly incomplete coverage&quot;,</span>
<span class="sd">            )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">assessment</span> <span class="o">=</span> <span class="n">Feedback</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
        <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span>
        <span class="n">error</span><span class="o">=</span><span class="n">error</span><span class="p">,</span>
        <span class="n">rationale</span><span class="o">=</span><span class="n">rationale</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="n">span_id</span><span class="o">=</span><span class="n">span_id</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">TracingClient</span><span class="p">()</span><span class="o">.</span><span class="n">log_assessment</span><span class="p">(</span><span class="n">trace_id</span><span class="p">,</span> <span class="n">assessment</span><span class="p">)</span></div>


<div class="viewcode-block" id="override_feedback"><a class="viewcode-back" href="../../../python_api/mlflow.html#mlflow.override_feedback">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">override_feedback</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">trace_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">assessment_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">value</span><span class="p">:</span> <span class="n">FeedbackValueType</span><span class="p">,</span>
    <span class="n">rationale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AssessmentSource</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Assessment</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Overrides an existing feedback assessment with a new assessment. This API</span>
<span class="sd">    logs a new assessment with the `overrides` field set to the provided assessment ID.</span>
<span class="sd">    The original assessment will be marked as invalid, but will otherwise be unchanged.</span>
<span class="sd">    This is useful when you want to correct an assessment generated by an LLM judge,</span>
<span class="sd">    but want to preserve the original assessment for future judge fine-tuning.</span>

<span class="sd">    If you want to mutate an assessment in-place, use :py:func:`update_assessment` instead.</span>

<span class="sd">    Args:</span>
<span class="sd">        trace_id: The ID of the trace.</span>
<span class="sd">        assessment_id: The ID of the assessment to override.</span>
<span class="sd">        value: The new value of the assessment.</span>
<span class="sd">        rationale: The rationale of the new assessment.</span>
<span class="sd">        source: The source of the new assessment.</span>
<span class="sd">        metadata: Additional metadata for the new assessment.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :py:class:`~mlflow.entities.Assessment`: The created assessment.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            import mlflow</span>
<span class="sd">            from mlflow.entities import AssessmentSource, AssessmentSourceType</span>

<span class="sd">            # First, log an initial LLM-generated feedback as a simulation</span>
<span class="sd">            llm_feedback = mlflow.log_feedback(</span>
<span class="sd">                trace_id=&quot;tr-1234567890abcdef&quot;,</span>
<span class="sd">                name=&quot;relevance&quot;,</span>
<span class="sd">                value=0.6,</span>
<span class="sd">                source=AssessmentSource(source_type=AssessmentSourceType.LLM, source_id=&quot;gpt-4&quot;),</span>
<span class="sd">                rationale=&quot;Response partially addresses the question&quot;,</span>
<span class="sd">            )</span>

<span class="sd">            # Later, a human reviewer disagrees and wants to override</span>
<span class="sd">            corrected_assessment = mlflow.override_feedback(</span>
<span class="sd">                trace_id=&quot;tr-1234567890abcdef&quot;,</span>
<span class="sd">                assessment_id=llm_feedback.assessment_id,</span>
<span class="sd">                value=0.9,</span>
<span class="sd">                rationale=&quot;Response fully addresses the question with good examples&quot;,</span>
<span class="sd">                source=AssessmentSource(</span>
<span class="sd">                    source_type=AssessmentSourceType.HUMAN, source_id=&quot;expert_reviewer@company.com&quot;</span>
<span class="sd">                ),</span>
<span class="sd">                metadata={</span>
<span class="sd">                    &quot;override_reason&quot;: &quot;LLM underestimated relevance&quot;,</span>
<span class="sd">                    &quot;review_date&quot;: &quot;2024-01-15&quot;,</span>
<span class="sd">                    &quot;confidence&quot;: &quot;high&quot;,</span>
<span class="sd">                },</span>
<span class="sd">            )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">old_assessment</span> <span class="o">=</span> <span class="n">get_assessment</span><span class="p">(</span><span class="n">trace_id</span><span class="p">,</span> <span class="n">assessment_id</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">old_assessment</span><span class="p">,</span> <span class="n">Feedback</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The assessment with ID </span><span class="si">{</span><span class="n">assessment_id</span><span class="si">}</span><span class="s2"> is not a feedback assessment.&quot;</span>
        <span class="p">)</span>

    <span class="n">new_assessment</span> <span class="o">=</span> <span class="n">Feedback</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">old_assessment</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="n">span_id</span><span class="o">=</span><span class="n">old_assessment</span><span class="o">.</span><span class="n">span_id</span><span class="p">,</span>
        <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span>
        <span class="n">rationale</span><span class="o">=</span><span class="n">rationale</span><span class="p">,</span>
        <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="n">overrides</span><span class="o">=</span><span class="n">old_assessment</span><span class="o">.</span><span class="n">assessment_id</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">TracingClient</span><span class="p">()</span><span class="o">.</span><span class="n">log_assessment</span><span class="p">(</span><span class="n">trace_id</span><span class="p">,</span> <span class="n">new_assessment</span><span class="p">)</span></div>
</pre></div>

              </div>
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../',
      VERSION:'3.2.1.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>