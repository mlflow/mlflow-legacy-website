"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3062],{866:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>f,frontMatter:()=>r,metadata:()=>c,toc:()=>h});var s=t(4848),o=t(8453),l=t(5983),i=t(6581);t(1226);const r={},a="Get Started with MLflow + Tensorflow",c={id:"deep-learning/tensorflow/quickstart/quickstart_tensorflow",title:"Get Started with MLflow + Tensorflow",description:"In this guide, we will show how to train your model with Tensorflow and log your training using MLflow.",source:"@site/docs/deep-learning/tensorflow/quickstart/quickstart_tensorflow.mdx",sourceDirName:"deep-learning/tensorflow/quickstart",slug:"/deep-learning/tensorflow/quickstart/quickstart_tensorflow",permalink:"/docs/latest/deep-learning/tensorflow/quickstart/quickstart_tensorflow",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"docsSidebar",previous:{title:"Tensorflow within MLflow",permalink:"/docs/latest/deep-learning/tensorflow/guide/"},next:{title:"MLflow PyTorch Flavor",permalink:"/docs/latest/deep-learning/pytorch/"}},d={},h=[{value:"Install dependencies",id:"install-dependencies",level:2},{value:"Load the dataset",id:"load-the-dataset",level:2},{value:"Define the Model",id:"define-the-model",level:2},{value:"Set up tracking/visualization tool",id:"set-up-trackingvisualization-tool",level:2},{value:"Logging with MLflow",id:"logging-with-mlflow",level:2},{value:"MLflow Auto Logging",id:"mlflow-auto-logging",level:3},{value:"Log with MLflow Callback",id:"log-with-mlflow-callback",level:3},{value:"Customize the MLflow Callback",id:"customize-the-mlflow-callback",level:3},{value:"Wrap up",id:"wrap-up",level:2}];function u(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"get-started-with-mlflow--tensorflow",children:"Get Started with MLflow + Tensorflow"})}),"\n",(0,s.jsx)(n.p,{children:"In this guide, we will show how to train your model with Tensorflow and log your training using MLflow."}),"\n",(0,s.jsxs)(n.p,{children:["We will use ",(0,s.jsx)(n.a,{href:"https://community.cloud.databricks.com/",children:"Databricks Community Edition"})," as our tracking server, which has built-in support for MLflow. Databricks CE is the free version of Databricks platform, if you haven't, please register an account via ",(0,s.jsx)(n.a,{href:"https://www.databricks.com/try-databricks",children:"link"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["You can run code in this guide from cloud-based notebooks like Databricks notebook or Google Colab, or run it on your local machine.\n",(0,s.jsxs)("a",{href:"https://raw.githubusercontent.com/mlflow/mlflow/master/docs/source/deep-learning/tensorflow/quickstart/quickstart_tensorflow.ipynb",class:"notebook-download-btn",children:[(0,s.jsx)("i",{class:"fas fa-download"}),"Download this Notebook"]}),(0,s.jsx)("br",{})]}),"\n",(0,s.jsx)(n.h2,{id:"install-dependencies",children:"Install dependencies"}),"\n",(0,s.jsxs)(n.p,{children:["Let's install the ",(0,s.jsx)(n.code,{children:"mlflow"})," package."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"%pip install -q mlflow\n"})}),"\n",(0,s.jsx)(n.p,{children:"Then let's import the packages."}),"\n",(0,s.jsx)(l.d,{executionCount:2,children:"import tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow import keras"}),"\n",(0,s.jsx)(n.h2,{id:"load-the-dataset",children:"Load the dataset"}),"\n",(0,s.jsxs)(n.p,{children:["We will do a simple image classification on handwritten digits with ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/MNIST_database",children:"mnist dataset"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["Let's load the dataset using ",(0,s.jsx)(n.code,{children:"tensorflow_datasets"})," (",(0,s.jsx)(n.code,{children:"tfds"}),"), which returns datasets in the format of ",(0,s.jsx)(n.code,{children:"tf.data.Dataset"}),"."]}),"\n",(0,s.jsx)(l.d,{executionCount:3,children:'# Load the mnist dataset.\ntrain_ds, test_ds = tfds.load(\n  "mnist",\n  split=["train", "test"],\n  shuffle_files=True,\n)'}),"\n",(0,s.jsx)(i.p,{children:"Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1..."}),"\n",(0,s.jsx)(i.p,{children:"Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"}),"\n",(0,s.jsx)(i.p,{children:"Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data."}),"\n",(0,s.jsx)(n.p,{children:"Let's preprocess our data with the following steps:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Scale each pixel's value to ",(0,s.jsx)(n.code,{children:"[0, 1)"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"Batch the dataset."}),"\n",(0,s.jsxs)(n.li,{children:["Use ",(0,s.jsx)(n.code,{children:"prefetch"})," to speed up the training."]}),"\n"]}),"\n",(0,s.jsx)(l.d,{executionCount:4,children:'def preprocess_fn(data):\n  image = tf.cast(data["image"], tf.float32) / 255\n  label = data["label"]\n  return (image, label)\n\n\ntrain_ds = train_ds.map(preprocess_fn).batch(128).prefetch(tf.data.AUTOTUNE)\ntest_ds = test_ds.map(preprocess_fn).batch(128).prefetch(tf.data.AUTOTUNE)'}),"\n",(0,s.jsx)(n.h2,{id:"define-the-model",children:"Define the Model"}),"\n",(0,s.jsxs)(n.p,{children:["Let's define a convolutional neural network as our classifier. We can use ",(0,s.jsx)(n.code,{children:"keras.Sequential"})," to stack up the layers."]}),"\n",(0,s.jsx)(l.d,{executionCount:13,children:'input_shape = (28, 28, 1)\nnum_classes = 10\n\nmodel = keras.Sequential(\n  [\n      keras.Input(shape=input_shape),\n      keras.layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),\n      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n      keras.layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),\n      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n      keras.layers.Flatten(),\n      keras.layers.Dropout(0.5),\n      keras.layers.Dense(num_classes, activation="softmax"),\n  ]\n)'}),"\n",(0,s.jsx)(n.p,{children:"Set training-related configs, optimizers, loss function, metrics."}),"\n",(0,s.jsx)(l.d,{executionCount:14,children:"model.compile(\n  loss=keras.losses.SparseCategoricalCrossentropy(),\n  optimizer=keras.optimizers.Adam(0.001),\n  metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)"}),"\n",(0,s.jsx)(n.h2,{id:"set-up-trackingvisualization-tool",children:"Set up tracking/visualization tool"}),"\n",(0,s.jsxs)(n.p,{children:["In this tutorial, we will use Databricks CE as MLflow tracking server. For other options such as using your local MLflow server, please read the ",(0,s.jsx)(n.a,{href:"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",children:"Tracking Server Overview"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["If you have not, please register an account of ",(0,s.jsx)(n.a,{href:"https://www.databricks.com/try-databricks#account",children:"Databricks community edition"}),". It should take no longer than 1min to register. Databricks CE (community edition) is a free platform for users to try out Databricks features. For this guide, we need the ML experiment dashboard for us to track our training progress."]}),"\n",(0,s.jsx)(n.p,{children:"After successfully registering an account on Databricks CE, let's connnect MLflow to Databricks CE. You will need to enter following information:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Databricks Host"}),": ",(0,s.jsx)(n.a,{href:"https://community.cloud.databricks.com/",children:"https://community.cloud.databricks.com/"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Username"}),": your signed up email"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Password"}),": your password"]}),"\n"]}),"\n",(0,s.jsx)(l.d,{executionCount:" ",children:"import mlflow\n\nmlflow.login()"}),"\n",(0,s.jsx)(n.p,{children:"Now this colab is connected to the hosted tracking server. Let's configure MLflow metadata. Two things to set up:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"mlflow.set_tracking_uri"}),': always use "databricks".']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"mlflow.set_experiment"}),": pick up a name you like, start with ",(0,s.jsx)(n.code,{children:"/"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"logging-with-mlflow",children:"Logging with MLflow"}),"\n",(0,s.jsx)(n.p,{children:"There are two ways you can log to MLflow from your Tensorflow pipeline:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"MLflow auto logging."}),"\n",(0,s.jsx)(n.li,{children:"Use a callback."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Auto logging is simple to configure, but gives you less control. Using a callback is more flexible. Let's see how each way is done."}),"\n",(0,s.jsx)(n.h3,{id:"mlflow-auto-logging",children:"MLflow Auto Logging"}),"\n",(0,s.jsxs)(n.p,{children:["All you need to do is to call ",(0,s.jsx)(n.code,{children:"mlflow.tensorflow.autolog()"})," before kicking off the training, then the backend will automatically log the metrics into the server you configured earlier. In our case, Databricks CE."]}),"\n",(0,s.jsx)(l.d,{executionCount:15,children:'# Choose any name that you like.\nmlflow.set_experiment("/mlflow-tf-keras-mnist")\n\nmlflow.tensorflow.autolog()\n\nmodel.fit(x=train_ds, epochs=3)'}),"\n",(0,s.jsx)(i.p,{isStderr:!0,children:"2023/11/15 01:53:35 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '7c1db53e417b43f0a1d9e095c9943acb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow"}),"\n",(0,s.jsx)(i.p,{children:"Epoch 1/3\n469/469 [==============================] - 13s 7ms/step - loss: 0.3610 - sparse_categorical_accuracy: 0.8890\nEpoch 2/3\n469/469 [==============================] - 3s 6ms/step - loss: 0.1035 - sparse_categorical_accuracy: 0.9681\nEpoch 3/3\n469/469 [==============================] - 4s 8ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9760"}),"\n",(0,s.jsx)(i.p,{isStderr:!0,children:'2023/11/15 01:54:05 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: tuple index out of range\n2023/11/15 01:54:05 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.8.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n2023/11/15 01:54:05 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model\'s pyfunc representation accepts pandas DataFrames as inference inputs.\n2023/11/15 01:54:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils."'}),"\n",(0,s.jsx)(i.p,{children:"Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"}),"\n",(0,s.jsx)(i.p,{isStderr:!0,children:"2023/11/15 01:54:13 INFO mlflow.store.artifact.cloud_artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false"}),"\n",(0,s.jsx)(i.p,{children:"Uploading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"}),"\n",(0,s.jsx)(i.p,{children:"<keras.src.callbacks.History at 0x7d48e6556b60>"}),"\n",(0,s.jsxs)(n.p,{children:["While your training is ongoing, you can find this training in your dashboard. Log in to your ",(0,s.jsx)(n.a,{href:"https://community.cloud.databricks.com/",children:"Databricks CE"})," account, and click on top left to select machine learning in the drop down list. Then click on the experiment icon. See the screenshot below:\n",(0,s.jsx)(n.img,{src:"https://i.imgur.com/eQgnAcI.png",alt:"landing page"})]}),"\n",(0,s.jsxs)(n.p,{children:["After clicking the ",(0,s.jsx)(n.code,{children:"Experiment"})," button, it will bring you to the experiment page, where you can find your runs. Clicking on the most recent experiment and run, you can find your metrics there, similar to:\n",(0,s.jsx)(n.img,{src:"https://i.imgur.com/uuHLttD.png",alt:"experiment page"})]}),"\n",(0,s.jsx)(n.p,{children:"You can click on metrics to see the chart."}),"\n",(0,s.jsx)(n.p,{children:"Let's evaluate the training result."}),"\n",(0,s.jsx)(l.d,{executionCount:17,children:'score = model.evaluate(test_ds)\n\nprint(f"Test loss: {score[0]:.4f}")\nprint(f"Test accuracy: {score[1]: .2f}")'}),"\n",(0,s.jsx)(i.p,{children:"79/79 [==============================] - 1s 12ms/step - loss: 0.0484 - sparse_categorical_accuracy: 0.9838\nTest loss: 0.05\nTest accuracy:  0.98"}),"\n",(0,s.jsx)(n.h3,{id:"log-with-mlflow-callback",children:"Log with MLflow Callback"}),"\n",(0,s.jsxs)(n.p,{children:["Auto logging is powerful and convenient, but if you are looking for a more native way as Tensorflow pipelines, you can use ",(0,s.jsx)(n.code,{children:"mlflow.tensorflow.MllflowCallback"})," inside ",(0,s.jsx)(n.code,{children:"model.fit()"}),", it will log:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Your model configuration, layers, hyperparameters and so on."}),"\n",(0,s.jsxs)(n.li,{children:["The training stats, including losses and metrics configured with ",(0,s.jsx)(n.code,{children:"model.compile()"}),"."]}),"\n"]}),"\n",(0,s.jsx)(l.d,{executionCount:22,children:"from mlflow.tensorflow import MlflowCallback\n\n# Turn off autologging.\nmlflow.tensorflow.autolog(disable=True)\n\nwith mlflow.start_run() as run:\n  model.fit(\n      x=train_ds,\n      epochs=2,\n      callbacks=[MlflowCallback(run)],\n  )"}),"\n",(0,s.jsx)(i.p,{children:"Epoch 1/2\n469/469 [==============================] - 5s 10ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9851\nEpoch 2/2\n469/469 [==============================] - 4s 8ms/step - loss: 0.0432 - sparse_categorical_accuracy: 0.9866"}),"\n",(0,s.jsx)(n.p,{children:"Going to the Databricks CE experiment view, you will see a similar dashboard as before."}),"\n",(0,s.jsx)(n.h3,{id:"customize-the-mlflow-callback",children:"Customize the MLflow Callback"}),"\n",(0,s.jsxs)(n.p,{children:["If you want to add extra logging logic, you can customize the MLflow callback. You can either subclass from ",(0,s.jsx)(n.code,{children:"keras.callbacks.Callback"})," and write everything from scratch or subclass from ",(0,s.jsx)(n.code,{children:"mlflow.tensorflow.MllflowCallback"})," to add you custom logging logic."]}),"\n",(0,s.jsx)(n.p,{children:"Let's look at an example that we want to replace the loss with its log value to log to MLflow."}),"\n",(0,s.jsx)(l.d,{executionCount:19,children:'import math\n\n\n# Create our own callback by subclassing `MlflowCallback`.\nclass MlflowCustomCallback(MlflowCallback):\n  def on_epoch_end(self, epoch, logs=None):\n      if not self.log_every_epoch:\n          return\n      loss = logs["loss"]\n      logs["log_loss"] = math.log(loss)\n      del logs["loss"]\n      self.metrics_logger.record_metrics(logs, epoch)'}),"\n",(0,s.jsx)(n.p,{children:"Train the model with the new callback."}),"\n",(0,s.jsx)(l.d,{executionCount:21,children:"with mlflow.start_run() as run:\n  run_id = run.info.run_id\n  model.fit(\n      x=train_ds,\n      epochs=2,\n      callbacks=[MlflowCustomCallback(run)],\n  )"}),"\n",(0,s.jsx)(i.p,{children:"Epoch 1/2\n469/469 [==============================] - 5s 10ms/step - loss: 0.0537 - sparse_categorical_accuracy: 0.9834 - log_loss: -2.9237\nEpoch 2/2\n469/469 [==============================] - 4s 9ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9846 - log_loss: -3.0022"}),"\n",(0,s.jsx)(i.p,{isStderr:!0,children:"2023/11/15 01:57:50 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: MLflow autologging must be turned off if an `MllflowCallback` is explicitly added to the callback list. You are creating an `MllflowCallback` while having autologging enabled. Please either call `mlflow.tensorflow.autolog(disable=True)` to disable autologging or remove `MllflowCallback` from the callback list."}),"\n",(0,s.jsxs)(n.p,{children:["Going to your Databricks CE page, you should find the ",(0,s.jsx)(n.code,{children:"log_loss"})," is replacing the ",(0,s.jsx)(n.code,{children:"loss"})," metric, similar to what is shown in the screenshot below."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://i.imgur.com/dncAwaP.png",alt:"log loss screenshot"})}),"\n",(0,s.jsx)(n.h2,{id:"wrap-up",children:"Wrap up"}),"\n",(0,s.jsx)(n.p,{children:"Now you have learned the basic integration between MLflow and Tensorflow. There are a few things not covered by this quickstart, e.g., saving TF model to MLflow and loading it back. For a detailed guide, please refer to our main guide for integration between MLflow and Tensorflow."})]})}function f(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},6581:(e,n,t)=>{t.d(n,{p:()=>o});var s=t(4848);const o=e=>{let{children:n,isStderr:t}=e;return(0,s.jsxs)("div",{style:{display:"flex",flexDirection:"row"},children:[(0,s.jsx)("div",{style:{width:"2rem",flexShrink:0}}),(0,s.jsx)("pre",{style:{margin:0,borderRadius:0,background:"none",fontSize:"0.85rem",flexGrow:1,padding:"var(--padding-sm)"},children:n})]})}},5983:(e,n,t)=>{t.d(n,{d:()=>i});var s=t(1432);const o="codeBlock_oJcR";var l=t(4848);const i=e=>{let{children:n,executionCount:t}=e;return(0,l.jsxs)("div",{style:{display:"flex",flexDirection:"row",marginTop:"var(--padding-md)",width:"100%"},children:[(0,l.jsx)("div",{style:{width:"2rem",flexShrink:0,fontSize:"0.8rem"},children:`[${t}]`}),(0,l.jsx)("div",{style:{flexGrow:1,minWidth:0},children:(0,l.jsx)(s.A,{className:o,language:"python",children:n})})]})}},1226:(e,n,t)=>{t.d(n,{Q:()=>o});var s=t(4848);const o=e=>{let{children:n}=e;return(0,s.jsxs)("div",{style:{display:"flex",flexDirection:"row",width:"100%"},children:[(0,s.jsx)("div",{style:{width:"2rem",flexShrink:0}}),(0,s.jsx)("div",{style:{flexGrow:1,minWidth:0,fontSize:"0.8rem"},children:n})]})}}}]);