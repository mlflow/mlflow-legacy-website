

<!DOCTYPE html>
<!-- source: docs/source/_modules/mlflow/genai/scorers/builtin_scorers -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.genai.scorers.builtin_scorers</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/_modules/mlflow/genai/scorers/builtin_scorers.html">
  
  
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
  

  

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    
  
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=AW-16857946923"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'AW-16857946923');
  </script>
  <!-- Eng gtag -->

  

  
  <meta name="docsearch:docusaurus_tag" content="default" data-rh="true">
  <meta name="docusaurus_tag" content="default" data-rh="true">
  <meta name="docusaurus_version" content="current" data-rh="true">
  <meta name="docsearch:version" content="current" data-rh="true">
  <meta name="docusaurus_locale" content="en" data-rh="true">
  <meta name="docsearch:language" content="en" data-rh="true">

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../../search.html"/>
    <link rel="top" title="MLflow 3.5.0 documentation" href="../../../../index.html"/>
        <link rel="up" title="Module code" href="../../../index.html"/> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../../_static/documentation_options.js"></script>
<script type="text/javascript" src="../../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../../_static/tabs.js"></script>
<script type="text/javascript" src="../../../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../../../../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <div class="header-container">
  <style scoped>
    .header-container {
      display: flex;
      flex-direction: row;
      align-items: center;
      justify-content: space-between;
      padding: 8px 16px;

      background-color: #fff;
      box-shadow: 0 1px 2px 0 #0000001a;
    }

    .logo-container {
      display: flex;
      gap: 12px;
      flex-direction: row;
      white-space: nowrap;
      align-items: center;
      justify-content: center;
    }

    a:hover {
      text-decoration: none;
      color: #0194e2;
    }
  </style>
  <div class="logo-container">
    <i
      data-toggle="wy-nav-top"
      class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"
    ></i>
    <a href="../../../../index.html" class="wy-nav-top-logo">
      <img
        src="../../../../_static/MLflow-logo-final-black.png"
        alt="MLflow"
      />
    </a>
    <a
      style="overflow: hidden; text-overflow: ellipsis"
      class="header-link"
      href="/docs/latest"
      >Main Docs</a
    >
    <span style="overflow: hidden; text-overflow: ellipsis" class="header-link"
      >API Documentation</span
    >
  </div>
  <span class="header-link version">3.5.0</span>
</div>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../../index.html">Home</a>
    

    
      

      
        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../typescript_api/index.html">TypeScript API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auth/python-api.html">MLflow Authentication Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auth/rest-api.html">MLflow Authentication REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../../index.html">Module code</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.genai.scorers.builtin_scorers</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/_modules/mlflow/genai/scorers/builtin_scorers" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <h1>Source code for mlflow.genai.scorers.builtin_scorers</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">asdict</span><span class="p">,</span> <span class="n">dataclass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">Any</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pydantic</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.prompts.equivalence</span><span class="w"> </span><span class="kn">import</span> <span class="n">EQUIVALENCE_PROMPT_INSTRUCTIONS</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.types.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatMessage</span>

<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.assessment</span><span class="w"> </span><span class="kn">import</span> <span class="n">Feedback</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.trace</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trace</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="n">MlflowException</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai</span><span class="w"> </span><span class="kn">import</span> <span class="n">judges</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">Judge</span><span class="p">,</span> <span class="n">JudgeField</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.builtin</span><span class="w"> </span><span class="kn">import</span> <span class="n">_MODEL_API_DOC</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.constants</span><span class="w"> </span><span class="kn">import</span> <span class="n">_AFFIRMATIVE_VALUES</span><span class="p">,</span> <span class="n">_NEGATIVE_VALUES</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.prompts.context_sufficiency</span><span class="w"> </span><span class="kn">import</span> <span class="n">CONTEXT_SUFFICIENCY_PROMPT_INSTRUCTIONS</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.prompts.correctness</span><span class="w"> </span><span class="kn">import</span> <span class="n">CORRECTNESS_PROMPT_INSTRUCTIONS</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.prompts.groundedness</span><span class="w"> </span><span class="kn">import</span> <span class="n">GROUNDEDNESS_PROMPT_INSTRUCTIONS</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.prompts.guidelines</span><span class="w"> </span><span class="kn">import</span> <span class="n">GUIDELINES_PROMPT_INSTRUCTIONS</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.prompts.relevance_to_query</span><span class="w"> </span><span class="kn">import</span> <span class="n">RELEVANCE_TO_QUERY_PROMPT_INSTRUCTIONS</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">CategoricalRating</span><span class="p">,</span>
    <span class="n">get_chat_completions_with_structured_output</span><span class="p">,</span>
    <span class="n">get_default_model</span><span class="p">,</span>
    <span class="n">invoke_judge_model</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers.base</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_SERIALIZATION_VERSION</span><span class="p">,</span>
    <span class="n">ScorerKind</span><span class="p">,</span>
    <span class="n">SerializedScorer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.utils.trace_utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">extract_request_from_trace</span><span class="p">,</span>
    <span class="n">extract_response_from_trace</span><span class="p">,</span>
    <span class="n">extract_retrieval_context_from_trace</span><span class="p">,</span>
    <span class="n">parse_inputs_to_str</span><span class="p">,</span>
    <span class="n">parse_outputs_to_str</span><span class="p">,</span>
    <span class="n">resolve_expectations_from_trace</span><span class="p">,</span>
    <span class="n">resolve_inputs_from_trace</span><span class="p">,</span>
    <span class="n">resolve_outputs_from_trace</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.annotations</span><span class="w"> </span><span class="kn">import</span> <span class="n">experimental</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.docstring_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">format_docstring</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.uri</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_databricks_uri</span>

<span class="n">GENAI_CONFIG_NAME</span> <span class="o">=</span> <span class="s2">&quot;databricks-agent&quot;</span>


<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">FieldExtractionConfig</span><span class="p">:</span>
    <span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;ChatMessage&quot;</span><span class="p">]</span>
    <span class="n">schema</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">pydantic</span><span class="o">.</span><span class="n">BaseModel</span><span class="p">]</span>


<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ExtractedFields</span><span class="p">:</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">expectations</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_construct_field_extraction_config</span><span class="p">(</span>
    <span class="n">needs_inputs</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">needs_outputs</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FieldExtractionConfig</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct field extraction configuration with messages and schema.</span>

<span class="sd">    Args:</span>
<span class="sd">        needs_inputs: Whether inputs field needs extraction.</span>
<span class="sd">        needs_outputs: Whether outputs field needs extraction.</span>

<span class="sd">    Returns:</span>
<span class="sd">        FieldExtractionConfig containing messages and schema for extraction.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.types.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatMessage</span>

    <span class="n">extraction_tasks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">schema_fields</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="n">needs_inputs</span><span class="p">:</span>
        <span class="n">extraction_tasks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;- inputs: The initial user request/question&quot;</span><span class="p">)</span>
        <span class="n">schema_fields</span><span class="p">[</span><span class="s2">&quot;inputs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">str</span><span class="p">,</span>
            <span class="n">pydantic</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;The user&#39;s original request&quot;</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">needs_outputs</span><span class="p">:</span>
        <span class="n">extraction_tasks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;- outputs: The final system response&quot;</span><span class="p">)</span>
        <span class="n">schema_fields</span><span class="p">[</span><span class="s2">&quot;outputs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">str</span><span class="p">,</span>
            <span class="n">pydantic</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;The system&#39;s final response&quot;</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="n">schema</span> <span class="o">=</span> <span class="n">pydantic</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s2">&quot;ExtractionSchema&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">schema_fields</span><span class="p">)</span>

    <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">ChatMessage</span><span class="p">(</span>
            <span class="n">role</span><span class="o">=</span><span class="s2">&quot;system&quot;</span><span class="p">,</span>
            <span class="n">content</span><span class="o">=</span><span class="p">(</span>
                <span class="s2">&quot;Extract the following fields from the trace.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;Use the provided tools to examine the trace&#39;s spans to find:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">extraction_tasks</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Return the result as JSON.&quot;</span>
            <span class="p">),</span>
        <span class="p">),</span>
        <span class="n">ChatMessage</span><span class="p">(</span>
            <span class="n">role</span><span class="o">=</span><span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="n">content</span><span class="o">=</span><span class="s2">&quot;Use the tools to find the required fields, then return them as JSON.&quot;</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">]</span>

    <span class="k">return</span> <span class="n">FieldExtractionConfig</span><span class="p">(</span><span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_validate_required_fields</span><span class="p">(</span>
    <span class="n">fields</span><span class="p">:</span> <span class="n">ExtractedFields</span><span class="p">,</span>
    <span class="n">judge</span><span class="p">:</span> <span class="n">Judge</span><span class="p">,</span>
    <span class="n">scorer_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validate that all required fields for a scorer are present.</span>

<span class="sd">    Args:</span>
<span class="sd">        fields: Extracted fields containing inputs, outputs, and expectations.</span>
<span class="sd">        judge: Judge instance to determine which fields are required.</span>
<span class="sd">        scorer_name: Name of the scorer for error messages.</span>

<span class="sd">    Raises:</span>
<span class="sd">        MlflowException: If any required fields are missing.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">required_fields</span> <span class="o">=</span> <span class="p">{</span><span class="n">field</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">judge</span><span class="o">.</span><span class="n">get_input_fields</span><span class="p">()}</span>
    <span class="n">missing_fields</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="s2">&quot;inputs&quot;</span> <span class="ow">in</span> <span class="n">required_fields</span> <span class="ow">and</span> <span class="n">fields</span><span class="o">.</span><span class="n">inputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">missing_fields</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;inputs&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;outputs&quot;</span> <span class="ow">in</span> <span class="n">required_fields</span> <span class="ow">and</span> <span class="n">fields</span><span class="o">.</span><span class="n">outputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">missing_fields</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;outputs&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;expectations&quot;</span> <span class="ow">in</span> <span class="n">required_fields</span> <span class="ow">and</span> <span class="n">fields</span><span class="o">.</span><span class="n">expectations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">missing_fields</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;expectations&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">missing_fields</span><span class="p">:</span>
        <span class="n">fields_str</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">missing_fields</span><span class="p">)</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scorer_name</span><span class="si">}</span><span class="s2"> requires the following fields: </span><span class="si">{</span><span class="n">fields_str</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="s2">&quot;Provide them directly or pass a trace containing them.&quot;</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">resolve_scorer_fields</span><span class="p">(</span>
    <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">judge</span><span class="p">:</span> <span class="n">Judge</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">expectations</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extract_expectations</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExtractedFields</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resolve scorer fields from provided values or extract from trace if needed.</span>

<span class="sd">    Args:</span>
<span class="sd">        trace: MLflow trace object containing the execution to evaluate.</span>
<span class="sd">        judge: Judge instance to determine which fields need extraction.</span>
<span class="sd">        inputs: Input data to evaluate. If None, will be extracted from trace.</span>
<span class="sd">        outputs: Output data to evaluate. If None, will be extracted from trace.</span>
<span class="sd">        expectations: Dictionary of expected outcomes. If None, will be extracted from trace.</span>
<span class="sd">        model: Model URI to use for LLM-based extraction if needed.</span>
<span class="sd">        extract_expectations: If True, extract expectations from trace.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ExtractedFields dataclass containing inputs, outputs, and expectations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">trace</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ExtractedFields</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">expectations</span><span class="o">=</span><span class="n">expectations</span><span class="p">)</span>

    <span class="n">inputs</span> <span class="o">=</span> <span class="n">resolve_inputs_from_trace</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">trace</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">resolve_outputs_from_trace</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">trace</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">extract_expectations</span><span class="p">:</span>
        <span class="n">expectations</span> <span class="o">=</span> <span class="n">resolve_expectations_from_trace</span><span class="p">(</span><span class="n">expectations</span><span class="p">,</span> <span class="n">trace</span><span class="p">)</span>

    <span class="n">input_field_names</span> <span class="o">=</span> <span class="p">{</span><span class="n">field</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">judge</span><span class="o">.</span><span class="n">get_input_fields</span><span class="p">()}</span>
    <span class="n">needs_inputs</span> <span class="o">=</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;inputs&quot;</span> <span class="ow">in</span> <span class="n">input_field_names</span>
    <span class="n">needs_outputs</span> <span class="o">=</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;outputs&quot;</span> <span class="ow">in</span> <span class="n">input_field_names</span>

    <span class="k">if</span> <span class="n">needs_inputs</span> <span class="ow">or</span> <span class="n">needs_outputs</span><span class="p">:</span>
        <span class="n">extraction_config</span> <span class="o">=</span> <span class="n">_construct_field_extraction_config</span><span class="p">(</span>
            <span class="n">needs_inputs</span><span class="o">=</span><span class="n">needs_inputs</span><span class="p">,</span>
            <span class="n">needs_outputs</span><span class="o">=</span><span class="n">needs_outputs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">extracted</span> <span class="o">=</span> <span class="n">get_chat_completions_with_structured_output</span><span class="p">(</span>
                <span class="n">model_uri</span><span class="o">=</span><span class="n">model</span> <span class="ow">or</span> <span class="n">get_default_model</span><span class="p">(),</span>
                <span class="n">messages</span><span class="o">=</span><span class="n">extraction_config</span><span class="o">.</span><span class="n">messages</span><span class="p">,</span>
                <span class="n">output_schema</span><span class="o">=</span><span class="n">extraction_config</span><span class="o">.</span><span class="n">schema</span><span class="p">,</span>
                <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">needs_inputs</span><span class="p">:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span> <span class="ow">or</span> <span class="n">extracted</span><span class="o">.</span><span class="n">inputs</span>
            <span class="k">if</span> <span class="n">needs_outputs</span><span class="p">:</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span> <span class="ow">or</span> <span class="n">extracted</span><span class="o">.</span><span class="n">outputs</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Failed to extract required fields from trace using LLM: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">e</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="n">ExtractedFields</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">expectations</span><span class="o">=</span><span class="n">expectations</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_sanitize_scorer_feedback</span><span class="p">(</span><span class="n">feedback</span><span class="p">:</span> <span class="n">Feedback</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sanitize feedback values from LLM judges to ensure YES/NO consistency.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">CategoricalRating</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">feedback</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">value_str</span> <span class="o">=</span> <span class="n">feedback</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">value_str</span> <span class="ow">in</span> <span class="n">_AFFIRMATIVE_VALUES</span><span class="p">:</span>
                <span class="n">feedback</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">CategoricalRating</span><span class="o">.</span><span class="n">YES</span>
            <span class="k">elif</span> <span class="n">value_str</span> <span class="ow">in</span> <span class="n">_NEGATIVE_VALUES</span><span class="p">:</span>
                <span class="n">feedback</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">CategoricalRating</span><span class="o">.</span><span class="n">NO</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">feedback</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">CategoricalRating</span><span class="p">(</span><span class="n">value_str</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">feedback</span>


<span class="k">class</span><span class="w"> </span><span class="nc">BuiltInScorer</span><span class="p">(</span><span class="n">Judge</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract base class for built-in scorers that share a common implementation.</span>
<span class="sd">    All built-in scorers should inherit from this class.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">required_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instructions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the instructions of what this scorer evaluates.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">model_dump</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Override model_dump to handle builtin scorer serialization.&quot;&quot;&quot;</span>
        <span class="n">pydantic_model_data</span> <span class="o">=</span> <span class="n">pydantic</span><span class="o">.</span><span class="n">BaseModel</span><span class="o">.</span><span class="n">model_dump</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">pydantic_model_data</span><span class="p">[</span><span class="s2">&quot;instructions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instructions</span>

        <span class="n">serialized</span> <span class="o">=</span> <span class="n">SerializedScorer</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">aggregations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">aggregations</span><span class="p">,</span>
            <span class="n">mlflow_version</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
            <span class="n">serialization_version</span><span class="o">=</span><span class="n">_SERIALIZATION_VERSION</span><span class="p">,</span>
            <span class="n">builtin_scorer_class</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
            <span class="n">builtin_scorer_pydantic_data</span><span class="o">=</span><span class="n">pydantic_model_data</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">asdict</span><span class="p">(</span><span class="n">serialized</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">model_validate</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">SerializedScorer</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;BuiltInScorer&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Override model_validate to handle builtin scorer deserialization.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">builtin_scorers</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">SerializedScorer</span><span class="p">):</span>
            <span class="n">serialized</span> <span class="o">=</span> <span class="n">obj</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;builtin_scorer_class&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Invalid builtin scorer data: expected a dictionary with &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;&#39;builtin_scorer_class&#39; field, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="n">serialized</span> <span class="o">=</span> <span class="n">SerializedScorer</span><span class="p">(</span><span class="o">**</span><span class="n">obj</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Failed to parse serialized scorer data: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">scorer_class</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builtin_scorers</span><span class="p">,</span> <span class="n">serialized</span><span class="o">.</span><span class="n">builtin_scorer_class</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unknown builtin scorer class: </span><span class="si">{</span><span class="n">serialized</span><span class="o">.</span><span class="n">builtin_scorer_class</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">constructor_args</span> <span class="o">=</span> <span class="n">serialized</span><span class="o">.</span><span class="n">builtin_scorer_pydantic_data</span> <span class="ow">or</span> <span class="p">{}</span>

        <span class="k">return</span> <span class="n">scorer_class</span><span class="p">(</span><span class="o">**</span><span class="n">constructor_args</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">validate_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">missing_columns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">required_columns</span> <span class="o">-</span> <span class="n">columns</span>
        <span class="k">if</span> <span class="n">missing_columns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MissingColumnsException</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">missing_columns</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">kind</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScorerKind</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ScorerKind</span><span class="o">.</span><span class="n">BUILTIN</span>


<div class="viewcode-block" id="RetrievalRelevance"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.RetrievalRelevance">[docs]</a><span class="nd">@format_docstring</span><span class="p">(</span><span class="n">_MODEL_API_DOC</span><span class="p">)</span>
<span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">RetrievalRelevance</span><span class="p">(</span><span class="n">BuiltInScorer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retrieval relevance measures whether each chunk is relevant to the input request.</span>

<span class="sd">    You can invoke the scorer directly with a single input for testing, or pass it to</span>
<span class="sd">    `mlflow.genai.evaluate` for running full evaluation on a dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: The name of the scorer. Defaults to &quot;retrieval_relevance&quot;.</span>
<span class="sd">        model: {{ model }}</span>

<span class="sd">    Example (direct usage):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import RetrievalRelevance</span>

<span class="sd">        trace = mlflow.get_trace(&quot;&lt;your-trace-id&gt;&quot;)</span>
<span class="sd">        feedbacks = RetrievalRelevance(name=&quot;my_retrieval_relevance&quot;)(trace=trace)</span>
<span class="sd">        print(feedbacks)</span>

<span class="sd">    Example (with evaluate):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>

<span class="sd">        data = mlflow.search_traces(...)</span>
<span class="sd">        result = mlflow.genai.evaluate(data=data, scorers=[RetrievalRelevance()])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;retrieval_relevance&quot;</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">required_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span> <span class="s2">&quot;trace&quot;</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">/</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instructions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the instructions of what this scorer evaluates.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;Evaluates whether each retrieved context chunk is relevant to the input request.&quot;</span>

<div class="viewcode-block" id="RetrievalRelevance.get_input_fields"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.RetrievalRelevance.get_input_fields">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_input_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">JudgeField</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the input fields for the RetrievalRelevance judge.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of JudgeField objects defining the input fields based on the __call__ method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;trace&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;The trace of the model&#39;s execution. Must contains at least one span with &quot;</span>
                    <span class="s2">&quot;type `RETRIEVER`. MLflow will extract the retrieved context from that span. &quot;</span>
                    <span class="s2">&quot;If multiple spans are found, MLflow will use the **last** one.&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
        <span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate chunk relevance for each context chunk.</span>

<span class="sd">        Args:</span>
<span class="sd">            trace: The trace of the model&#39;s execution. Must contains at least one span with</span>
<span class="sd">                type `RETRIEVER`. MLflow will extract the retrieved context from that span.</span>
<span class="sd">                If multiple spans are found, MLflow will use the **last** one.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of assessments evaluating the relevance of each context chunk.</span>
<span class="sd">            If the number of retrievers is N and each retriever has M chunks, the list will</span>
<span class="sd">            contain N * (M + 1) assessments. Each retriever span will emit M assessments</span>
<span class="sd">            for the relevance of its chunks and 1 assessment for the average relevance of all</span>
<span class="sd">            chunks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">request</span> <span class="o">=</span> <span class="n">extract_request_from_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
        <span class="n">span_id_to_context</span> <span class="o">=</span> <span class="n">extract_retrieval_context_from_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>

        <span class="n">feedbacks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">span_id</span><span class="p">,</span> <span class="n">context</span> <span class="ow">in</span> <span class="n">span_id_to_context</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">feedbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_compute_span_relevance</span><span class="p">(</span><span class="n">span_id</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">context</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">feedbacks</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_span_relevance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">span_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">request</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">chunks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Feedback</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the relevance of retrieved context for one retriever span.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.prompts.retrieval_relevance</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_prompt</span>

        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">or</span> <span class="n">get_default_model</span><span class="p">()</span>

        <span class="n">chunk_feedbacks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">&quot;databricks&quot;</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">databricks.agents.evals.judges</span><span class="w"> </span><span class="kn">import</span> <span class="n">chunk_relevance</span>

            <span class="n">chunk_feedbacks</span> <span class="o">=</span> <span class="n">chunk_relevance</span><span class="p">(</span>
                <span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">,</span> <span class="n">retrieved_context</span><span class="o">=</span><span class="n">chunks</span><span class="p">,</span> <span class="n">assessment_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">get_prompt</span><span class="p">(</span><span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">chunk</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">])</span>
                <span class="n">feedback</span> <span class="o">=</span> <span class="n">invoke_judge_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">assessment_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                <span class="n">sanitized_feedback</span> <span class="o">=</span> <span class="n">_sanitize_scorer_feedback</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span>
                <span class="n">chunk_feedbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sanitized_feedback</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">feedback</span> <span class="ow">in</span> <span class="n">chunk_feedbacks</span><span class="p">:</span>
            <span class="n">feedback</span><span class="o">.</span><span class="n">span_id</span> <span class="o">=</span> <span class="n">span_id</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk_feedbacks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="n">average</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="s2">&quot;yes&quot;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">chunk_feedbacks</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk_feedbacks</span><span class="p">)</span>

        <span class="n">span_level_feedback</span> <span class="o">=</span> <span class="n">Feedback</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;/precision&quot;</span><span class="p">,</span>
            <span class="n">value</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
            <span class="n">source</span><span class="o">=</span><span class="n">chunk_feedbacks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">source</span><span class="p">,</span>
            <span class="n">span_id</span><span class="o">=</span><span class="n">span_id</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">span_level_feedback</span><span class="p">]</span> <span class="o">+</span> <span class="n">chunk_feedbacks</span></div>


<div class="viewcode-block" id="RetrievalSufficiency"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.RetrievalSufficiency">[docs]</a><span class="nd">@format_docstring</span><span class="p">(</span><span class="n">_MODEL_API_DOC</span><span class="p">)</span>
<span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">RetrievalSufficiency</span><span class="p">(</span><span class="n">BuiltInScorer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retrieval sufficiency evaluates whether the retrieved documents provide all necessary</span>
<span class="sd">    information to generate the expected response.</span>

<span class="sd">    You can invoke the scorer directly with a single input for testing, or pass it to</span>
<span class="sd">    `mlflow.genai.evaluate` for running full evaluation on a dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: The name of the scorer. Defaults to &quot;retrieval_sufficiency&quot;.</span>
<span class="sd">        model: {{ model }}</span>

<span class="sd">    Example (direct usage):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import RetrievalSufficiency</span>

<span class="sd">        trace = mlflow.get_trace(&quot;&lt;your-trace-id&gt;&quot;)</span>
<span class="sd">        feedback = RetrievalSufficiency(name=&quot;my_retrieval_sufficiency&quot;)(trace=trace)</span>
<span class="sd">        print(feedback)</span>

<span class="sd">    Example (with evaluate):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>

<span class="sd">        data = mlflow.search_traces(...)</span>
<span class="sd">        result = mlflow.genai.evaluate(data=data, scorers=[RetrievalSufficiency()])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;retrieval_sufficiency&quot;</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">required_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span> <span class="s2">&quot;trace&quot;</span><span class="p">}</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instructions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the instructions of what this scorer evaluates.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">CONTEXT_SUFFICIENCY_PROMPT_INSTRUCTIONS</span>

<div class="viewcode-block" id="RetrievalSufficiency.get_input_fields"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.RetrievalSufficiency.get_input_fields">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_input_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">JudgeField</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the input fields for the RetrievalSufficiency judge.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of JudgeField objects defining the input fields based on the __call__ method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;trace&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;The trace of the model&#39;s execution. Must contain at least one span with &quot;</span>
                    <span class="s2">&quot;type `RETRIEVER`. MLflow will extract the retrieved context from that span. &quot;</span>
                    <span class="s2">&quot;If multiple spans are found, MLflow will use the **last** one.&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;expectations&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;A dictionary of expectations for the response. This must contain either &quot;</span>
                    <span class="s2">&quot;`expected_response` or `expected_facts` key (optional).&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
        <span class="p">]</span></div>

<div class="viewcode-block" id="RetrievalSufficiency.validate_columns"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.RetrievalSufficiency.validate_columns">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">validate_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">validate_columns</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="s2">&quot;expectations/expected_response&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">columns</span>
            <span class="ow">and</span> <span class="s2">&quot;expectations/expected_facts&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">columns</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">MissingColumnsException</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="p">[</span><span class="s2">&quot;expectations/expected_response or expectations/expected_facts&quot;</span><span class="p">],</span>
            <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span><span class="p">,</span> <span class="n">expectations</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Feedback</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate context sufficiency based on retrieved documents.</span>

<span class="sd">        Args:</span>
<span class="sd">            trace: The trace of the model&#39;s execution. Must contains at least one span with</span>
<span class="sd">                type `RETRIEVER`. MLflow will extract the retrieved context from that span.</span>
<span class="sd">                If multiple spans are found, MLflow will use the **last** one.</span>
<span class="sd">            expectations: A dictionary of expectations for the response. Either `expected_facts` or</span>
<span class="sd">                `expected_response` key is required. Alternatively, you can pass a trace annotated</span>
<span class="sd">                with `expected_facts` or `expected_response` label(s) and omit this argument.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">request</span> <span class="o">=</span> <span class="n">extract_request_from_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
        <span class="n">span_id_to_context</span> <span class="o">=</span> <span class="n">extract_retrieval_context_from_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>

        <span class="n">expectations</span> <span class="o">=</span> <span class="n">expectations</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">expected_facts</span> <span class="o">=</span> <span class="n">expectations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;expected_facts&quot;</span><span class="p">)</span>
        <span class="n">expected_response</span> <span class="o">=</span> <span class="n">expectations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;expected_response&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">expected_facts</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">expected_response</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">assessment</span> <span class="ow">in</span> <span class="n">trace</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">assessments</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">assessment</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;expected_facts&quot;</span> <span class="ow">and</span> <span class="n">expected_facts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">expected_facts</span> <span class="o">=</span> <span class="n">assessment</span><span class="o">.</span><span class="n">value</span>
                <span class="k">if</span> <span class="n">assessment</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;expected_response&quot;</span> <span class="ow">and</span> <span class="n">expected_response</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">expected_response</span> <span class="o">=</span> <span class="n">assessment</span><span class="o">.</span><span class="n">value</span>

        <span class="n">feedbacks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">span_id</span><span class="p">,</span> <span class="n">context</span> <span class="ow">in</span> <span class="n">span_id_to_context</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">feedback</span> <span class="o">=</span> <span class="n">judges</span><span class="o">.</span><span class="n">is_context_sufficient</span><span class="p">(</span>
                <span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">,</span>
                <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">,</span>
                <span class="n">expected_response</span><span class="o">=</span><span class="n">expected_response</span><span class="p">,</span>
                <span class="n">expected_facts</span><span class="o">=</span><span class="n">expected_facts</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">feedback</span><span class="o">.</span><span class="n">span_id</span> <span class="o">=</span> <span class="n">span_id</span>
            <span class="n">feedbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">feedbacks</span></div>


<div class="viewcode-block" id="RetrievalGroundedness"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.RetrievalGroundedness">[docs]</a><span class="nd">@format_docstring</span><span class="p">(</span><span class="n">_MODEL_API_DOC</span><span class="p">)</span>
<span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">RetrievalGroundedness</span><span class="p">(</span><span class="n">BuiltInScorer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    RetrievalGroundedness assesses whether the agent&#39;s response is aligned with the information</span>
<span class="sd">    provided in the retrieved context.</span>

<span class="sd">    You can invoke the scorer directly with a single input for testing, or pass it to</span>
<span class="sd">    `mlflow.genai.evaluate` for running full evaluation on a dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: The name of the scorer. Defaults to &quot;retrieval_groundedness&quot;.</span>
<span class="sd">        model: {{ model }}</span>

<span class="sd">    Example (direct usage):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import RetrievalGroundedness</span>

<span class="sd">        trace = mlflow.get_trace(&quot;&lt;your-trace-id&gt;&quot;)</span>
<span class="sd">        feedback = RetrievalGroundedness(name=&quot;my_retrieval_groundedness&quot;)(trace=trace)</span>
<span class="sd">        print(feedback)</span>

<span class="sd">    Example (with evaluate):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>

<span class="sd">        data = mlflow.search_traces(...)</span>
<span class="sd">        result = mlflow.genai.evaluate(data=data, scorers=[RetrievalGroundedness()])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;retrieval_groundedness&quot;</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">required_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span> <span class="s2">&quot;trace&quot;</span><span class="p">}</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instructions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the instructions of what this scorer evaluates.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">GROUNDEDNESS_PROMPT_INSTRUCTIONS</span>

<div class="viewcode-block" id="RetrievalGroundedness.get_input_fields"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.RetrievalGroundedness.get_input_fields">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_input_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">JudgeField</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the input fields for the RetrievalGroundedness judge.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of JudgeField objects defining the input fields based on the __call__ method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;trace&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;The trace of the model&#39;s execution. Must contains at least one span with &quot;</span>
                    <span class="s2">&quot;type `RETRIEVER`. MLflow will extract the retrieved context from that span. &quot;</span>
                    <span class="s2">&quot;If multiple spans are found, MLflow will use the **last** one.&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
        <span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Feedback</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate groundedness of response against retrieved context.</span>

<span class="sd">        Args:</span>
<span class="sd">            trace: The trace of the model&#39;s execution. Must contains at least one span with</span>
<span class="sd">                type `RETRIEVER`. MLflow will extract the retrieved context from that span.</span>
<span class="sd">                If multiple spans are found, MLflow will use the **last** one.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An :py:class:`mlflow.entities.assessment.Feedback~` object with a boolean value</span>
<span class="sd">            indicating the groundedness of the response.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">request</span> <span class="o">=</span> <span class="n">extract_request_from_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">extract_response_from_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
        <span class="n">span_id_to_context</span> <span class="o">=</span> <span class="n">extract_retrieval_context_from_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
        <span class="n">feedbacks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">span_id</span><span class="p">,</span> <span class="n">context</span> <span class="ow">in</span> <span class="n">span_id_to_context</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">feedback</span> <span class="o">=</span> <span class="n">judges</span><span class="o">.</span><span class="n">is_grounded</span><span class="p">(</span>
                <span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">,</span>
                <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">,</span>
                <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">feedback</span><span class="o">.</span><span class="n">span_id</span> <span class="o">=</span> <span class="n">span_id</span>
            <span class="n">feedbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">feedbacks</span></div>


<div class="viewcode-block" id="Guidelines"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.Guidelines">[docs]</a><span class="nd">@format_docstring</span><span class="p">(</span><span class="n">_MODEL_API_DOC</span><span class="p">)</span>
<span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Guidelines</span><span class="p">(</span><span class="n">BuiltInScorer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Guideline adherence evaluates whether the agent&#39;s response follows specific constraints</span>
<span class="sd">    or instructions provided in the guidelines.</span>

<span class="sd">    You can invoke the scorer directly with a single input for testing, or pass it to</span>
<span class="sd">    `mlflow.genai.evaluate` for running full evaluation on a dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: The name of the scorer. Defaults to &quot;guidelines&quot;.</span>
<span class="sd">        guidelines: A single guideline text or a list of guidelines.</span>
<span class="sd">        model: {{ model }}</span>

<span class="sd">    Example (direct usage):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Guidelines</span>

<span class="sd">        english = Guidelines(</span>
<span class="sd">            name=&quot;english_guidelines&quot;,</span>
<span class="sd">            guidelines=[&quot;The response must be in English&quot;],</span>
<span class="sd">        )</span>
<span class="sd">        feedback = english(</span>
<span class="sd">            inputs={&quot;question&quot;: &quot;What is the capital of France?&quot;},</span>
<span class="sd">            outputs=&quot;The capital of France is Paris.&quot;,</span>
<span class="sd">        )</span>
<span class="sd">        print(feedback)</span>

<span class="sd">    Example (with evaluate):</span>

<span class="sd">    In the following example, the guidelines specified in the `english` and `clarify` scorers</span>
<span class="sd">    will be uniformly applied to all the examples in the dataset. The evaluation result will</span>
<span class="sd">    contains two scores &quot;english&quot; and &quot;clarify&quot;.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Guidelines</span>

<span class="sd">        english = Guidelines(</span>
<span class="sd">            name=&quot;english&quot;,</span>
<span class="sd">            guidelines=[&quot;The response must be in English&quot;],</span>
<span class="sd">        )</span>
<span class="sd">        clarify = Guidelines(</span>
<span class="sd">            name=&quot;clarify&quot;,</span>
<span class="sd">            guidelines=[&quot;The response must be clear, coherent, and concise&quot;],</span>
<span class="sd">        )</span>

<span class="sd">        data = [</span>
<span class="sd">            {</span>
<span class="sd">                &quot;inputs&quot;: {&quot;question&quot;: &quot;What is the capital of France?&quot;},</span>
<span class="sd">                &quot;outputs&quot;: &quot;The capital of France is Paris.&quot;,</span>
<span class="sd">            },</span>
<span class="sd">            {</span>
<span class="sd">                &quot;inputs&quot;: {&quot;question&quot;: &quot;What is the capital of Germany?&quot;},</span>
<span class="sd">                &quot;outputs&quot;: &quot;The capital of Germany is Berlin.&quot;,</span>
<span class="sd">            },</span>
<span class="sd">        ]</span>
<span class="sd">        mlflow.genai.evaluate(data=data, scorers=[english, clarify])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;guidelines&quot;</span>
    <span class="n">guidelines</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">required_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span> <span class="s2">&quot;outputs&quot;</span><span class="p">}</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instructions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the instructions of what this scorer evaluates.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">GUIDELINES_PROMPT_INSTRUCTIONS</span>

<div class="viewcode-block" id="Guidelines.get_input_fields"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.Guidelines.get_input_fields">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_input_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">JudgeField</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the input fields for the Guidelines judge.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of JudgeField objects defining the input fields based on the __call__ method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;A dictionary of input data, e.g. &quot;</span>
                    <span class="s2">&quot;{&#39;question&#39;: &#39;What is the capital of France?&#39;}.&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;outputs&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The response from the model, e.g. &#39;The capital of France is Paris.&#39;&quot;</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate adherence to specified guidelines.</span>

<span class="sd">        This scorer can be used in two ways:</span>
<span class="sd">        1. Pass an MLflow trace object to automatically extract</span>
<span class="sd">           and evaluate the inputs and outputs from the trace.</span>
<span class="sd">        2. Directly provide the inputs and outputs to evaluate.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: A dictionary of input data, e.g. {&quot;question&quot;: &quot;What is the capital of France?&quot;}.</span>
<span class="sd">                Optional when trace is provided.</span>
<span class="sd">            outputs: The response from the model, e.g. &quot;The capital of France is Paris.&quot;</span>
<span class="sd">                Optional when trace is provided.</span>
<span class="sd">            trace: MLflow trace object containing the execution to evaluate. When provided,</span>
<span class="sd">                inputs and outputs will be automatically extracted from the trace.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An :py:class:`mlflow.entities.assessment.Feedback~` object with a boolean value</span>
<span class="sd">            indicating the adherence to the specified guidelines.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">resolve_scorer_fields</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">_validate_required_fields</span><span class="p">(</span><span class="n">fields</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;Guidelines scorer&quot;</span><span class="p">)</span>

        <span class="n">feedback</span> <span class="o">=</span> <span class="n">judges</span><span class="o">.</span><span class="n">meets_guidelines</span><span class="p">(</span>
            <span class="n">guidelines</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">guidelines</span><span class="p">,</span>
            <span class="n">context</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;request&quot;</span><span class="p">:</span> <span class="n">parse_inputs_to_str</span><span class="p">(</span><span class="n">fields</span><span class="o">.</span><span class="n">inputs</span><span class="p">),</span>
                <span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="n">parse_outputs_to_str</span><span class="p">(</span><span class="n">fields</span><span class="o">.</span><span class="n">outputs</span><span class="p">),</span>
            <span class="p">},</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">_sanitize_scorer_feedback</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span></div>


<div class="viewcode-block" id="ExpectationsGuidelines"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.ExpectationsGuidelines">[docs]</a><span class="nd">@format_docstring</span><span class="p">(</span><span class="n">_MODEL_API_DOC</span><span class="p">)</span>
<span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ExpectationsGuidelines</span><span class="p">(</span><span class="n">BuiltInScorer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This scorer evaluates whether the agent&#39;s response follows specific constraints</span>
<span class="sd">    or instructions provided for each row in the input dataset. This scorer is useful when</span>
<span class="sd">    you have a different set of guidelines for each example.</span>

<span class="sd">    To use this scorer, the input dataset should contain the `expectations` column with the</span>
<span class="sd">    `guidelines` field. Then pass this scorer to `mlflow.genai.evaluate` for running full</span>
<span class="sd">    evaluation on the input dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: The name of the scorer. Defaults to &quot;expectations_guidelines&quot;.</span>
<span class="sd">        model: {{ model }}</span>

<span class="sd">    Example:</span>

<span class="sd">    In this example, the guidelines specified in the `guidelines` field of the `expectations`</span>
<span class="sd">    column will be applied to each example individually. The evaluation result will contain a</span>
<span class="sd">    single &quot;expectations_guidelines&quot; score.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import ExpectationsGuidelines</span>

<span class="sd">        data = [</span>
<span class="sd">            {</span>
<span class="sd">                &quot;inputs&quot;: {&quot;question&quot;: &quot;What is the capital of France?&quot;},</span>
<span class="sd">                &quot;outputs&quot;: &quot;The capital of France is Paris.&quot;,</span>
<span class="sd">                &quot;expectations&quot;: {</span>
<span class="sd">                    &quot;guidelines&quot;: [&quot;The response must be factual and concise&quot;],</span>
<span class="sd">                },</span>
<span class="sd">            },</span>
<span class="sd">            {</span>
<span class="sd">                &quot;inputs&quot;: {&quot;question&quot;: &quot;How to learn Python?&quot;},</span>
<span class="sd">                &quot;outputs&quot;: &quot;You can read a book or take a course.&quot;,</span>
<span class="sd">                &quot;expectations&quot;: {</span>
<span class="sd">                    &quot;guidelines&quot;: [&quot;The response must be helpful and encouraging&quot;],</span>
<span class="sd">                },</span>
<span class="sd">            },</span>
<span class="sd">        ]</span>
<span class="sd">        mlflow.genai.evaluate(data=data, scorers=[ExpectationsGuidelines()])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;expectations_guidelines&quot;</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">required_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span> <span class="s2">&quot;outputs&quot;</span><span class="p">}</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instructions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the instructions of what this scorer evaluates.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;Evaluates adherence to per-example guidelines provided in the expectations column.&quot;</span>

<div class="viewcode-block" id="ExpectationsGuidelines.get_input_fields"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.ExpectationsGuidelines.get_input_fields">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_input_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">JudgeField</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the input fields for the ExpectationsGuidelines judge.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of JudgeField objects defining the input fields based on the __call__ method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;A dictionary of input data, e.g. &quot;</span>
                    <span class="s2">&quot;{&#39;question&#39;: &#39;What is the capital of France?&#39;}.&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;outputs&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The response from the model, e.g. &#39;The capital of France is Paris.&#39;&quot;</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;expectations&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;A dictionary containing guidelines for evaluation. &quot;</span>
                    <span class="s2">&quot;Must contain a &#39;guidelines&#39; key (optional).&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
        <span class="p">]</span></div>

<div class="viewcode-block" id="ExpectationsGuidelines.validate_columns"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.ExpectationsGuidelines.validate_columns">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">validate_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">validate_columns</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;expectations/guidelines&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MissingColumnsException</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;expectations/guidelines&quot;</span><span class="p">])</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">expectations</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate adherence to specified guidelines.</span>

<span class="sd">        This scorer can be used in two ways:</span>
<span class="sd">        1. Pass an MLflow trace object to automatically extract</span>
<span class="sd">           and evaluate inputs, outputs, and expectations from the trace.</span>
<span class="sd">        2. Directly provide the inputs, outputs, and expectations to evaluate.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: A dictionary of input data, e.g. {&quot;question&quot;: &quot;What is the capital of France?&quot;}.</span>
<span class="sd">                Optional when trace is provided.</span>
<span class="sd">            outputs: The response from the model, e.g. &quot;The capital of France is Paris.&quot;</span>
<span class="sd">                Optional when trace is provided.</span>
<span class="sd">            expectations: A dictionary of expectations for the response. This must contain either</span>
<span class="sd">                `guidelines` key, which is used to evaluate the response against the guidelines</span>
<span class="sd">                specified in the `guidelines` field of the `expectations` column of the dataset.</span>
<span class="sd">                E.g., {&quot;guidelines&quot;: [&quot;The response must be factual and concise&quot;]}</span>
<span class="sd">                Optional when trace is provided.</span>
<span class="sd">            trace: MLflow trace object containing the execution to evaluate. When provided,</span>
<span class="sd">                missing inputs, outputs, and expectations will be automatically extracted from</span>
<span class="sd">                the trace.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An :py:class:`mlflow.entities.assessment.Feedback~` object with a boolean value</span>
<span class="sd">            indicating the adherence to the specified guidelines.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">resolve_scorer_fields</span><span class="p">(</span>
            <span class="n">trace</span><span class="p">,</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">outputs</span><span class="p">,</span>
            <span class="n">expectations</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">extract_expectations</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_validate_required_fields</span><span class="p">(</span><span class="n">fields</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;ExpectationsGuidelines scorer&quot;</span><span class="p">)</span>

        <span class="n">guidelines</span> <span class="o">=</span> <span class="p">(</span><span class="n">fields</span><span class="o">.</span><span class="n">expectations</span> <span class="ow">or</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;guidelines&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">guidelines</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;Guidelines must be specified in the `expectations` parameter or &quot;</span>
                <span class="s2">&quot;must be present in the trace.&quot;</span>
            <span class="p">)</span>
        <span class="n">feedback</span> <span class="o">=</span> <span class="n">judges</span><span class="o">.</span><span class="n">meets_guidelines</span><span class="p">(</span>
            <span class="n">guidelines</span><span class="o">=</span><span class="n">guidelines</span><span class="p">,</span>
            <span class="n">context</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;request&quot;</span><span class="p">:</span> <span class="n">parse_inputs_to_str</span><span class="p">(</span><span class="n">fields</span><span class="o">.</span><span class="n">inputs</span><span class="p">),</span>
                <span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="n">parse_outputs_to_str</span><span class="p">(</span><span class="n">fields</span><span class="o">.</span><span class="n">outputs</span><span class="p">),</span>
            <span class="p">},</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">_sanitize_scorer_feedback</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span></div>


<div class="viewcode-block" id="RelevanceToQuery"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.RelevanceToQuery">[docs]</a><span class="nd">@format_docstring</span><span class="p">(</span><span class="n">_MODEL_API_DOC</span><span class="p">)</span>
<span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">RelevanceToQuery</span><span class="p">(</span><span class="n">BuiltInScorer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Relevance ensures that the agent&#39;s response directly addresses the user&#39;s input without</span>
<span class="sd">    deviating into unrelated topics.</span>

<span class="sd">    You can invoke the scorer directly with a single input for testing, or pass it to</span>
<span class="sd">    `mlflow.genai.evaluate` for running full evaluation on a dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: The name of the scorer. Defaults to &quot;relevance_to_query&quot;.</span>
<span class="sd">        model: {{ model }}</span>

<span class="sd">    Example (direct usage):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import RelevanceToQuery</span>

<span class="sd">        assessment = RelevanceToQuery(name=&quot;my_relevance_to_query&quot;)(</span>
<span class="sd">            inputs={&quot;question&quot;: &quot;What is the capital of France?&quot;},</span>
<span class="sd">            outputs=&quot;The capital of France is Paris.&quot;,</span>
<span class="sd">        )</span>
<span class="sd">        print(assessment)</span>

<span class="sd">    Example (with evaluate):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import RelevanceToQuery</span>

<span class="sd">        data = [</span>
<span class="sd">            {</span>
<span class="sd">                &quot;inputs&quot;: {&quot;question&quot;: &quot;What is the capital of France?&quot;},</span>
<span class="sd">                &quot;outputs&quot;: &quot;The capital of France is Paris.&quot;,</span>
<span class="sd">            }</span>
<span class="sd">        ]</span>
<span class="sd">        result = mlflow.genai.evaluate(data=data, scorers=[RelevanceToQuery()])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;relevance_to_query&quot;</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">required_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span> <span class="s2">&quot;outputs&quot;</span><span class="p">}</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instructions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the instructions of what this scorer evaluates.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">RELEVANCE_TO_QUERY_PROMPT_INSTRUCTIONS</span>

<div class="viewcode-block" id="RelevanceToQuery.get_input_fields"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.RelevanceToQuery.get_input_fields">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_input_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">JudgeField</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the input fields for the RelevanceToQuery judge.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of JudgeField objects defining the input fields based on the __call__ method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;A dictionary of input data, e.g. &quot;</span>
                    <span class="s2">&quot;{&#39;question&#39;: &#39;What is the capital of France?&#39;}.&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;outputs&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The response from the model, e.g. &#39;The capital of France is Paris.&#39;&quot;</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate relevance to the user&#39;s query.</span>

<span class="sd">        This scorer can be used in two ways:</span>
<span class="sd">        1. Pass an MLflow trace object to automatically extract</span>
<span class="sd">           and evaluate the inputs and outputs from the trace.</span>
<span class="sd">        2. Directly provide the inputs and outputs to evaluate.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: A dictionary of input data, e.g. {&quot;question&quot;: &quot;What is the capital of France?&quot;}.</span>
<span class="sd">                Optional when trace is provided.</span>
<span class="sd">            outputs: The response from the model, e.g. &quot;The capital of France is Paris.&quot;</span>
<span class="sd">                Optional when trace is provided.</span>
<span class="sd">            trace: MLflow trace object containing the execution to evaluate. When provided,</span>
<span class="sd">                inputs and outputs will be automatically extracted from the trace.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An :py:class:`mlflow.entities.assessment.Feedback~` object with a boolean value</span>
<span class="sd">            indicating the relevance of the response to the query.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">resolve_scorer_fields</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">_validate_required_fields</span><span class="p">(</span><span class="n">fields</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;RelevanceToQuery scorer&quot;</span><span class="p">)</span>

        <span class="c1"># Use the existing scorer implementation with extracted/provided fields</span>
        <span class="n">request</span> <span class="o">=</span> <span class="n">parse_inputs_to_str</span><span class="p">(</span><span class="n">fields</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">feedback</span> <span class="o">=</span> <span class="n">judges</span><span class="o">.</span><span class="n">is_context_relevant</span><span class="p">(</span>
            <span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">fields</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">_sanitize_scorer_feedback</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span></div>


<div class="viewcode-block" id="Safety"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.Safety">[docs]</a><span class="nd">@format_docstring</span><span class="p">(</span><span class="n">_MODEL_API_DOC</span><span class="p">)</span>
<span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Safety</span><span class="p">(</span><span class="n">BuiltInScorer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Safety ensures that the agent&#39;s responses do not contain harmful, offensive, or toxic content.</span>

<span class="sd">    You can invoke the scorer directly with a single input for testing, or pass it to</span>
<span class="sd">    `mlflow.genai.evaluate` for running full evaluation on a dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: The name of the scorer. Defaults to &quot;safety&quot;.</span>
<span class="sd">        model: {{ model }}</span>

<span class="sd">    Example (direct usage):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Safety</span>

<span class="sd">        assessment = Safety(name=&quot;my_safety&quot;)(outputs=&quot;The capital of France is Paris.&quot;)</span>
<span class="sd">        print(assessment)</span>

<span class="sd">    Example (with evaluate):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Safety</span>

<span class="sd">        data = [</span>
<span class="sd">            {</span>
<span class="sd">                &quot;inputs&quot;: {&quot;question&quot;: &quot;What is the capital of France?&quot;},</span>
<span class="sd">                &quot;outputs&quot;: &quot;The capital of France is Paris.&quot;,</span>
<span class="sd">            }</span>
<span class="sd">        ]</span>
<span class="sd">        result = mlflow.genai.evaluate(data=data, scorers=[Safety()])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;safety&quot;</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">required_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span> <span class="s2">&quot;outputs&quot;</span><span class="p">}</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instructions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the instructions of what this scorer evaluates.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;Ensures responses do not contain harmful, offensive, or toxic content.&quot;</span>

<div class="viewcode-block" id="Safety.get_input_fields"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.Safety.get_input_fields">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_input_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">JudgeField</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the input fields for the Safety judge.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of JudgeField objects defining the input fields based on the __call__ method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;outputs&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The response from the model, e.g. &#39;The capital of France is Paris.&#39;&quot;</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">/</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate safety of the response.</span>

<span class="sd">        This scorer can be used in two ways:</span>
<span class="sd">        1. Pass an MLflow trace object to automatically extract</span>
<span class="sd">           and evaluate the outputs from the trace.</span>
<span class="sd">        2. Directly provide the outputs to evaluate.</span>

<span class="sd">        Args:</span>
<span class="sd">            outputs: The response from the model, e.g. &quot;The capital of France is Paris.&quot;</span>
<span class="sd">                Optional when trace is provided.</span>
<span class="sd">            trace: MLflow trace object containing the execution to evaluate. When provided,</span>
<span class="sd">                outputs will be automatically extracted from the trace.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An :py:class:`mlflow.entities.assessment.Feedback~` object with a boolean value</span>
<span class="sd">            indicating the safety of the response.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">resolve_scorer_fields</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">_validate_required_fields</span><span class="p">(</span><span class="n">fields</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;Safety scorer&quot;</span><span class="p">)</span>

        <span class="n">feedback</span> <span class="o">=</span> <span class="n">judges</span><span class="o">.</span><span class="n">is_safe</span><span class="p">(</span>
            <span class="n">content</span><span class="o">=</span><span class="n">parse_outputs_to_str</span><span class="p">(</span><span class="n">fields</span><span class="o">.</span><span class="n">outputs</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">_sanitize_scorer_feedback</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span></div>


<div class="viewcode-block" id="Correctness"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.Correctness">[docs]</a><span class="nd">@format_docstring</span><span class="p">(</span><span class="n">_MODEL_API_DOC</span><span class="p">)</span>
<span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Correctness</span><span class="p">(</span><span class="n">BuiltInScorer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Correctness ensures that the agent&#39;s responses are correct and accurate.</span>

<span class="sd">    You can invoke the scorer directly with a single input for testing, or pass it to</span>
<span class="sd">    `mlflow.genai.evaluate` for running full evaluation on a dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: The name of the scorer. Defaults to &quot;correctness&quot;.</span>
<span class="sd">        model: {{ model }}</span>

<span class="sd">    Example (direct usage):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Correctness</span>

<span class="sd">        assessment = Correctness(name=&quot;my_correctness&quot;)(</span>
<span class="sd">            inputs={</span>
<span class="sd">                &quot;question&quot;: &quot;What is the difference between reduceByKey and groupByKey in Spark?&quot;</span>
<span class="sd">            },</span>
<span class="sd">            outputs=(</span>
<span class="sd">                &quot;reduceByKey aggregates data before shuffling, whereas groupByKey &quot;</span>
<span class="sd">                &quot;shuffles all data, making reduceByKey more efficient.&quot;</span>
<span class="sd">            ),</span>
<span class="sd">            expectations=[</span>
<span class="sd">                {&quot;expected_response&quot;: &quot;reduceByKey aggregates data before shuffling&quot;},</span>
<span class="sd">                {&quot;expected_response&quot;: &quot;groupByKey shuffles all data&quot;},</span>
<span class="sd">            ],</span>
<span class="sd">        )</span>
<span class="sd">        print(assessment)</span>

<span class="sd">    Example (with evaluate):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Correctness</span>

<span class="sd">        data = [</span>
<span class="sd">            {</span>
<span class="sd">                &quot;inputs&quot;: {</span>
<span class="sd">                    &quot;question&quot;: (</span>
<span class="sd">                        &quot;What is the difference between reduceByKey and groupByKey in Spark?&quot;</span>
<span class="sd">                    )</span>
<span class="sd">                },</span>
<span class="sd">                &quot;outputs&quot;: (</span>
<span class="sd">                    &quot;reduceByKey aggregates data before shuffling, whereas groupByKey &quot;</span>
<span class="sd">                    &quot;shuffles all data, making reduceByKey more efficient.&quot;</span>
<span class="sd">                ),</span>
<span class="sd">                &quot;expectations&quot;: {</span>
<span class="sd">                    &quot;expected_response&quot;: (</span>
<span class="sd">                        &quot;reduceByKey aggregates data before shuffling. &quot;</span>
<span class="sd">                        &quot;groupByKey shuffles all data&quot;</span>
<span class="sd">                    ),</span>
<span class="sd">                },</span>
<span class="sd">            }</span>
<span class="sd">        ]</span>
<span class="sd">        result = mlflow.genai.evaluate(data=data, scorers=[Correctness()])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;correctness&quot;</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">required_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span> <span class="s2">&quot;outputs&quot;</span><span class="p">}</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instructions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the instructions of what this scorer evaluates.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">CORRECTNESS_PROMPT_INSTRUCTIONS</span>

<div class="viewcode-block" id="Correctness.validate_columns"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.Correctness.validate_columns">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">validate_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">validate_columns</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="s2">&quot;expectations/expected_response&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">columns</span>
            <span class="ow">and</span> <span class="s2">&quot;expectations/expected_facts&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">columns</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">MissingColumnsException</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="p">[</span><span class="s2">&quot;expectations/expected_response or expectations/expected_facts&quot;</span><span class="p">],</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="Correctness.get_input_fields"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.Correctness.get_input_fields">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_input_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">JudgeField</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the input fields for the Correctness judge.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of JudgeField objects defining the input fields based on the __call__ method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;A dictionary of input data, e.g. &quot;</span>
                    <span class="s2">&quot;{&#39;question&#39;: &#39;What is the capital of France?&#39;}.&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;outputs&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The response from the model, e.g. &#39;The capital of France is Paris.&#39;&quot;</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;expectations&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;A dictionary of expectations for the response. This must contain either &quot;</span>
                    <span class="s2">&quot;`expected_response` or `expected_facts` key, which is used to evaluate the &quot;</span>
                    <span class="s2">&quot;response against the expected response or facts respectively. &quot;</span>
                    <span class="s2">&quot;E.g., {&#39;expected_facts&#39;: [&#39;Paris&#39;, &#39;France&#39;, &#39;Capital&#39;]}&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
        <span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">expectations</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate correctness of the response against expectations.</span>

<span class="sd">        This scorer can be used in two ways:</span>
<span class="sd">        1. Pass an MLflow trace object to automatically extract</span>
<span class="sd">           inputs, outputs, and expectations from the trace and its assessments.</span>
<span class="sd">        2. Directly provide inputs, outputs, and expectations to evaluate.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: A dictionary of input data, e.g. {&quot;question&quot;: &quot;What is the capital of France?&quot;}.</span>
<span class="sd">                Optional when trace is provided.</span>
<span class="sd">            outputs: The response from the model, e.g. &quot;The capital of France is Paris.&quot;</span>
<span class="sd">                Optional when trace is provided.</span>
<span class="sd">            expectations: A dictionary of expectations for the response. This must contain either</span>
<span class="sd">                `expected_response` or `expected_facts` key. Optional when trace is provided;</span>
<span class="sd">                will be extracted from trace&#39;s human assessment data if available.</span>
<span class="sd">            trace: MLflow trace object containing the execution to evaluate. When provided,</span>
<span class="sd">                inputs, outputs, and expectations will be automatically extracted from the trace.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An :py:class:`mlflow.entities.assessment.Feedback~` object with a boolean value</span>
<span class="sd">            indicating the correctness of the response.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">resolve_scorer_fields</span><span class="p">(</span>
            <span class="n">trace</span><span class="p">,</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">outputs</span><span class="p">,</span>
            <span class="n">expectations</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">extract_expectations</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_validate_required_fields</span><span class="p">(</span><span class="n">fields</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;Correctness scorer&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">fields</span><span class="o">.</span><span class="n">expectations</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="n">fields</span><span class="o">.</span><span class="n">expectations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;expected_response&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="n">fields</span><span class="o">.</span><span class="n">expectations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;expected_facts&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;Correctness scorer requires either `expected_response` or `expected_facts` &quot;</span>
                <span class="s2">&quot;in the `expectations` dictionary.&quot;</span>
            <span class="p">)</span>

        <span class="n">request</span> <span class="o">=</span> <span class="n">parse_inputs_to_str</span><span class="p">(</span><span class="n">fields</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">parse_outputs_to_str</span><span class="p">(</span><span class="n">fields</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">expected_facts</span> <span class="o">=</span> <span class="n">fields</span><span class="o">.</span><span class="n">expectations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;expected_facts&quot;</span><span class="p">)</span>
        <span class="n">expected_response</span> <span class="o">=</span> <span class="n">fields</span><span class="o">.</span><span class="n">expectations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;expected_response&quot;</span><span class="p">)</span>

        <span class="n">feedback</span> <span class="o">=</span> <span class="n">judges</span><span class="o">.</span><span class="n">is_correct</span><span class="p">(</span>
            <span class="n">request</span><span class="o">=</span><span class="n">request</span><span class="p">,</span>
            <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">,</span>
            <span class="n">expected_response</span><span class="o">=</span><span class="n">expected_response</span><span class="p">,</span>
            <span class="n">expected_facts</span><span class="o">=</span><span class="n">expected_facts</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">_sanitize_scorer_feedback</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span></div>


<div class="viewcode-block" id="Equivalence"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.Equivalence">[docs]</a><span class="nd">@format_docstring</span><span class="p">(</span><span class="n">_MODEL_API_DOC</span><span class="p">)</span>
<span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.5.0&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Equivalence</span><span class="p">(</span><span class="n">BuiltInScorer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Equivalence compares outputs against expected outputs for semantic equivalence.</span>

<span class="sd">    This scorer uses exact matching for numerical types (int, float, bool) and</span>
<span class="sd">    an LLM judge for text outputs to determine if they are semantically equivalent</span>
<span class="sd">    in both content and format.</span>

<span class="sd">    You can invoke the scorer directly with a single input for testing, or pass it to</span>
<span class="sd">    `mlflow.genai.evaluate` or `mlflow.genai.optimize_prompts` for evaluation.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: The name of the scorer. Defaults to &quot;equivalence&quot;.</span>
<span class="sd">        model: {{ model }}</span>

<span class="sd">    Example (direct usage):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Equivalence</span>

<span class="sd">        # Numerical equivalence</span>
<span class="sd">        assessment = Equivalence()(</span>
<span class="sd">            outputs=42,</span>
<span class="sd">            expectations={&quot;expected_response&quot;: 42},</span>
<span class="sd">        )</span>
<span class="sd">        print(assessment)  # value: ategoricalRating.YES, rationale: &#39;Exact numerical match&#39;</span>

<span class="sd">        # Text equivalence</span>
<span class="sd">        assessment = Equivalence()(</span>
<span class="sd">            outputs=&quot;The capital is Paris&quot;,</span>
<span class="sd">            expectations={&quot;expected_response&quot;: &quot;Paris is the capital&quot;},</span>
<span class="sd">        )</span>
<span class="sd">        print(assessment)  # value: CategoricalRating.YES (semantically equivalent)</span>

<span class="sd">    Example (with evaluate):</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Equivalence</span>

<span class="sd">        data = [</span>
<span class="sd">            {</span>
<span class="sd">                &quot;outputs&quot;: &quot;The capital is Paris&quot;,</span>
<span class="sd">                &quot;expectations&quot;: {&quot;expected_response&quot;: &quot;Paris&quot;},</span>
<span class="sd">            }</span>
<span class="sd">        ]</span>
<span class="sd">        result = mlflow.genai.evaluate(data=data, scorers=[Equivalence()])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;equivalence&quot;</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">required_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;outputs&quot;</span><span class="p">}</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instructions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the instructions of what this scorer evaluates.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">EQUIVALENCE_PROMPT_INSTRUCTIONS</span>

<div class="viewcode-block" id="Equivalence.validate_columns"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.Equivalence.validate_columns">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">validate_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">validate_columns</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;expectations/expected_response&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MissingColumnsException</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;expectations/expected_response&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="Equivalence.get_input_fields"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.Equivalence.get_input_fields">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_input_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">JudgeField</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the input fields for the Equivalence scorer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of JudgeField objects defining the input fields.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;outputs&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The actual output from the program to compare.&quot;</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">JudgeField</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;expectations&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="p">(</span>
                    <span class="s2">&quot;A dictionary containing the expected output. Must contain an &quot;</span>
                    <span class="s2">&quot;&#39;expected_response&#39; key with the expected value, e.g. &quot;</span>
                    <span class="s2">&quot;{&#39;expected_response&#39;: &#39;Paris&#39;}.&quot;</span>
                <span class="p">),</span>
            <span class="p">),</span>
        <span class="p">]</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">expectations</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate output equivalence.</span>

<span class="sd">        This scorer can be used in two ways:</span>
<span class="sd">        1. Pass an MLflow trace object to automatically extract</span>
<span class="sd">           outputs and expectations from the trace and its assessments.</span>
<span class="sd">        2. Directly provide outputs and expectations to evaluate.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: A dictionary of input data (optional, not used in evaluation).</span>
<span class="sd">            outputs: The actual output to compare. Optional when trace is provided.</span>
<span class="sd">            expectations: A dictionary containing the expected output. Must contain an</span>
<span class="sd">                &#39;expected_response&#39; key. Optional when trace is provided.</span>
<span class="sd">            trace: MLflow trace object containing the execution to evaluate. When provided,</span>
<span class="sd">                outputs and expectations will be automatically extracted from the trace.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Feedback object with &#39;yes&#39;/&#39;no&#39; value and rationale</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.builtin</span><span class="w"> </span><span class="kn">import</span> <span class="n">_sanitize_feedback</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.prompts.equivalence</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">EQUIVALENCE_FEEDBACK_NAME</span><span class="p">,</span>
            <span class="n">get_prompt</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Use resolve_scorer_fields to extract fields from trace if provided</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">resolve_scorer_fields</span><span class="p">(</span>
            <span class="n">trace</span><span class="p">,</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">outputs</span><span class="p">,</span>
            <span class="n">expectations</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">extract_expectations</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_validate_required_fields</span><span class="p">(</span><span class="n">fields</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;Equivalence scorer&quot;</span><span class="p">)</span>

        <span class="c1"># Validate that expected_response is present</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">fields</span><span class="o">.</span><span class="n">expectations</span> <span class="ow">or</span> <span class="n">fields</span><span class="o">.</span><span class="n">expectations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;expected_response&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;Equivalence scorer requires `expected_response` in the `expectations` dictionary.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Extract the expected response</span>
        <span class="n">expected_output</span> <span class="o">=</span> <span class="n">fields</span><span class="o">.</span><span class="n">expectations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;expected_response&quot;</span><span class="p">)</span>
        <span class="n">actual_output</span> <span class="o">=</span> <span class="n">fields</span><span class="o">.</span><span class="n">outputs</span>

        <span class="c1"># Handle exact match for numerical types</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">actual_output</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">expected_output</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">actual_output</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
                    <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                    <span class="n">value</span><span class="o">=</span><span class="n">CategoricalRating</span><span class="o">.</span><span class="n">YES</span><span class="p">,</span>
                    <span class="n">rationale</span><span class="o">=</span><span class="s2">&quot;Exact numerical match&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
                    <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                    <span class="n">value</span><span class="o">=</span><span class="n">CategoricalRating</span><span class="o">.</span><span class="n">NO</span><span class="p">,</span>
                    <span class="n">rationale</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Values do not match: </span><span class="si">{</span><span class="n">actual_output</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="n">expected_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># Convert to strings for comparison</span>
        <span class="n">outputs_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">actual_output</span><span class="p">)</span>
        <span class="n">expectations_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">expected_output</span><span class="p">)</span>

        <span class="c1"># Use exact match first</span>
        <span class="k">if</span> <span class="n">outputs_str</span> <span class="o">==</span> <span class="n">expectations_str</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="n">value</span><span class="o">=</span><span class="n">CategoricalRating</span><span class="o">.</span><span class="n">YES</span><span class="p">,</span>
                <span class="n">rationale</span><span class="o">=</span><span class="s2">&quot;Exact string match&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Use LLM judge for semantic equivalence</span>

        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">or</span> <span class="n">get_default_model</span><span class="p">()</span>
        <span class="n">assessment_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="ow">or</span> <span class="n">EQUIVALENCE_FEEDBACK_NAME</span>

        <span class="n">prompt</span> <span class="o">=</span> <span class="n">get_prompt</span><span class="p">(</span>
            <span class="n">output</span><span class="o">=</span><span class="n">outputs_str</span><span class="p">,</span>
            <span class="n">expected_output</span><span class="o">=</span><span class="n">expectations_str</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">feedback</span> <span class="o">=</span> <span class="n">invoke_judge_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">assessment_name</span><span class="o">=</span><span class="n">assessment_name</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">_sanitize_feedback</span><span class="p">(</span><span class="n">feedback</span><span class="p">)</span></div>


<div class="viewcode-block" id="get_all_scorers"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorers.get_all_scorers">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_all_scorers</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">BuiltInScorer</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a list of all built-in scorers.</span>

<span class="sd">    Example:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import get_all_scorers</span>

<span class="sd">        data = [</span>
<span class="sd">            {</span>
<span class="sd">                &quot;inputs&quot;: {&quot;question&quot;: &quot;What is the capital of France?&quot;},</span>
<span class="sd">                &quot;outputs&quot;: &quot;The capital of France is Paris.&quot;,</span>
<span class="sd">                &quot;expectations&quot;: {&quot;expected_response&quot;: &quot;Paris is the capital city of France.&quot;},</span>
<span class="sd">            }</span>
<span class="sd">        ]</span>
<span class="sd">        result = mlflow.genai.evaluate(data=data, scorers=get_all_scorers())</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">scorers</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">ExpectationsGuidelines</span><span class="p">(),</span>
        <span class="n">Correctness</span><span class="p">(),</span>
        <span class="n">RelevanceToQuery</span><span class="p">(),</span>
        <span class="n">RetrievalSufficiency</span><span class="p">(),</span>
        <span class="n">RetrievalGroundedness</span><span class="p">(),</span>
        <span class="n">Equivalence</span><span class="p">(),</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="n">is_databricks_uri</span><span class="p">(</span><span class="n">mlflow</span><span class="o">.</span><span class="n">get_tracking_uri</span><span class="p">()):</span>
        <span class="n">scorers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">Safety</span><span class="p">(),</span> <span class="n">RetrievalRelevance</span><span class="p">()])</span>
    <span class="k">return</span> <span class="n">scorers</span></div>


<span class="k">class</span><span class="w"> </span><span class="nc">MissingColumnsException</span><span class="p">(</span><span class="n">MlflowException</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scorer</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">missing_columns</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">scorer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">missing_columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">missing_columns</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The following columns are required for the scorer </span><span class="si">{</span><span class="n">scorer</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">missing_columns</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
</pre></div>

              </div>
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../../',
      VERSION:'3.5.0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>