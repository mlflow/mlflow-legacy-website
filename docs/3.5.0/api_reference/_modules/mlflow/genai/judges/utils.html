

<!DOCTYPE html>
<!-- source: docs/source/_modules/mlflow/genai/judges/utils -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.genai.judges.utils</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/_modules/mlflow/genai/judges/utils.html">
  
  
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
  

  

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    
  
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=AW-16857946923"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'AW-16857946923');
  </script>
  <!-- Eng gtag -->

  

  
  <meta name="docsearch:docusaurus_tag" content="default" data-rh="true">
  <meta name="docusaurus_tag" content="default" data-rh="true">
  <meta name="docusaurus_version" content="current" data-rh="true">
  <meta name="docsearch:version" content="current" data-rh="true">
  <meta name="docusaurus_locale" content="en" data-rh="true">
  <meta name="docsearch:language" content="en" data-rh="true">

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../../search.html"/>
    <link rel="top" title="MLflow 3.5.0 documentation" href="../../../../index.html"/>
        <link rel="up" title="Module code" href="../../../index.html"/> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../../_static/documentation_options.js"></script>
<script type="text/javascript" src="../../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../../_static/tabs.js"></script>
<script type="text/javascript" src="../../../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../../../../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <div class="header-container">
  <style scoped>
    .header-container {
      display: flex;
      flex-direction: row;
      align-items: center;
      justify-content: space-between;
      padding: 8px 16px;

      background-color: #fff;
      box-shadow: 0 1px 2px 0 #0000001a;
    }

    .logo-container {
      display: flex;
      gap: 12px;
      flex-direction: row;
      white-space: nowrap;
      align-items: center;
      justify-content: center;
    }

    a:hover {
      text-decoration: none;
      color: #0194e2;
    }
  </style>
  <div class="logo-container">
    <i
      data-toggle="wy-nav-top"
      class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"
    ></i>
    <a href="../../../../index.html" class="wy-nav-top-logo">
      <img
        src="../../../../_static/MLflow-logo-final-black.png"
        alt="MLflow"
      />
    </a>
    <a
      style="overflow: hidden; text-overflow: ellipsis"
      class="header-link"
      href="/docs/latest"
      >Main Docs</a
    >
    <span style="overflow: hidden; text-overflow: ellipsis" class="header-link"
      >API Documentation</span
    >
  </div>
  <span class="header-link version">3.5.0</span>
</div>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../../index.html">Home</a>
    

    
      

      
        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../typescript_api/index.html">TypeScript API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auth/python-api.html">MLflow Authentication Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auth/rest-api.html">MLflow Authentication REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../../index.html">Module code</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.genai.judges.utils</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/_modules/mlflow/genai/judges/utils" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <h1>Source code for mlflow.genai.judges.utils</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">threading</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">traceback</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">contextlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">ContextDecorator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">asdict</span><span class="p">,</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">is_dataclass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">NamedTuple</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">litellm</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">AlignmentOptimizer</span><span class="p">,</span> <span class="n">JudgeField</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.types.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatMessage</span><span class="p">,</span> <span class="n">ToolCall</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.assessment</span><span class="w"> </span><span class="kn">import</span> <span class="n">Feedback</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.assessment_source</span><span class="w"> </span><span class="kn">import</span> <span class="n">AssessmentSource</span><span class="p">,</span> <span class="n">AssessmentSourceType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.trace</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trace</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="n">MlflowException</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.constants</span><span class="w"> </span><span class="kn">import</span> <span class="n">_DATABRICKS_DEFAULT_JUDGE_MODEL</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.utils.enum_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrEnum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.protos.databricks_pb2</span><span class="w"> </span><span class="kn">import</span> <span class="n">BAD_REQUEST</span><span class="p">,</span> <span class="n">INVALID_PARAMETER_VALUE</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.telemetry.events</span><span class="w"> </span><span class="kn">import</span> <span class="n">InvokeCustomJudgeModelEvent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.telemetry.track</span><span class="w"> </span><span class="kn">import</span> <span class="n">record_usage_event</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.telemetry.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_is_in_databricks</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.uri</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_databricks_uri</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.version</span><span class="w"> </span><span class="kn">import</span> <span class="n">VERSION</span>

<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="c1"># &quot;endpoints&quot; is a special case for Databricks model serving endpoints.</span>
<span class="n">_NATIVE_PROVIDERS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;openai&quot;</span><span class="p">,</span> <span class="s2">&quot;anthropic&quot;</span><span class="p">,</span> <span class="s2">&quot;bedrock&quot;</span><span class="p">,</span> <span class="s2">&quot;mistral&quot;</span><span class="p">,</span> <span class="s2">&quot;endpoints&quot;</span><span class="p">]</span>
<span class="n">_LITELLM_PROVIDERS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;azure&quot;</span><span class="p">,</span> <span class="s2">&quot;vertexai&quot;</span><span class="p">,</span> <span class="s2">&quot;cohere&quot;</span><span class="p">,</span> <span class="s2">&quot;replicate&quot;</span><span class="p">,</span> <span class="s2">&quot;groq&quot;</span><span class="p">,</span> <span class="s2">&quot;together&quot;</span><span class="p">]</span>

<span class="c1"># Global cache to track model capabilities across function calls</span>
<span class="c1"># Key: model URI (e.g., &quot;openai/gpt-4&quot;), Value: boolean indicating response_format support</span>
<span class="n">_MODEL_RESPONSE_FORMAT_CAPABILITIES</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>


<span class="k">class</span><span class="w"> </span><span class="nc">DatabricksLLMJudgePrompts</span><span class="p">(</span><span class="n">NamedTuple</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Result of splitting ChatMessage list for Databricks API.&quot;&quot;&quot;</span>

    <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_databricks_agents_installed</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if databricks-agents is installed for databricks judge functionality.</span>

<span class="sd">    Raises:</span>
<span class="sd">        MlflowException: If databricks-agents is not installed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">databricks.agents.evals</span>  <span class="c1"># noqa: F401</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;To use &#39;</span><span class="si">{</span><span class="n">_DATABRICKS_DEFAULT_JUDGE_MODEL</span><span class="si">}</span><span class="s2">&#39; as the judge model, the Databricks &quot;</span>
            <span class="s2">&quot;agents library must be installed. Please install it with: &quot;</span>
            <span class="s2">&quot;`pip install databricks-agents`&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_default_model</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">is_databricks_uri</span><span class="p">(</span><span class="n">mlflow</span><span class="o">.</span><span class="n">get_tracking_uri</span><span class="p">()):</span>
        <span class="k">return</span> <span class="n">_DATABRICKS_DEFAULT_JUDGE_MODEL</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;openai:/gpt-4.1-mini&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_default_optimizer</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">AlignmentOptimizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the default alignment optimizer.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A SIMBA alignment optimizer with no model specified (uses default model).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.optimizers.simba</span><span class="w"> </span><span class="kn">import</span> <span class="n">SIMBAAlignmentOptimizer</span>

    <span class="k">return</span> <span class="n">SIMBAAlignmentOptimizer</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_is_litellm_available</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if LiteLLM is available for import.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">litellm</span>  <span class="c1"># noqa: F401</span>

        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">validate_judge_model</span><span class="p">(</span><span class="n">model_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validate that a judge model URI is valid and has required dependencies.</span>

<span class="sd">    This function performs early validation at judge construction time to provide</span>
<span class="sd">    fast feedback about configuration issues.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_uri: The model URI to validate (e.g., &quot;databricks&quot;, &quot;openai:/gpt-4&quot;)</span>

<span class="sd">    Raises:</span>
<span class="sd">        MlflowException: If the model URI is invalid or required dependencies are missing.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.metrics.genai.model_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_parse_model_uri</span>

    <span class="c1"># Special handling for Databricks default model</span>
    <span class="k">if</span> <span class="n">model_uri</span> <span class="o">==</span> <span class="n">_DATABRICKS_DEFAULT_JUDGE_MODEL</span><span class="p">:</span>
        <span class="c1"># Check if databricks-agents is available</span>
        <span class="n">_check_databricks_agents_installed</span><span class="p">()</span>
        <span class="k">return</span>

    <span class="c1"># Validate the URI format and extract provider</span>
    <span class="n">provider</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="n">_parse_model_uri</span><span class="p">(</span><span class="n">model_uri</span><span class="p">)</span>

    <span class="c1"># Check if LiteLLM is required and available for non-native providers</span>
    <span class="k">if</span> <span class="n">provider</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_NATIVE_PROVIDERS</span> <span class="ow">and</span> <span class="n">provider</span> <span class="ow">in</span> <span class="n">_LITELLM_PROVIDERS</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_litellm_available</span><span class="p">():</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;LiteLLM is required for using &#39;</span><span class="si">{</span><span class="n">provider</span><span class="si">}</span><span class="s2">&#39; as a provider. &quot;</span>
                <span class="s2">&quot;Please install it with: `pip install litellm`&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">format_prompt</span><span class="p">(</span><span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">values</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Format double-curly variables in the prompt template.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">values</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Escape backslashes in the replacement string to prevent re.sub from interpreting</span>
        <span class="c1"># them as escape sequences (e.g. \u being treated as Unicode escape)</span>
        <span class="n">replacement</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\\\\</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\{\{\s*&quot;</span> <span class="o">+</span> <span class="n">key</span> <span class="o">+</span> <span class="sa">r</span><span class="s2">&quot;\s*\}\}&quot;</span><span class="p">,</span> <span class="n">replacement</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prompt</span>


<span class="k">def</span><span class="w"> </span><span class="nf">add_output_format_instructions</span><span class="p">(</span><span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">output_fields</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;JudgeField&quot;</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Add structured output format instructions to a judge prompt.</span>

<span class="sd">    This ensures the LLM returns a JSON response with the expected fields,</span>
<span class="sd">    matching the expected format for the invoke_judge_model function.</span>

<span class="sd">    Args:</span>
<span class="sd">        prompt: The formatted prompt with template variables filled in</span>
<span class="sd">        output_fields: List of JudgeField objects defining output fields.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The prompt with output format instructions appended</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">json_format_lines</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">output_fields</span><span class="p">:</span>
        <span class="n">json_format_lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;    &quot;</span><span class="si">{</span><span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&quot;: &quot;</span><span class="si">{</span><span class="n">field</span><span class="o">.</span><span class="n">description</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">)</span>

    <span class="n">json_format</span> <span class="o">=</span> <span class="s2">&quot;{</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">json_format_lines</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">}&quot;</span>

    <span class="n">output_format_instructions</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>

<span class="s2">Please provide your assessment in the following JSON format only (no markdown):</span>

<span class="si">{</span><span class="n">json_format</span><span class="si">}</span><span class="s2">&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">prompt</span> <span class="o">+</span> <span class="n">output_format_instructions</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_sanitize_justification</span><span class="p">(</span><span class="n">justification</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="c1"># Some judge prompts instruct the model to think step by step.</span>
    <span class="k">return</span> <span class="n">justification</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;Let&#39;s think step by step. &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_split_messages_for_databricks</span><span class="p">(</span><span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;ChatMessage&quot;</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">DatabricksLLMJudgePrompts</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Split a list of ChatMessage objects into system and user prompts for Databricks API.</span>

<span class="sd">    Args:</span>
<span class="sd">        messages: List of ChatMessage objects to split.</span>

<span class="sd">    Returns:</span>
<span class="sd">        DatabricksLLMJudgePrompts namedtuple with system_prompt and user_prompt fields.</span>
<span class="sd">        The system_prompt may be None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        MlflowException: If the messages list is empty or invalid.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.types.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatMessage</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">messages</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;Invalid prompt format: expected non-empty list of ChatMessage&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">system_prompt</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">user_parts</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">ChatMessage</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">msg</span><span class="o">.</span><span class="n">role</span> <span class="o">==</span> <span class="s2">&quot;system&quot;</span><span class="p">:</span>
                <span class="c1"># Use the first system message as the actual system prompt for the API.</span>
                <span class="c1"># Any subsequent system messages are appended to the user prompt to preserve</span>
                <span class="c1"># their content and maintain the order in which they appear in the submitted</span>
                <span class="c1"># evaluation payload.</span>
                <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">system_prompt</span> <span class="o">=</span> <span class="n">msg</span><span class="o">.</span><span class="n">content</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">user_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;System: </span><span class="si">{</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">msg</span><span class="o">.</span><span class="n">role</span> <span class="o">==</span> <span class="s2">&quot;user&quot;</span><span class="p">:</span>
                <span class="n">user_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">msg</span><span class="o">.</span><span class="n">role</span> <span class="o">==</span> <span class="s2">&quot;assistant&quot;</span><span class="p">:</span>
                <span class="n">user_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Assistant: </span><span class="si">{</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">user_prompt</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">user_parts</span><span class="p">)</span> <span class="k">if</span> <span class="n">user_parts</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>

    <span class="k">return</span> <span class="n">DatabricksLLMJudgePrompts</span><span class="p">(</span><span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span> <span class="n">user_prompt</span><span class="o">=</span><span class="n">user_prompt</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_parse_databricks_judge_response</span><span class="p">(</span>
    <span class="n">llm_output</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">assessment_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse the response from Databricks judge into a Feedback object.</span>

<span class="sd">    Args:</span>
<span class="sd">        llm_output: Raw output from the LLM, or None if no response.</span>
<span class="sd">        assessment_name: Name of the assessment.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Feedback object with parsed results or error.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">AssessmentSource</span><span class="p">(</span>
        <span class="n">source_type</span><span class="o">=</span><span class="n">AssessmentSourceType</span><span class="o">.</span><span class="n">LLM_JUDGE</span><span class="p">,</span> <span class="n">source_id</span><span class="o">=</span><span class="n">_DATABRICKS_DEFAULT_JUDGE_MODEL</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">llm_output</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">assessment_name</span><span class="p">,</span>
            <span class="n">error</span><span class="o">=</span><span class="s2">&quot;Empty response from Databricks judge&quot;</span><span class="p">,</span>
            <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">llm_output</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">assessment_name</span><span class="p">,</span>
            <span class="n">error</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Invalid JSON response from Databricks judge: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;result&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">response_data</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">assessment_name</span><span class="p">,</span>
            <span class="n">error</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Response missing &#39;result&#39; field: </span><span class="si">{</span><span class="n">response_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">assessment_name</span><span class="p">,</span>
        <span class="n">value</span><span class="o">=</span><span class="n">response_data</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">],</span>
        <span class="n">rationale</span><span class="o">=</span><span class="n">response_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rationale&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">),</span>
        <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">call_chat_completions</span><span class="p">(</span><span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invokes the Databricks chat completions API using the databricks.agents.evals library.</span>

<span class="sd">    Args:</span>
<span class="sd">        user_prompt (str): The user prompt.</span>
<span class="sd">        system_prompt (str): The system prompt.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The chat completions result.</span>

<span class="sd">    Raises:</span>
<span class="sd">        MlflowException: If databricks-agents is not installed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_databricks_agents_installed</span><span class="p">()</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">databricks.rag_eval</span><span class="w"> </span><span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">env_vars</span>

    <span class="n">env_vars</span><span class="o">.</span><span class="n">RAG_EVAL_EVAL_SESSION_CLIENT_NAME</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mlflow-judge-optimizer-v</span><span class="si">{</span><span class="n">VERSION</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nd">@context</span><span class="o">.</span><span class="n">eval_context</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_call_chat_completions</span><span class="p">(</span><span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">managed_rag_client</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">get_context</span><span class="p">()</span><span class="o">.</span><span class="n">build_managed_rag_client</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">managed_rag_client</span><span class="o">.</span><span class="n">get_chat_completions_result</span><span class="p">(</span>
            <span class="n">user_prompt</span><span class="o">=</span><span class="n">user_prompt</span><span class="p">,</span>
            <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">_call_chat_completions</span><span class="p">(</span><span class="n">user_prompt</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_invoke_databricks_judge</span><span class="p">(</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;ChatMessage&quot;</span><span class="p">],</span>
    <span class="n">assessment_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invoke the Databricks judge using the databricks.agents.evals library.</span>

<span class="sd">    Uses the direct chat completions API for clean prompt submission without</span>
<span class="sd">    any additional formatting or template requirements.</span>

<span class="sd">    Args:</span>
<span class="sd">        prompt: The formatted prompt with template variables filled in.</span>
<span class="sd">        assessment_name: The name of the assessment.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Feedback object from the Databricks judge.</span>

<span class="sd">    Raises:</span>
<span class="sd">        MlflowException: If databricks-agents is not installed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">system_prompt</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">user_prompt</span> <span class="o">=</span> <span class="n">prompt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="n">_split_messages_for_databricks</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
            <span class="n">system_prompt</span> <span class="o">=</span> <span class="n">prompts</span><span class="o">.</span><span class="n">system_prompt</span>
            <span class="n">user_prompt</span> <span class="o">=</span> <span class="n">prompts</span><span class="o">.</span><span class="n">user_prompt</span>

        <span class="n">llm_result</span> <span class="o">=</span> <span class="n">call_chat_completions</span><span class="p">(</span><span class="n">user_prompt</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_parse_databricks_judge_response</span><span class="p">(</span><span class="n">llm_result</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">assessment_name</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to invoke Databricks judge: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Feedback</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">assessment_name</span><span class="p">,</span>
            <span class="n">error</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Failed to invoke Databricks judge: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">source</span><span class="o">=</span><span class="n">AssessmentSource</span><span class="p">(</span>
                <span class="n">source_type</span><span class="o">=</span><span class="n">AssessmentSourceType</span><span class="o">.</span><span class="n">LLM_JUDGE</span><span class="p">,</span>
                <span class="n">source_id</span><span class="o">=</span><span class="n">_DATABRICKS_DEFAULT_JUDGE_MODEL</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_invoke_via_gateway</span><span class="p">(</span>
    <span class="n">model_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">provider</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;ChatMessage&quot;</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invoke the judge model via native AI Gateway adapters.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_uri: The full model URI.</span>
<span class="sd">        provider: The provider name.</span>
<span class="sd">        messages: List of ChatMessage objects.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The JSON response string from the model.</span>

<span class="sd">    Raises:</span>
<span class="sd">        MlflowException: If the provider is not natively supported or invocation fails.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.metrics.genai.model_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_endpoint_type</span><span class="p">,</span> <span class="n">score_model_on_payload</span>

    <span class="k">if</span> <span class="n">provider</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_NATIVE_PROVIDERS</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;LiteLLM is required for using &#39;</span><span class="si">{</span><span class="n">provider</span><span class="si">}</span><span class="s2">&#39; LLM. Please install it with &quot;</span>
            <span class="s2">&quot;`pip install litellm`.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">score_model_on_payload</span><span class="p">(</span>
        <span class="n">model_uri</span><span class="o">=</span><span class="n">model_uri</span><span class="p">,</span>
        <span class="n">payload</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">}</span> <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">],</span>
        <span class="n">endpoint_type</span><span class="o">=</span><span class="n">get_endpoint_type</span><span class="p">(</span><span class="n">model_uri</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;llm/v1/chat&quot;</span><span class="p">,</span>
    <span class="p">)</span>


<span class="nd">@record_usage_event</span><span class="p">(</span><span class="n">InvokeCustomJudgeModelEvent</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">invoke_judge_model</span><span class="p">(</span>
    <span class="n">model_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;ChatMessage&quot;</span><span class="p">],</span>
    <span class="n">assessment_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_retries</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Feedback</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invoke the judge model.</span>

<span class="sd">    Routes to the appropriate implementation based on the model URI:</span>
<span class="sd">    - &quot;databricks&quot;: Uses databricks.agents.evals library for default judge,</span>
<span class="sd">                    direct API for regular endpoints</span>
<span class="sd">    - LiteLLM-supported providers: Uses LiteLLM if available</span>
<span class="sd">    - Native providers: Falls back to AI Gateway adapters</span>

<span class="sd">    Args:</span>
<span class="sd">        model_uri: The model URI.</span>
<span class="sd">        prompt: The prompt to evaluate. Can be a string (single prompt) or</span>
<span class="sd">                a list of ChatMessage objects.</span>
<span class="sd">        assessment_name: The name of the assessment.</span>
<span class="sd">        trace: Optional trace object for context.</span>
<span class="sd">        num_retries: Number of retries on transient failures when using litellm.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Feedback object with the judge&#39;s assessment.</span>

<span class="sd">    Raises:</span>
<span class="sd">        MlflowException: If the model cannot be invoked or dependencies are missing.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">model_uri</span> <span class="o">==</span> <span class="n">_DATABRICKS_DEFAULT_JUDGE_MODEL</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_invoke_databricks_judge</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">assessment_name</span><span class="p">)</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.metrics.genai.model_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_parse_model_uri</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.types.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatMessage</span>

    <span class="n">model_provider</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="n">_parse_model_uri</span><span class="p">(</span><span class="n">model_uri</span><span class="p">)</span>
    <span class="n">in_databricks</span> <span class="o">=</span> <span class="n">_is_in_databricks</span><span class="p">()</span>

    <span class="c1"># Handle Databricks endpoints (not the default judge) with proper telemetry</span>
    <span class="k">if</span> <span class="n">model_provider</span> <span class="o">==</span> <span class="s2">&quot;databricks&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">_invoke_judge_model</span><span class="p">(</span>
                <span class="n">model_uri</span><span class="o">=</span><span class="n">model_uri</span><span class="p">,</span>
                <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
                <span class="n">assessment_name</span><span class="o">=</span><span class="n">assessment_name</span><span class="p">,</span>
                <span class="n">num_retries</span><span class="o">=</span><span class="n">num_retries</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">feedback</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">feedback</span>

            <span class="c1"># Record success telemetry only when in Databricks</span>
            <span class="k">if</span> <span class="n">in_databricks</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">_record_judge_model_usage_success_databricks_telemetry</span><span class="p">(</span>
                        <span class="n">request_id</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">request_id</span><span class="p">,</span>
                        <span class="n">model_provider</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">model_provider</span><span class="p">,</span>
                        <span class="n">endpoint_name</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
                        <span class="n">num_prompt_tokens</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">num_prompt_tokens</span><span class="p">,</span>
                        <span class="n">num_completion_tokens</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">num_completion_tokens</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">telemetry_error</span><span class="p">:</span>
                    <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="s2">&quot;Failed to record judge model usage success telemetry. Error: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                        <span class="n">telemetry_error</span><span class="p">,</span>
                    <span class="p">)</span>

            <span class="k">return</span> <span class="n">feedback</span>

        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># Record failure telemetry only when in Databricks</span>
            <span class="k">if</span> <span class="n">in_databricks</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">_record_judge_model_usage_failure_databricks_telemetry</span><span class="p">(</span>
                        <span class="n">model_provider</span><span class="o">=</span><span class="n">model_provider</span><span class="p">,</span>
                        <span class="n">endpoint_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                        <span class="n">error_code</span><span class="o">=</span><span class="s2">&quot;UNKNOWN&quot;</span><span class="p">,</span>
                        <span class="n">error_message</span><span class="o">=</span><span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">(),</span>
                    <span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">telemetry_error</span><span class="p">:</span>
                    <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="s2">&quot;Failed to record judge model usage failure telemetry. Error: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                        <span class="n">telemetry_error</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="k">raise</span>

    <span class="c1"># Handle all other cases (including non-Databricks, ChatMessage prompts, traces)</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">ChatMessage</span><span class="p">(</span><span class="n">role</span><span class="o">=</span><span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">prompt</span><span class="p">)]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">prompt</span>

    <span class="k">if</span> <span class="n">_is_litellm_available</span><span class="p">():</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">_invoke_litellm</span><span class="p">(</span>
            <span class="n">provider</span><span class="o">=</span><span class="n">model_provider</span><span class="p">,</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
            <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">,</span>
            <span class="n">num_retries</span><span class="o">=</span><span class="n">num_retries</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">trace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;LiteLLM is required for using traces with judges. &quot;</span>
            <span class="s2">&quot;Please install it with `pip install litellm`.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">_invoke_via_gateway</span><span class="p">(</span><span class="n">model_uri</span><span class="p">,</span> <span class="n">model_provider</span><span class="p">,</span> <span class="n">messages</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">response_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Failed to parse response from judge model. Response: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

    <span class="n">feedback</span> <span class="o">=</span> <span class="n">Feedback</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">assessment_name</span><span class="p">,</span>
        <span class="n">value</span><span class="o">=</span><span class="n">response_dict</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">],</span>
        <span class="n">rationale</span><span class="o">=</span><span class="n">_sanitize_justification</span><span class="p">(</span><span class="n">response_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rationale&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)),</span>
        <span class="n">source</span><span class="o">=</span><span class="n">AssessmentSource</span><span class="p">(</span><span class="n">source_type</span><span class="o">=</span><span class="n">AssessmentSourceType</span><span class="o">.</span><span class="n">LLM_JUDGE</span><span class="p">,</span> <span class="n">source_id</span><span class="o">=</span><span class="n">model_uri</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;error&quot;</span> <span class="ow">in</span> <span class="n">response_dict</span><span class="p">:</span>
        <span class="n">feedback</span><span class="o">.</span><span class="n">error</span> <span class="o">=</span> <span class="n">response_dict</span><span class="p">[</span><span class="s2">&quot;error&quot;</span><span class="p">]</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Judge evaluation failed with error: </span><span class="si">{</span><span class="n">response_dict</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">feedback</span>


<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">InvokeDatabricksModelOutput</span><span class="p">:</span>
    <span class="n">response</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">request_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="n">num_prompt_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="n">num_completion_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_parse_databricks_model_response</span><span class="p">(</span>
    <span class="n">res_json</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">headers</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">InvokeDatabricksModelOutput</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse and validate the response from a Databricks model invocation.</span>

<span class="sd">    Args:</span>
<span class="sd">        res_json: The JSON response from the model</span>
<span class="sd">        headers: The response headers</span>

<span class="sd">    Returns:</span>
<span class="sd">        InvokeDatabricksModelOutput with parsed response data</span>

<span class="sd">    Raises:</span>
<span class="sd">        MlflowException: If the response structure is invalid</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Validate and extract choices</span>
    <span class="n">choices</span> <span class="o">=</span> <span class="n">res_json</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;choices&quot;</span><span class="p">,</span> <span class="p">[])</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">choices</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;Invalid response from Databricks model: missing &#39;choices&#39; field&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">first_choice</span> <span class="o">=</span> <span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="s2">&quot;message&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">first_choice</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;Invalid response from Databricks model: missing &#39;message&#39; field&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">content</span> <span class="o">=</span> <span class="n">first_choice</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;message&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;content&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">content</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;Invalid response from Databricks model: missing &#39;content&#39; field&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Handle reasoning response (list of content items)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">text_content</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">content</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="n">item</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;type&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span>
                <span class="n">text_content</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="n">text_content</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;Invalid reasoning response: no text content found in response list&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">text_content</span>

    <span class="n">usage</span> <span class="o">=</span> <span class="n">res_json</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;usage&quot;</span><span class="p">,</span> <span class="p">{})</span>

    <span class="k">return</span> <span class="n">InvokeDatabricksModelOutput</span><span class="p">(</span>
        <span class="n">response</span><span class="o">=</span><span class="n">content</span><span class="p">,</span>
        <span class="n">request_id</span><span class="o">=</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;x-request-id&quot;</span><span class="p">),</span>
        <span class="n">num_prompt_tokens</span><span class="o">=</span><span class="n">usage</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt_tokens&quot;</span><span class="p">),</span>
        <span class="n">num_completion_tokens</span><span class="o">=</span><span class="n">usage</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;completion_tokens&quot;</span><span class="p">),</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_invoke_databricks_model</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">num_retries</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">InvokeDatabricksModelOutput</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.databricks_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_databricks_host_creds</span>

    <span class="n">host_creds</span> <span class="o">=</span> <span class="n">get_databricks_host_creds</span><span class="p">()</span>
    <span class="n">api_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">host_creds</span><span class="o">.</span><span class="n">host</span><span class="si">}</span><span class="s2">/serving-endpoints/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">/invocations&quot;</span>

    <span class="c1"># Implement retry logic with exponential backoff</span>
    <span class="n">last_exception</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">attempt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_retries</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
                <span class="n">url</span><span class="o">=</span><span class="n">api_url</span><span class="p">,</span>
                <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Authorization&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Bearer </span><span class="si">{</span><span class="n">host_creds</span><span class="o">.</span><span class="n">token</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">},</span>
                <span class="n">json</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span>
                        <span class="p">{</span>
                            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                        <span class="p">}</span>
                    <span class="p">],</span>
                <span class="p">},</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">RequestException</span><span class="p">,</span> <span class="n">requests</span><span class="o">.</span><span class="n">ConnectionError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">last_exception</span> <span class="o">=</span> <span class="n">e</span>
            <span class="k">if</span> <span class="n">attempt</span> <span class="o">&lt;</span> <span class="n">num_retries</span><span class="p">:</span>
                <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request attempt </span><span class="si">{</span><span class="n">attempt</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> failed with error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="n">attempt</span><span class="p">)</span>  <span class="c1"># Exponential backoff</span>
                <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Failed to invoke Databricks model after </span><span class="si">{</span><span class="n">num_retries</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> attempts: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

        <span class="c1"># Check HTTP status before parsing JSON</span>
        <span class="k">if</span> <span class="n">res</span><span class="o">.</span><span class="n">status_code</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">400</span><span class="p">,</span> <span class="mi">401</span><span class="p">,</span> <span class="mi">403</span><span class="p">,</span> <span class="mi">404</span><span class="p">]:</span>
            <span class="c1"># Don&#39;t retry on bad request, unauthorized, not found, or forbidden</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Databricks model invocation failed with status </span><span class="si">{</span><span class="n">res</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">res</span><span class="o">.</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">res</span><span class="o">.</span><span class="n">status_code</span> <span class="o">&gt;=</span> <span class="mi">400</span><span class="p">:</span>
            <span class="c1"># For other errors, raise exception and potentially retry</span>
            <span class="n">error_msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Databricks model invocation failed with status </span><span class="si">{</span><span class="n">res</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">res</span><span class="o">.</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">attempt</span> <span class="o">&lt;</span> <span class="n">num_retries</span><span class="p">:</span>
                <span class="c1"># Log and retry for transient errors</span>
                <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Attempt </span><span class="si">{</span><span class="n">attempt</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> failed: </span><span class="si">{</span><span class="n">error_msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="n">attempt</span><span class="p">)</span>  <span class="c1"># Exponential backoff</span>
                <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span><span class="n">error_msg</span><span class="p">,</span> <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">)</span>

        <span class="c1"># Parse JSON response</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">res_json</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Failed to parse JSON response from Databricks model: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

        <span class="c1"># Parse and validate the response using helper function</span>
        <span class="k">return</span> <span class="n">_parse_databricks_model_response</span><span class="p">(</span><span class="n">res_json</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>

    <span class="c1"># This should not be reached, but just in case</span>
    <span class="k">if</span> <span class="n">last_exception</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Failed to invoke Databricks model: </span><span class="si">{</span><span class="n">last_exception</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">last_exception</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_record_judge_model_usage_success_databricks_telemetry</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">request_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_provider</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">endpoint_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">num_prompt_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_completion_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">databricks.agents.telemetry</span><span class="w"> </span><span class="kn">import</span> <span class="n">record_judge_model_usage_success</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;Failed to import databricks.agents.telemetry.record_judge_model_usage_success; &quot;</span>
            <span class="s2">&quot;databricks-agents needs to be installed.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracking.fluent</span><span class="w"> </span><span class="kn">import</span> <span class="n">_get_experiment_id</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.databricks_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_job_id</span><span class="p">,</span> <span class="n">get_job_run_id</span><span class="p">,</span> <span class="n">get_workspace_id</span>

    <span class="n">record_judge_model_usage_success</span><span class="p">(</span>
        <span class="n">request_id</span><span class="o">=</span><span class="n">request_id</span><span class="p">,</span>
        <span class="n">experiment_id</span><span class="o">=</span><span class="n">_get_experiment_id</span><span class="p">(),</span>
        <span class="n">job_id</span><span class="o">=</span><span class="n">get_job_id</span><span class="p">(),</span>
        <span class="n">job_run_id</span><span class="o">=</span><span class="n">get_job_run_id</span><span class="p">(),</span>
        <span class="n">workspace_id</span><span class="o">=</span><span class="n">get_workspace_id</span><span class="p">(),</span>
        <span class="n">model_provider</span><span class="o">=</span><span class="n">model_provider</span><span class="p">,</span>
        <span class="n">endpoint_name</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">,</span>
        <span class="n">num_prompt_tokens</span><span class="o">=</span><span class="n">num_prompt_tokens</span><span class="p">,</span>
        <span class="n">num_completion_tokens</span><span class="o">=</span><span class="n">num_completion_tokens</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_record_judge_model_usage_failure_databricks_telemetry</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">model_provider</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">endpoint_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">error_code</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">error_message</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">databricks.agents.telemetry</span><span class="w"> </span><span class="kn">import</span> <span class="n">record_judge_model_usage_failure</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;Failed to import databricks.agents.telemetry.record_judge_model_usage_success; &quot;</span>
            <span class="s2">&quot;databricks-agents needs to be installed.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracking.fluent</span><span class="w"> </span><span class="kn">import</span> <span class="n">_get_experiment_id</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.databricks_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_job_id</span><span class="p">,</span> <span class="n">get_job_run_id</span><span class="p">,</span> <span class="n">get_workspace_id</span>

    <span class="n">record_judge_model_usage_failure</span><span class="p">(</span>
        <span class="n">experiment_id</span><span class="o">=</span><span class="n">_get_experiment_id</span><span class="p">(),</span>
        <span class="n">job_id</span><span class="o">=</span><span class="n">get_job_id</span><span class="p">(),</span>
        <span class="n">job_run_id</span><span class="o">=</span><span class="n">get_job_run_id</span><span class="p">(),</span>
        <span class="n">workspace_id</span><span class="o">=</span><span class="n">get_workspace_id</span><span class="p">(),</span>
        <span class="n">model_provider</span><span class="o">=</span><span class="n">model_provider</span><span class="p">,</span>
        <span class="n">endpoint_name</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">,</span>
        <span class="n">error_code</span><span class="o">=</span><span class="n">error_code</span><span class="p">,</span>
        <span class="n">error_message</span><span class="o">=</span><span class="n">error_message</span><span class="p">,</span>
    <span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">InvokeJudgeModelHelperOutput</span><span class="p">:</span>
    <span class="n">feedback</span><span class="p">:</span> <span class="n">Feedback</span>
    <span class="n">model_provider</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">request_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="n">num_prompt_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="n">num_completion_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_invoke_judge_model</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">model_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">assessment_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">num_retries</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">InvokeJudgeModelHelperOutput</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.metrics.genai.model_utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
        <span class="n">_parse_model_uri</span><span class="p">,</span>
        <span class="n">get_endpoint_type</span><span class="p">,</span>
        <span class="n">score_model_on_payload</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">provider</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="n">_parse_model_uri</span><span class="p">(</span><span class="n">model_uri</span><span class="p">)</span>
    <span class="n">request_id</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">num_prompt_tokens</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">num_completion_tokens</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">provider</span> <span class="o">==</span> <span class="s2">&quot;databricks&quot;</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">_invoke_databricks_model</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">num_retries</span><span class="o">=</span><span class="n">num_retries</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">response</span>
        <span class="n">request_id</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">request_id</span>
        <span class="n">num_prompt_tokens</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">num_prompt_tokens</span>
        <span class="n">num_completion_tokens</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">num_completion_tokens</span>
    <span class="k">elif</span> <span class="n">_is_litellm_available</span><span class="p">():</span>
        <span class="c1"># prioritize litellm for better performance</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.types.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatMessage</span>

        <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">ChatMessage</span><span class="p">(</span><span class="n">role</span><span class="o">=</span><span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">prompt</span><span class="p">)]</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">_invoke_litellm</span><span class="p">(</span>
            <span class="n">provider</span><span class="o">=</span><span class="n">provider</span><span class="p">,</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
            <span class="n">trace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">num_retries</span><span class="o">=</span><span class="n">num_retries</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">provider</span> <span class="ow">in</span> <span class="n">_NATIVE_PROVIDERS</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">score_model_on_payload</span><span class="p">(</span>
            <span class="n">model_uri</span><span class="o">=</span><span class="n">model_uri</span><span class="p">,</span>
            <span class="n">payload</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">endpoint_type</span><span class="o">=</span><span class="n">get_endpoint_type</span><span class="p">(</span><span class="n">model_uri</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;llm/v1/chat&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;LiteLLM is required for using &#39;</span><span class="si">{</span><span class="n">provider</span><span class="si">}</span><span class="s2">&#39; LLM. Please install it with &quot;</span>
            <span class="s2">&quot;`pip install litellm`.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">response_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">feedback</span> <span class="o">=</span> <span class="n">Feedback</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">assessment_name</span><span class="p">,</span>
            <span class="n">value</span><span class="o">=</span><span class="n">response_dict</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">],</span>
            <span class="n">rationale</span><span class="o">=</span><span class="n">_sanitize_justification</span><span class="p">(</span><span class="n">response_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rationale&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)),</span>
            <span class="n">source</span><span class="o">=</span><span class="n">AssessmentSource</span><span class="p">(</span>
                <span class="n">source_type</span><span class="o">=</span><span class="n">AssessmentSourceType</span><span class="o">.</span><span class="n">LLM_JUDGE</span><span class="p">,</span>
                <span class="n">source_id</span><span class="o">=</span><span class="n">model_uri</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Failed to parse the response from the judge. Response: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

    <span class="k">return</span> <span class="n">InvokeJudgeModelHelperOutput</span><span class="p">(</span>
        <span class="n">feedback</span><span class="o">=</span><span class="n">feedback</span><span class="p">,</span>
        <span class="n">model_provider</span><span class="o">=</span><span class="n">provider</span><span class="p">,</span>
        <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
        <span class="n">request_id</span><span class="o">=</span><span class="n">request_id</span><span class="p">,</span>
        <span class="n">num_prompt_tokens</span><span class="o">=</span><span class="n">num_prompt_tokens</span><span class="p">,</span>
        <span class="n">num_completion_tokens</span><span class="o">=</span><span class="n">num_completion_tokens</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_SuppressLiteLLMNonfatalErrors</span><span class="p">(</span><span class="n">ContextDecorator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Thread-safe context manager and decorator to suppress LiteLLM&#39;s &quot;Give Feedback&quot; and</span>
<span class="sd">    &quot;Provider List&quot; messages. These messages indicate nonfatal bugs in the LiteLLM library;</span>
<span class="sd">    they are often noisy and can be safely ignored.</span>

<span class="sd">    Uses reference counting to ensure suppression remains active while any thread is running,</span>
<span class="sd">    preventing race conditions in parallel execution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lock</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">RLock</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">original_litellm_settings</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;_SuppressLiteLLMNonfatalErrors&quot;</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">litellm</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">lock</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># First caller - store original settings and enable suppression</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">original_litellm_settings</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;set_verbose&quot;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">litellm</span><span class="p">,</span> <span class="s2">&quot;set_verbose&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                    <span class="s2">&quot;suppress_debug_info&quot;</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">litellm</span><span class="p">,</span> <span class="s2">&quot;suppress_debug_info&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="p">}</span>
                <span class="n">litellm</span><span class="o">.</span><span class="n">set_verbose</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">litellm</span><span class="o">.</span><span class="n">suppress_debug_info</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__exit__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">_exc_type</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="ne">BaseException</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_exc_val</span><span class="p">:</span> <span class="ne">BaseException</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_exc_tb</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">litellm</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">lock</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Last caller - restore original settings</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">original_verbose</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_litellm_settings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;set_verbose&quot;</span><span class="p">)</span>
                <span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">litellm</span><span class="o">.</span><span class="n">set_verbose</span> <span class="o">=</span> <span class="n">original_verbose</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">original_suppress</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_litellm_settings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;suppress_debug_info&quot;</span><span class="p">)</span>
                <span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">litellm</span><span class="o">.</span><span class="n">suppress_debug_info</span> <span class="o">=</span> <span class="n">original_suppress</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">original_litellm_settings</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

        <span class="k">return</span> <span class="kc">False</span>


<span class="c1"># Global instance for use as threadsafe decorator</span>
<span class="n">_suppress_litellm_nonfatal_errors</span> <span class="o">=</span> <span class="n">_SuppressLiteLLMNonfatalErrors</span><span class="p">()</span>


<span class="nd">@_suppress_litellm_nonfatal_errors</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_invoke_litellm</span><span class="p">(</span>
    <span class="n">provider</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;ChatMessage&quot;</span><span class="p">],</span>
    <span class="n">trace</span><span class="p">:</span> <span class="n">Trace</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_retries</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invoke the judge via litellm with retry support.</span>

<span class="sd">    Args:</span>
<span class="sd">        provider: The provider name (e.g., &#39;openai&#39;, &#39;anthropic&#39;).</span>
<span class="sd">        model_name: The model name.</span>
<span class="sd">        messages: List of ChatMessage objects.</span>
<span class="sd">        trace: Optional trace object for context with tool calling support.</span>
<span class="sd">        num_retries: Number of retries with exponential backoff on transient failures.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The model&#39;s response content.</span>

<span class="sd">    Raises:</span>
<span class="sd">        MlflowException: If the request fails after all retries.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">litellm</span>

    <span class="c1"># Import at function level to avoid circular imports</span>
    <span class="c1"># (tools.registry imports from utils for invoke_judge_model)</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">list_judge_tools</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.tools.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">_judge_tool_registry</span>

    <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">litellm</span><span class="o">.</span><span class="n">Message</span><span class="p">(</span><span class="n">role</span><span class="o">=</span><span class="n">msg</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">)</span> <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">]</span>

    <span class="n">litellm_model_uri</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">provider</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">tools</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">trace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">judge_tools</span> <span class="o">=</span> <span class="n">list_judge_tools</span><span class="p">()</span>
        <span class="n">tools</span> <span class="o">=</span> <span class="p">[</span><span class="n">tool</span><span class="o">.</span><span class="n">get_definition</span><span class="p">()</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span> <span class="k">for</span> <span class="n">tool</span> <span class="ow">in</span> <span class="n">judge_tools</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_make_completion_request</span><span class="p">(</span><span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">litellm</span><span class="o">.</span><span class="n">Message</span><span class="p">],</span> <span class="n">include_response_format</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper to make litellm completion request with optional response_format.&quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">litellm_model_uri</span><span class="p">,</span>
            <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">,</span>
            <span class="s2">&quot;tools&quot;</span><span class="p">:</span> <span class="n">tools</span> <span class="k">if</span> <span class="n">tools</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;tool_choice&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span> <span class="k">if</span> <span class="n">tools</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;retry_policy&quot;</span><span class="p">:</span> <span class="n">_get_litellm_retry_policy</span><span class="p">(</span><span class="n">num_retries</span><span class="p">),</span>
            <span class="s2">&quot;retry_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;exponential_backoff_retry&quot;</span><span class="p">,</span>
            <span class="c1"># In LiteLLM version 1.55.3+, max_retries is stacked on top of retry_policy.</span>
            <span class="c1"># To avoid double-retry, we set max_retries=0</span>
            <span class="s2">&quot;max_retries&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="c1"># Drop any parameters that are known to be unsupported by the LLM.</span>
            <span class="c1"># This is important for compatibility with certain models that don&#39;t support</span>
            <span class="c1"># certain call parameters (e.g. GPT-4 doesn&#39;t support &#39;response_format&#39;)</span>
            <span class="s2">&quot;drop_params&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">include_response_format</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;response_format&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_get_judge_response_format</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">litellm</span><span class="o">.</span><span class="n">completion</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_prune_messages_for_context_window</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper to prune messages when context window is exceeded.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">max_context_length</span> <span class="o">=</span> <span class="n">litellm</span><span class="o">.</span><span class="n">get_max_tokens</span><span class="p">(</span><span class="n">litellm_model_uri</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># If the model is unknown to LiteLLM, fetching its max tokens may</span>
            <span class="c1"># result in an exception</span>
            <span class="n">max_context_length</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="n">_prune_messages_exceeding_context_window_length</span><span class="p">(</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="n">litellm_model_uri</span><span class="p">,</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_context_length</span> <span class="ow">or</span> <span class="mi">100000</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">include_response_format</span> <span class="o">=</span> <span class="n">_MODEL_RESPONSE_FORMAT_CAPABILITIES</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">litellm_model_uri</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">response</span> <span class="o">=</span> <span class="n">_make_completion_request</span><span class="p">(</span>
                    <span class="n">messages</span><span class="p">,</span> <span class="n">include_response_format</span><span class="o">=</span><span class="n">include_response_format</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="n">litellm</span><span class="o">.</span><span class="n">BadRequestError</span><span class="p">,</span> <span class="n">litellm</span><span class="o">.</span><span class="n">UnsupportedParamsError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">litellm</span><span class="o">.</span><span class="n">ContextWindowExceededError</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;context length&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                    <span class="c1"># Retry with pruned messages</span>
                    <span class="n">messages</span> <span class="o">=</span> <span class="n">_prune_messages_for_context_window</span><span class="p">()</span>
                    <span class="k">continue</span>
                <span class="c1"># Check whether the request attempted to use structured outputs, rather than</span>
                <span class="c1"># checking whether the model supports structured outputs in the capabilities cache,</span>
                <span class="c1"># since the capabilities cache may have been updated between the time that</span>
                <span class="c1"># include_response_format was set and the request was made</span>
                <span class="k">if</span> <span class="n">include_response_format</span><span class="p">:</span>
                    <span class="c1"># Retry without response_format if the request failed due to unsupported params.</span>
                    <span class="c1"># Some models don&#39;t support structured outputs (response_format) at all,</span>
                    <span class="c1"># and some models don&#39;t support both tool calling and structured outputs.</span>
                    <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">litellm_model_uri</span><span class="si">}</span><span class="s2"> may not support structured outputs or combined &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;tool calling + structured outputs. Error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Falling back to unstructured response.&quot;</span>
                    <span class="p">)</span>
                    <span class="c1"># Cache the lack of structured outputs support for future calls</span>
                    <span class="n">_MODEL_RESPONSE_FORMAT_CAPABILITIES</span><span class="p">[</span><span class="n">litellm_model_uri</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="c1"># Retry without response_format</span>
                    <span class="n">include_response_format</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">continue</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span>

            <span class="n">message</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">message</span><span class="o">.</span><span class="n">tool_calls</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span>

            <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
            <span class="c1"># TODO: Consider making tool calls concurrent for better performance.</span>
            <span class="c1"># Currently sequential for simplicity and to maintain order of results.</span>
            <span class="k">for</span> <span class="n">tool_call</span> <span class="ow">in</span> <span class="n">message</span><span class="o">.</span><span class="n">tool_calls</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">mlflow_tool_call</span> <span class="o">=</span> <span class="n">_create_mlflow_tool_call_from_litellm</span><span class="p">(</span>
                        <span class="n">litellm_tool_call</span><span class="o">=</span><span class="n">tool_call</span>
                    <span class="p">)</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">_judge_tool_registry</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">tool_call</span><span class="o">=</span><span class="n">mlflow_tool_call</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">_create_litellm_tool_response_message</span><span class="p">(</span>
                            <span class="n">tool_call_id</span><span class="o">=</span><span class="n">tool_call</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                            <span class="n">tool_name</span><span class="o">=</span><span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                            <span class="n">content</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="n">e</span><span class="si">!s}</span><span class="s2">&quot;</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Convert dataclass results to dict if needed</span>
                    <span class="c1"># The tool result is either a dict, string, or dataclass</span>
                    <span class="k">if</span> <span class="n">is_dataclass</span><span class="p">(</span><span class="n">result</span><span class="p">):</span>
                        <span class="n">result</span> <span class="o">=</span> <span class="n">asdict</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
                    <span class="n">result_json</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">result</span>
                    <span class="p">)</span>
                    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">_create_litellm_tool_response_message</span><span class="p">(</span>
                            <span class="n">tool_call_id</span><span class="o">=</span><span class="n">tool_call</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                            <span class="n">tool_name</span><span class="o">=</span><span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                            <span class="n">content</span><span class="o">=</span><span class="n">result_json</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to invoke the judge via litellm: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_create_mlflow_tool_call_from_litellm</span><span class="p">(</span>
    <span class="n">litellm_tool_call</span><span class="p">:</span> <span class="s2">&quot;litellm.ChatCompletionMessageToolCall&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ToolCall&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create an MLflow ToolCall from a LiteLLM tool call.</span>

<span class="sd">    Args:</span>
<span class="sd">        litellm_tool_call: The LiteLLM ChatCompletionMessageToolCall object.</span>

<span class="sd">    Returns:</span>
<span class="sd">        An MLflow ToolCall object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.types.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">ToolCall</span>

    <span class="k">return</span> <span class="n">ToolCall</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="n">litellm_tool_call</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
        <span class="n">function</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">litellm_tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s2">&quot;arguments&quot;</span><span class="p">:</span> <span class="n">litellm_tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_create_litellm_tool_response_message</span><span class="p">(</span>
    <span class="n">tool_call_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">tool_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">content</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;litellm.Message&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a tool response message for LiteLLM.</span>

<span class="sd">    Args:</span>
<span class="sd">        tool_call_id: The ID of the tool call being responded to.</span>
<span class="sd">        tool_name: The name of the tool that was invoked.</span>
<span class="sd">        content: The content to include in the response.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A litellm.Message object representing the tool response message.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">litellm</span>

    <span class="k">return</span> <span class="n">litellm</span><span class="o">.</span><span class="n">Message</span><span class="p">(</span>
        <span class="n">tool_call_id</span><span class="o">=</span><span class="n">tool_call_id</span><span class="p">,</span>
        <span class="n">role</span><span class="o">=</span><span class="s2">&quot;tool&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">tool_name</span><span class="p">,</span>
        <span class="n">content</span><span class="o">=</span><span class="n">content</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_get_judge_response_format</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the response format for judge evaluations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A dictionary containing the JSON schema for structured outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Import here to avoid circular imports</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.judges.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">Judge</span>

    <span class="n">output_fields</span> <span class="o">=</span> <span class="n">Judge</span><span class="o">.</span><span class="n">get_output_fields</span><span class="p">()</span>

    <span class="n">properties</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">required_fields</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">output_fields</span><span class="p">:</span>
        <span class="n">properties</span><span class="p">[</span><span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
            <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="n">field</span><span class="o">.</span><span class="n">description</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">required_fields</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;json_schema&quot;</span><span class="p">,</span>
        <span class="s2">&quot;json_schema&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;judge_evaluation&quot;</span><span class="p">,</span>
            <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;schema&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
                <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="n">properties</span><span class="p">,</span>
                <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="n">required_fields</span><span class="p">,</span>
                <span class="s2">&quot;additionalProperties&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">},</span>
    <span class="p">}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_prune_messages_exceeding_context_window_length</span><span class="p">(</span>
    <span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;litellm.Message&quot;</span><span class="p">],</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;litellm.Message&quot;</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prune messages from history to stay under token limit.</span>

<span class="sd">    Args:</span>
<span class="sd">        messages: List of LiteLLM message objects.</span>
<span class="sd">        model: Model name for token counting.</span>
<span class="sd">        max_tokens: Maximum token limit.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Pruned list of LiteLLM message objects under the token limit</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">litellm</span>

    <span class="n">initial_tokens</span> <span class="o">=</span> <span class="n">litellm</span><span class="o">.</span><span class="n">token_counter</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">initial_tokens</span> <span class="o">&lt;=</span> <span class="n">max_tokens</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">messages</span>

    <span class="n">pruned_messages</span> <span class="o">=</span> <span class="n">messages</span><span class="p">[:]</span>
    <span class="c1"># Remove tool call pairs until we&#39;re under limit</span>
    <span class="k">while</span> <span class="n">litellm</span><span class="o">.</span><span class="n">token_counter</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">messages</span><span class="o">=</span><span class="n">pruned_messages</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_tokens</span><span class="p">:</span>
        <span class="c1"># Find first assistant message with tool calls</span>
        <span class="n">assistant_msg</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">assistant_idx</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">msg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pruned_messages</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">msg</span><span class="o">.</span><span class="n">role</span> <span class="o">==</span> <span class="s2">&quot;assistant&quot;</span> <span class="ow">and</span> <span class="n">msg</span><span class="o">.</span><span class="n">tool_calls</span><span class="p">:</span>
                <span class="n">assistant_msg</span> <span class="o">=</span> <span class="n">msg</span>
                <span class="n">assistant_idx</span> <span class="o">=</span> <span class="n">i</span>
                <span class="k">break</span>
        <span class="k">if</span> <span class="n">assistant_msg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">break</span>  <span class="c1"># No more tool calls to remove</span>
        <span class="n">pruned_messages</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">assistant_idx</span><span class="p">)</span>
        <span class="c1"># Remove corresponding tool response messages</span>
        <span class="n">tool_call_ids</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">tc</span><span class="o">.</span><span class="n">id</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tc</span><span class="p">,</span> <span class="s2">&quot;id&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">tc</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">tc</span> <span class="ow">in</span> <span class="n">assistant_msg</span><span class="o">.</span><span class="n">tool_calls</span>
        <span class="p">}</span>
        <span class="n">pruned_messages</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">msg</span>
            <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">pruned_messages</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">role</span> <span class="o">==</span> <span class="s2">&quot;tool&quot;</span> <span class="ow">and</span> <span class="n">msg</span><span class="o">.</span><span class="n">tool_call_id</span> <span class="ow">in</span> <span class="n">tool_call_ids</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="n">final_tokens</span> <span class="o">=</span> <span class="n">litellm</span><span class="o">.</span><span class="n">token_counter</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">messages</span><span class="o">=</span><span class="n">pruned_messages</span><span class="p">)</span>
    <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pruned message history from </span><span class="si">{</span><span class="n">initial_tokens</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">final_tokens</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pruned_messages</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_get_litellm_retry_policy</span><span class="p">(</span><span class="n">num_retries</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get a LiteLLM retry policy for retrying requests when transient API errors occur.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_retries: The number of times to retry a request if it fails transiently due to</span>
<span class="sd">                     network error, rate limiting, etc. Requests are retried with exponential</span>
<span class="sd">                     backoff.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A LiteLLM RetryPolicy instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">litellm</span><span class="w"> </span><span class="kn">import</span> <span class="n">RetryPolicy</span>

    <span class="k">return</span> <span class="n">RetryPolicy</span><span class="p">(</span>
        <span class="n">TimeoutErrorRetries</span><span class="o">=</span><span class="n">num_retries</span><span class="p">,</span>
        <span class="n">RateLimitErrorRetries</span><span class="o">=</span><span class="n">num_retries</span><span class="p">,</span>
        <span class="n">InternalServerErrorRetries</span><span class="o">=</span><span class="n">num_retries</span><span class="p">,</span>
        <span class="n">ContentPolicyViolationErrorRetries</span><span class="o">=</span><span class="n">num_retries</span><span class="p">,</span>
        <span class="c1"># We don&#39;t retry on errors that are unlikely to be transient</span>
        <span class="c1"># (e.g. bad request, invalid auth credentials)</span>
        <span class="n">BadRequestErrorRetries</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">AuthenticationErrorRetries</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span>


<div class="viewcode-block" id="CategoricalRating"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.judges.CategoricalRating">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">CategoricalRating</span><span class="p">(</span><span class="n">StrEnum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A categorical rating for an assessment.</span>

<span class="sd">    Example:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            from mlflow.genai.judges import CategoricalRating</span>
<span class="sd">            from mlflow.entities import Feedback</span>

<span class="sd">            # Create feedback with categorical rating</span>
<span class="sd">            feedback = Feedback(</span>
<span class="sd">                name=&quot;my_metric&quot;, value=CategoricalRating.YES, rationale=&quot;The metric is passing.&quot;</span>
<span class="sd">            )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">YES</span> <span class="o">=</span> <span class="s2">&quot;yes&quot;</span>
    <span class="n">NO</span> <span class="o">=</span> <span class="s2">&quot;no&quot;</span>
    <span class="n">UNKNOWN</span> <span class="o">=</span> <span class="s2">&quot;unknown&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_missing_</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">member</span> <span class="ow">in</span> <span class="bp">cls</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">member</span> <span class="o">==</span> <span class="n">value</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">member</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">UNKNOWN</span></div>
</pre></div>

              </div>
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../../',
      VERSION:'3.5.0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>