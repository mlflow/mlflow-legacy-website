

<!DOCTYPE html>
<!-- source: docs/source/_modules/mlflow/genai/evaluation/base -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.genai.evaluation.base</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/_modules/mlflow/genai/evaluation/base.html">
  
  
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
  

  

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    
  
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=AW-16857946923"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'AW-16857946923');
  </script>
  <!-- Eng gtag -->

  

  
  <meta name="docsearch:docusaurus_tag" content="default" data-rh="true">
  <meta name="docusaurus_tag" content="default" data-rh="true">
  <meta name="docusaurus_version" content="current" data-rh="true">
  <meta name="docsearch:version" content="current" data-rh="true">
  <meta name="docusaurus_locale" content="en" data-rh="true">
  <meta name="docsearch:language" content="en" data-rh="true">

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../../search.html"/>
    <link rel="top" title="MLflow 3.3.0 documentation" href="../../../../index.html"/>
        <link rel="up" title="Module code" href="../../../index.html"/> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../../_static/documentation_options.js"></script>
<script type="text/javascript" src="../../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../../_static/tabs.js"></script>
<script type="text/javascript" src="../../../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../../../../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <div class="header-container">
  <style scoped>
    .header-container {
      display: flex;
      flex-direction: row;
      align-items: center;
      justify-content: space-between;
      padding: 8px 16px;

      background-color: #fff;
      box-shadow: 0 1px 2px 0 #0000001a;
    }

    .logo-container {
      display: flex;
      gap: 12px;
      flex-direction: row;
      white-space: nowrap;
      align-items: center;
      justify-content: center;
    }

    a:hover {
      text-decoration: none;
      color: #0194e2;
    }
  </style>
  <div class="logo-container">
    <i
      data-toggle="wy-nav-top"
      class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"
    ></i>
    <a href="../../../../index.html" class="wy-nav-top-logo">
      <img
        src="../../../../_static/MLflow-logo-final-black.png"
        alt="MLflow"
      />
    </a>
    <a
      style="overflow: hidden; text-overflow: ellipsis"
      class="header-link"
      href="/docs/latest"
      >Main Docs</a
    >
    <span style="overflow: hidden; text-overflow: ellipsis" class="header-link"
      >API Documentation</span
    >
  </div>
  <span class="header-link version">3.3.0</span>
</div>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../../index.html">Home</a>
    

    
      

      
        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../typescript_api/index.html">TypeScript API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auth/python-api.html">MLflow Authentication Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auth/rest-api.html">MLflow Authentication REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../../index.html">Module code</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.genai.evaluation.base</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/_modules/mlflow/genai/evaluation/base" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <h1>Source code for mlflow.genai.evaluation.base</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">contextlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.data.dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.dataset_input</span><span class="w"> </span><span class="kn">import</span> <span class="n">DatasetInput</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.logged_model_input</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoggedModelInput</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.environment_variables</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLFLOW_GENAI_EVAL_MAX_WORKERS</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="n">MlflowException</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">EvaluationDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.evaluation.constant</span><span class="w"> </span><span class="kn">import</span> <span class="n">InputDatasetColumn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.evaluation.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_convert_scorer_to_legacy_metric</span><span class="p">,</span>
    <span class="n">_convert_to_eval_set</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Scorer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers.builtin_scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">GENAI_CONFIG_NAME</span><span class="p">,</span> <span class="n">BuiltInScorer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.scorers.validation</span><span class="w"> </span><span class="kn">import</span> <span class="n">valid_data_for_builtin_scorers</span><span class="p">,</span> <span class="n">validate_scorers</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.utils.display_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">display_evaluation_output</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.utils.trace_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">clean_up_extra_traces</span><span class="p">,</span> <span class="n">convert_predict_fn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.models.evaluation.base</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">EvaluationResult</span><span class="p">,</span>
    <span class="n">_is_model_deployment_endpoint_uri</span><span class="p">,</span>
    <span class="n">_start_run_or_reuse_active_run</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.models.evaluation.utils.trace</span><span class="w"> </span><span class="kn">import</span> <span class="n">configure_autologging_for_evaluation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracing.constant</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">DATABRICKS_OPTIONS_KEY</span><span class="p">,</span>
    <span class="n">DATABRICKS_OUTPUT_KEY</span><span class="p">,</span>
    <span class="n">RETURN_TRACE_OPTION_KEY</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracing.utils.copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">copy_trace_to_experiment</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracking.client</span><span class="w"> </span><span class="kn">import</span> <span class="n">MlflowClient</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.tracking.fluent</span><span class="w"> </span><span class="kn">import</span> <span class="n">_set_active_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.annotations</span><span class="w"> </span><span class="kn">import</span> <span class="n">experimental</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.mlflow_tags</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLFLOW_RUN_IS_EVALUATION</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.uri</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_databricks_uri</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.evaluation.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">EvaluationDatasetTypes</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="evaluate"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.evaluate">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="s2">&quot;EvaluationDatasetTypes&quot;</span><span class="p">,</span>
    <span class="n">scorers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Scorer</span><span class="p">],</span>
    <span class="n">predict_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EvaluationResult</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the performance of a generative AI model/application using specified</span>
<span class="sd">    data and scorers.</span>

<span class="sd">    This function allows you to evaluate a model&#39;s performance on a given dataset</span>
<span class="sd">    using various scoring criteria. It supports both built-in scorers provided by</span>
<span class="sd">    MLflow and custom scorers. The evaluation results include metrics and detailed</span>
<span class="sd">    per-row assessments.</span>

<span class="sd">    There are three different ways to use this function:</span>

<span class="sd">    **1. Use Traces to evaluate the model/application.**</span>

<span class="sd">    The `data` parameter takes a DataFrame with `trace` column, which contains a</span>
<span class="sd">    single trace object corresponding to the prediction for the row. This dataframe</span>
<span class="sd">    is easily obtained from the existing traces stored in MLflow, by using the</span>
<span class="sd">    :py:func:`mlflow.search_traces` function.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Correctness, Safety</span>
<span class="sd">        import pandas as pd</span>

<span class="sd">        # model_id is a string starting with &quot;m-&quot;, e.g. &quot;m-074689226d3b40bfbbdf4c3ff35832cd&quot;</span>
<span class="sd">        trace_df = mlflow.search_traces(model_id=&quot;&lt;my-model-id&gt;&quot;)</span>

<span class="sd">        mlflow.genai.evaluate(</span>
<span class="sd">            data=trace_df,</span>
<span class="sd">            scorers=[Correctness(), Safety()],</span>
<span class="sd">        )</span>

<span class="sd">    Built-in scorers will understand the model inputs, outputs, and other intermediate</span>
<span class="sd">    information e.g. retrieved context, from the trace object. You can also access to</span>
<span class="sd">    the trace object from the custom scorer function by using the `trace` parameter.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        from mlflow.genai.scorers import scorer</span>


<span class="sd">        @scorer</span>
<span class="sd">        def faster_than_one_second(inputs, outputs, trace):</span>
<span class="sd">            return trace.info.execution_duration &lt; 1000</span>

<span class="sd">    **2. Use DataFrame or dictionary with &quot;inputs&quot;, &quot;outputs&quot;, &quot;expectations&quot; columns.**</span>

<span class="sd">    Alternatively, you can pass inputs, outputs, and expectations (ground truth) as</span>
<span class="sd">    a column in the dataframe (or equivalent list of dictionaries).</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Correctness</span>
<span class="sd">        import pandas as pd</span>

<span class="sd">        data = pd.DataFrame(</span>
<span class="sd">            [</span>
<span class="sd">                {</span>
<span class="sd">                    &quot;inputs&quot;: {&quot;question&quot;: &quot;What is MLflow?&quot;},</span>
<span class="sd">                    &quot;outputs&quot;: &quot;MLflow is an ML platform&quot;,</span>
<span class="sd">                    &quot;expectations&quot;: &quot;MLflow is an ML platform&quot;,</span>
<span class="sd">                },</span>
<span class="sd">                {</span>
<span class="sd">                    &quot;inputs&quot;: {&quot;question&quot;: &quot;What is Spark?&quot;},</span>
<span class="sd">                    &quot;outputs&quot;: &quot;I don&#39;t know&quot;,</span>
<span class="sd">                    &quot;expectations&quot;: &quot;Spark is a data engine&quot;,</span>
<span class="sd">                },</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>

<span class="sd">        mlflow.genai.evaluate(</span>
<span class="sd">            data=data,</span>
<span class="sd">            scorers=[Correctness()],</span>
<span class="sd">        )</span>

<span class="sd">    **3. Pass `predict_fn` and input samples (and optionally expectations).**</span>

<span class="sd">    If you want to generate the outputs and traces on-the-fly from your input samples,</span>
<span class="sd">    you can pass a callable to the `predict_fn` parameter. In this case, MLflow will</span>
<span class="sd">    pass the inputs to the `predict_fn` as keyword arguments. Therefore, the &quot;inputs&quot;</span>
<span class="sd">    column must be a dictionary with the parameter names as keys.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import mlflow</span>
<span class="sd">        from mlflow.genai.scorers import Correctness, Safety</span>
<span class="sd">        import openai</span>

<span class="sd">        # Create a dataframe with input samples</span>
<span class="sd">        data = pd.DataFrame(</span>
<span class="sd">            [</span>
<span class="sd">                {&quot;inputs&quot;: {&quot;question&quot;: &quot;What is MLflow?&quot;}},</span>
<span class="sd">                {&quot;inputs&quot;: {&quot;question&quot;: &quot;What is Spark?&quot;}},</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>


<span class="sd">        # Define a predict function to evaluate. The &quot;inputs&quot; column will be</span>
<span class="sd">        # passed to the prediction function as keyword arguments.</span>
<span class="sd">        def predict_fn(question: str) -&gt; str:</span>
<span class="sd">            response = openai.OpenAI().chat.completions.create(</span>
<span class="sd">                model=&quot;gpt-4o-mini&quot;,</span>
<span class="sd">                messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: question}],</span>
<span class="sd">            )</span>
<span class="sd">            return response.choices[0].message.content</span>


<span class="sd">        mlflow.genai.evaluate(</span>
<span class="sd">            data=data,</span>
<span class="sd">            predict_fn=predict_fn,</span>
<span class="sd">            scorers=[Correctness(), Safety()],</span>
<span class="sd">        )</span>

<span class="sd">    Args:</span>
<span class="sd">        data: Dataset for the evaluation. Must be one of the following formats:</span>

<span class="sd">            * An EvaluationDataset entity</span>
<span class="sd">            * Pandas DataFrame</span>
<span class="sd">            * Spark DataFrame</span>
<span class="sd">            * List of dictionaries</span>

<span class="sd">            The dataset must include either of the following columns:</span>

<span class="sd">            1. `trace` column that contains a single trace object corresponding</span>
<span class="sd">                to the prediction for the row.</span>

<span class="sd">                If this column is present, MLflow extracts inputs, outputs, assessments,</span>
<span class="sd">                and other intermediate information e.g. retrieved context, from the trace</span>
<span class="sd">                object and uses them for scoring. When this column is present, the</span>
<span class="sd">                `predict_fn` parameter must not be provided.</span>

<span class="sd">            2. `inputs`, `outputs`, `expectations` columns.</span>

<span class="sd">                Alternatively, you can pass inputs, outputs, and expectations(ground</span>
<span class="sd">                truth) as a column in the dataframe (or equivalent list of dictionaries).</span>

<span class="sd">                - inputs (required): Column containing inputs for evaluation. The value</span>
<span class="sd">                  must be a dictionary. When `predict_fn` is provided, MLflow will pass</span>
<span class="sd">                  the inputs to the `predict_fn` as keyword arguments. For example,</span>

<span class="sd">                  * predict_fn: `def predict_fn(question: str, context: str) -&gt; str`</span>
<span class="sd">                  * inputs: `{&quot;question&quot;: &quot;What is MLflow?&quot;, &quot;context&quot;: &quot;MLflow is an ML platform&quot;}`</span>
<span class="sd">                  * `predict_fn` will receive &quot;What is MLflow?&quot; as the first argument</span>
<span class="sd">                    (`question`) and &quot;MLflow is an ML platform&quot; as the second argument (`context`)</span>

<span class="sd">                - outputs (optional): Column containing model or app outputs.</span>
<span class="sd">                  If this column is present, `predict_fn` must not be provided.</span>

<span class="sd">                - expectations (optional): Column containing a dictionary of ground truths.</span>

<span class="sd">            For list of dictionaries, each dict should follow the above schema.</span>

<span class="sd">        scorers: A list of Scorer objects that produces evaluation scores from</span>
<span class="sd">            inputs, outputs, and other additional contexts. MLflow provides pre-defined</span>
<span class="sd">            scorers, but you can also define custom ones.</span>

<span class="sd">        predict_fn: The target function to be evaluated. The specified function will be</span>
<span class="sd">            executed for each row in the input dataset, and outputs will be used for</span>
<span class="sd">            scoring.</span>

<span class="sd">            The function must emit a single trace per call. If it doesn&#39;t, decorate</span>
<span class="sd">            the function with @mlflow.trace decorator to ensure a trace to be emitted.</span>

<span class="sd">        model_id: Optional model identifier (e.g. &quot;m-074689226d3b40bfbbdf4c3ff35832cd&quot;)</span>
<span class="sd">            to associate with the evaluation results. Can be also set globally via the</span>
<span class="sd">            :py:func:`mlflow.set_active_model` function.</span>

<span class="sd">    Returns:</span>
<span class="sd">        An :py:class:`mlflow.models.EvaluationResult~` object.</span>

<span class="sd">    Note:</span>
<span class="sd">        This function is only supported on Databricks. The tracking URI must be</span>
<span class="sd">        set to Databricks.</span>

<span class="sd">    .. warning::</span>

<span class="sd">        This function is not thread-safe. Please do not use it in multi-threaded</span>
<span class="sd">        environments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">is_managed_dataset</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">EvaluationDataset</span><span class="p">)</span>

    <span class="n">scorers</span> <span class="o">=</span> <span class="n">validate_scorers</span><span class="p">(</span><span class="n">scorers</span><span class="p">)</span>
    <span class="c1"># convert into a pandas dataframe with expected evaluation set schema</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span> <span class="k">if</span> <span class="n">is_managed_dataset</span> <span class="k">else</span> <span class="n">_convert_to_eval_set</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">builtin_scorers</span> <span class="o">=</span> <span class="p">[</span><span class="n">scorer</span> <span class="k">for</span> <span class="n">scorer</span> <span class="ow">in</span> <span class="n">scorers</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scorer</span><span class="p">,</span> <span class="n">BuiltInScorer</span><span class="p">)]</span>
    <span class="n">valid_data_for_builtin_scorers</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">builtin_scorers</span><span class="p">,</span> <span class="n">predict_fn</span><span class="p">)</span>

    <span class="c1"># &quot;request&quot; column must exist after conversion</span>
    <span class="n">input_key</span> <span class="o">=</span> <span class="s2">&quot;inputs&quot;</span> <span class="k">if</span> <span class="n">is_managed_dataset</span> <span class="k">else</span> <span class="s2">&quot;request&quot;</span>
    <span class="n">sample_input</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">input_key</span><span class="p">]</span>

    <span class="c1"># Only check &#39;inputs&#39; column when it is not derived from the trace object</span>
    <span class="k">if</span> <span class="s2">&quot;trace&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sample_input</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
            <span class="s2">&quot;The &#39;inputs&#39; column must be a dictionary of field names and values. &quot;</span>
            <span class="s2">&quot;For example: {&#39;query&#39;: &#39;What is MLflow?&#39;}&quot;</span>
        <span class="p">)</span>

    <span class="c1"># If the input dataset is a managed dataset, we pass the original dataset</span>
    <span class="c1"># to the evaluate function to preserve metadata like dataset name.</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span> <span class="k">if</span> <span class="n">is_managed_dataset</span> <span class="k">else</span> <span class="n">df</span>

    <span class="k">if</span> <span class="n">predict_fn</span><span class="p">:</span>
        <span class="n">predict_fn</span> <span class="o">=</span> <span class="n">convert_predict_fn</span><span class="p">(</span><span class="n">predict_fn</span><span class="o">=</span><span class="n">predict_fn</span><span class="p">,</span> <span class="n">sample_input</span><span class="o">=</span><span class="n">sample_input</span><span class="p">)</span>

    <span class="n">eval_start_time</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_databricks_uri</span><span class="p">(</span><span class="n">mlflow</span><span class="o">.</span><span class="n">get_tracking_uri</span><span class="p">()):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_evaluate_dbx</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="p">,</span> <span class="n">predict_fn</span><span class="p">,</span> <span class="n">model_id</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_evaluate_oss</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="p">,</span> <span class="n">predict_fn</span><span class="p">,</span> <span class="n">model_id</span><span class="p">)</span>

    <span class="c1"># Clean up noisy traces generated during evaluation</span>
    <span class="n">clean_up_extra_traces</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">run_id</span><span class="p">,</span> <span class="n">eval_start_time</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span></div>


<span class="k">def</span><span class="w"> </span><span class="nf">_evaluate_oss</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="p">,</span> <span class="n">predict_fn</span><span class="p">,</span> <span class="n">model_id</span><span class="p">):</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.genai.evaluation</span><span class="w"> </span><span class="kn">import</span> <span class="n">harness</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">EvaluationDataset</span><span class="p">):</span>
        <span class="n">mlflow_dataset</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Rename &#39;request&#39; / &#39;response&#39; column back to &#39;inputs&#39; / &#39;outputs&#39;.</span>
        <span class="c1"># This is a temporary hack to avoid branching _convert_to_eval_set()</span>
        <span class="c1"># into OSS and DBX implementation.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
            <span class="n">columns</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;request&quot;</span><span class="p">:</span> <span class="n">InputDatasetColumn</span><span class="o">.</span><span class="n">INPUTS</span><span class="p">,</span>
                <span class="s2">&quot;response&quot;</span><span class="p">:</span> <span class="n">InputDatasetColumn</span><span class="o">.</span><span class="n">OUTPUTS</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="n">mlflow_dataset</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">data</span>

    <span class="k">with</span> <span class="p">(</span>
        <span class="n">_start_run_or_reuse_active_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run_id</span><span class="p">,</span>
        <span class="n">_set_active_model</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span> <span class="k">if</span> <span class="n">model_id</span> <span class="k">else</span> <span class="n">nullcontext</span><span class="p">(),</span>
        <span class="c1"># NB: Auto-logging should be enabled outside the thread pool to avoid race conditions.</span>
        <span class="n">configure_autologging_for_evaluation</span><span class="p">(</span><span class="n">enable_tracing</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="n">_log_dataset_input</span><span class="p">(</span><span class="n">mlflow_dataset</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">model_id</span><span class="p">)</span>

        <span class="c1"># NB: Set this tag before run finishes to suppress the generic run URL printing.</span>
        <span class="n">MlflowClient</span><span class="p">()</span><span class="o">.</span><span class="n">set_tag</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">MLFLOW_RUN_IS_EVALUATION</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">harness</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="n">predict_fn</span><span class="o">=</span><span class="n">predict_fn</span><span class="p">,</span>
            <span class="n">eval_df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">scorers</span><span class="o">=</span><span class="n">scorers</span><span class="p">,</span>
            <span class="n">run_id</span><span class="o">=</span><span class="n">run_id</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">display_evaluation_output</span><span class="p">(</span><span class="n">run_id</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Failed to display summary and usage instructions&quot;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_evaluate_dbx</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scorers</span><span class="p">,</span> <span class="n">predict_fn</span><span class="p">,</span> <span class="n">model_id</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;In Databricks, we run GenAI evaluation using databricks-agents package and</span>
<span class="sd">    the mlflow.evaluate() function. This is a temporary migration state and we will</span>
<span class="sd">    eventually unify this into OSS flow.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># NB: The &quot;RAG_EVAL_MAX_WORKERS&quot; env var is used in the DBX agent harness, but is</span>
    <span class="c1"># deprecated in favor of the new &quot;MLFLOW_GENAI_EVAL_MAX_WORKERS&quot; env var. The old</span>
    <span class="c1"># one is not publicly documented, but we keep it for backward compatibility.</span>
    <span class="k">if</span> <span class="n">MLFLOW_GENAI_EVAL_MAX_WORKERS</span><span class="o">.</span><span class="n">is_set</span><span class="p">()</span> <span class="ow">and</span> <span class="s2">&quot;RAG_EVAL_MAX_WORKERS&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;RAG_EVAL_MAX_WORKERS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">MLFLOW_GENAI_EVAL_MAX_WORKERS</span><span class="o">.</span><span class="n">get</span><span class="p">())</span>
    <span class="k">elif</span> <span class="s2">&quot;RAG_EVAL_MAX_WORKERS&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;The `RAG_EVAL_MAX_WORKERS` environment variable is deprecated. &quot;</span>
            <span class="s2">&quot;Please use `MLFLOW_GENAI_EVAL_MAX_WORKERS` instead.&quot;</span>
        <span class="p">)</span>

    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span>
            <span class="s2">&quot;ignore&quot;</span><span class="p">,</span>
            <span class="n">message</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;Hint: Inferred schema contains integer column\(s\).*&quot;</span><span class="p">,</span>
            <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Suppress numpy warning about ragged nested sequences. This is raised when passing</span>
        <span class="c1"># a dataset that contains complex object to mlflow.evaluate(). MLflow converts data</span>
        <span class="c1"># into numpy array to compute dataset digest, which triggers the warning.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span>
            <span class="s2">&quot;ignore&quot;</span><span class="p">,</span>
            <span class="n">message</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;Creating an ndarray from ragged nested sequences&quot;</span><span class="p">,</span>
            <span class="n">module</span><span class="o">=</span><span class="s2">&quot;mlflow.data.evaluation_dataset&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">predict_fn</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">evaluator_config</span><span class="o">=</span><span class="p">{</span><span class="n">GENAI_CONFIG_NAME</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">[]}},</span>  <span class="c1"># Turn off the default metrics</span>
            <span class="c1"># Scorers are passed to the eval harness as extra metrics</span>
            <span class="n">extra_metrics</span><span class="o">=</span><span class="p">[</span><span class="n">_convert_scorer_to_legacy_metric</span><span class="p">(</span><span class="n">_scorer</span><span class="p">)</span> <span class="k">for</span> <span class="n">_scorer</span> <span class="ow">in</span> <span class="n">scorers</span><span class="p">],</span>
            <span class="n">model_type</span><span class="o">=</span><span class="n">GENAI_CONFIG_NAME</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
            <span class="n">_called_from_genai_evaluate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_log_dataset_input</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">,</span>
    <span class="n">run_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">MlflowClient</span><span class="p">()</span>
    <span class="n">dataset_input</span> <span class="o">=</span> <span class="n">DatasetInput</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">_to_mlflow_entity</span><span class="p">())</span>
    <span class="n">client</span><span class="o">.</span><span class="n">log_inputs</span><span class="p">(</span>
        <span class="n">run_id</span><span class="o">=</span><span class="n">run_id</span><span class="p">,</span>
        <span class="n">datasets</span><span class="o">=</span><span class="p">[</span><span class="n">dataset_input</span><span class="p">],</span>
        <span class="n">models</span><span class="o">=</span><span class="p">[</span><span class="n">LoggedModelInput</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)]</span> <span class="k">if</span> <span class="n">model_id</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>


<div class="viewcode-block" id="to_predict_fn"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.to_predict_fn">[docs]</a><span class="nd">@experimental</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;3.0.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">to_predict_fn</span><span class="p">(</span><span class="n">endpoint_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert an endpoint URI to a predict function.</span>

<span class="sd">    Args:</span>
<span class="sd">        endpoint_uri: The endpoint URI to convert.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A predict function that can be used to make predictions.</span>

<span class="sd">    Example:</span>

<span class="sd">        The following example assumes that the model serving endpoint accepts a JSON</span>
<span class="sd">        object with a `messages` key. Please adjust the input based on the actual</span>
<span class="sd">        schema of the model serving endpoint.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from mlflow.genai.scorers import get_all_scorers</span>

<span class="sd">            data = [</span>
<span class="sd">                {</span>
<span class="sd">                    &quot;inputs&quot;: {</span>
<span class="sd">                        &quot;messages&quot;: [</span>
<span class="sd">                            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},</span>
<span class="sd">                            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is MLflow?&quot;},</span>
<span class="sd">                        ]</span>
<span class="sd">                    }</span>
<span class="sd">                },</span>
<span class="sd">                {</span>
<span class="sd">                    &quot;inputs&quot;: {</span>
<span class="sd">                        &quot;messages&quot;: [</span>
<span class="sd">                            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},</span>
<span class="sd">                            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is Spark?&quot;},</span>
<span class="sd">                        ]</span>
<span class="sd">                    }</span>
<span class="sd">                },</span>
<span class="sd">            ]</span>
<span class="sd">            predict_fn = mlflow.genai.to_predict_fn(&quot;endpoints:/chat&quot;)</span>
<span class="sd">            mlflow.genai.evaluate(</span>
<span class="sd">                data=data,</span>
<span class="sd">                predict_fn=predict_fn,</span>
<span class="sd">                scorers=get_all_scorers(),</span>
<span class="sd">            )</span>

<span class="sd">        You can also directly invoke the function to validate if the endpoint works</span>
<span class="sd">        properly with your input schema.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            predict_fn(**data[0][&quot;inputs&quot;])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_model_deployment_endpoint_uri</span><span class="p">(</span><span class="n">endpoint_uri</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Invalid endpoint URI: </span><span class="si">{</span><span class="n">endpoint_uri</span><span class="si">}</span><span class="s2">. The endpoint URI must be a valid model &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;deployment endpoint URI.&quot;</span>
        <span class="p">)</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.deployments</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_deploy_client</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.metrics.genai.model_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_parse_model_uri</span>

    <span class="n">client</span> <span class="o">=</span> <span class="n">get_deploy_client</span><span class="p">(</span><span class="s2">&quot;databricks&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">endpoint</span> <span class="o">=</span> <span class="n">_parse_model_uri</span><span class="p">(</span><span class="n">endpoint_uri</span><span class="p">)</span>
    <span class="n">endpoint_info</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_endpoint</span><span class="p">(</span><span class="n">endpoint</span><span class="p">)</span>

    <span class="c1"># Databricks Foundation Model API does not allow passing &quot;databricks_options&quot; in the payload,</span>
    <span class="c1"># so we need to handle this case separately.</span>
    <span class="n">is_fmapi</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">endpoint_info</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">is_fmapi</span> <span class="o">=</span> <span class="n">endpoint_info</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;endpoint_type&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;FOUNDATION_MODEL_API&quot;</span>

    <span class="c1"># NB: Wrap the function to show better docstring and change signature to `model_inputs`</span>
    <span class="c1">#   to unnamed keyword arguments. This is necessary because we pass input samples as</span>
    <span class="c1">#   keyword arguments to the predict function.</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_fn</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">start_time_ms</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time_ns</span><span class="p">()</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">)</span>
        <span class="c1"># Inject `{&quot;databricks_options&quot;: {&quot;return_trace&quot;: True}}` to the input payload</span>
        <span class="c1"># to return the trace in the response.</span>
        <span class="n">databricks_options</span> <span class="o">=</span> <span class="p">{</span><span class="n">DATABRICKS_OPTIONS_KEY</span><span class="p">:</span> <span class="p">{</span><span class="n">RETURN_TRACE_OPTION_KEY</span><span class="p">:</span> <span class="kc">True</span><span class="p">}}</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="n">kwargs</span> <span class="k">if</span> <span class="n">is_fmapi</span> <span class="k">else</span> <span class="p">{</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">databricks_options</span><span class="p">}</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span>
        <span class="n">end_time_ms</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time_ns</span><span class="p">()</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">)</span>

        <span class="c1"># If the endpoint returns a trace, copy it to the current experiment.</span>
        <span class="k">if</span> <span class="n">trace_dict</span> <span class="o">:=</span> <span class="n">result</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">DATABRICKS_OUTPUT_KEY</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;trace&quot;</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">copy_trace_to_experiment</span><span class="p">(</span><span class="n">trace_dict</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">result</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="s2">&quot;Failed to copy trace from the endpoint response to the current experiment. &quot;</span>
                    <span class="s2">&quot;Trace will only have a root span with request and response.&quot;</span><span class="p">,</span>
                    <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># If the endpoint doesn&#39;t return a trace, manually create a trace with request/response.</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_trace</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span>
            <span class="n">request</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="n">response</span><span class="o">=</span><span class="n">result</span><span class="p">,</span>
            <span class="n">start_time_ms</span><span class="o">=</span><span class="n">start_time_ms</span><span class="p">,</span>
            <span class="n">execution_time_ms</span><span class="o">=</span><span class="n">end_time_ms</span> <span class="o">-</span> <span class="n">start_time_ms</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="n">predict_fn</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">A wrapper function for invoking the model serving endpoint `</span><span class="si">{</span><span class="n">endpoint_uri</span><span class="si">}</span><span class="s2">`.</span>

<span class="s2">Args:</span>
<span class="s2">    **kwargs: The input samples to be passed to the model serving endpoint.</span>
<span class="s2">        For example, if the endpoint accepts a JSON object with a `messages` key,</span>
<span class="s2">        the function also expects to get `messages` as an argument.</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">predict_fn</span></div>
</pre></div>

              </div>
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../../',
      VERSION:'3.3.0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>