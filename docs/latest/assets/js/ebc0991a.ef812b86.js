"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6467],{5841:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>g,contentTitle:()=>h,default:()=>x,frontMatter:()=>d,metadata:()=>p,toc:()=>u});var a=t(4848),i=t(8453),l=t(9374),r=t(493),s=t(4252),o=t(1470),c=t(9365);const d={description:"MLflow Tracing is a feature that enables LLM observability in your apps. MLflow automatically logs traces for LangChain, LlamaIndex, and more.",sidebar_position:1},h="MLflow Tracing",p={id:"llms/tracing/index",title:"MLflow Tracing",description:"MLflow Tracing is a feature that enables LLM observability in your apps. MLflow automatically logs traces for LangChain, LlamaIndex, and more.",source:"@site/docs/llms/tracing/index.mdx",sourceDirName:"llms/tracing",slug:"/llms/tracing/",permalink:"/llms/tracing/",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{description:"MLflow Tracing is a feature that enables LLM observability in your apps. MLflow automatically logs traces for LangChain, LlamaIndex, and more.",sidebar_position:1},sidebar:"docsSidebar",previous:{title:"LLMs",permalink:"/llms/"},next:{title:"Tracing Concepts",permalink:"/llms/tracing/overview"}},g={},u=[{value:"Automatic Tracing",id:"automatic-tracing",level:2},{value:"LangChain Automatic Tracing",id:"langchain-automatic-tracing",level:3},{value:"OpenAI Automatic Tracing",id:"openai-automatic-tracing",level:3},{value:"OpenAI Swarm Automatic Tracing",id:"openai-swarm-automatic-tracing",level:3},{value:"LlamaIndex Automatic Tracing",id:"llamaindex-automatic-tracing",level:3},{value:"DSPy Automatic Tracing",id:"dspy-automatic-tracing",level:3},{value:"AutoGen Automatic Tracing",id:"autogen-automatic-tracing",level:3},{value:"Gemini Automatic Tracing",id:"gemini-automatic-tracing",level:3},{value:"LiteLLM Automatic Tracing",id:"litellm-automatic-tracing",level:3},{value:"Tracing Fluent APIs",id:"tracing-fluent-apis",level:2},{value:"Initiating a Trace",id:"initiating-a-trace",level:3},{value:"Trace Decorator",id:"trace-decorator",level:4},{value:"What is captured?",id:"what-is-captured",level:4},{value:"Error Handling with Traces",id:"error-handling-with-traces",level:4},{value:"How to handle parent-child relationships",id:"how-to-handle-parent-child-relationships",level:4},{value:"Span Type",id:"span-type",level:4},{value:"Context Handler",id:"context-handler",level:4},{value:"Function wrapping",id:"function-wrapping",level:4},{value:"Tracing Client APIs",id:"tracing-client-apis",level:2},{value:"Starting a Trace",id:"starting-a-trace",level:3},{value:"Adding a Child Span",id:"adding-a-child-span",level:3},{value:"Ending a Span",id:"ending-a-span",level:3},{value:"Ending a Trace",id:"ending-a-trace",level:3},{value:"Searching and Retrieving Traces",id:"searching-and-retrieving-traces",level:2},{value:"Searching for Traces",id:"searching-for-traces",level:3},{value:"Retrieving a Specific Trace",id:"retrieving-a-specific-trace",level:3},{value:"Managing Trace Data",id:"managing-trace-data",level:2},{value:"Deleting Traces",id:"deleting-traces",level:3},{value:"Setting and Deleting Trace Tags",id:"setting-and-deleting-trace-tags",level:3},{value:"Async Logging",id:"async-logging",level:2},{value:"Using OpenTelemetry Collector for Exporting Traces",id:"using-opentelemetry-collector-for-exporting-traces",level:2},{value:"Configurations",id:"configurations",level:3},{value:"FAQ",id:"faq",level:2},{value:"Q: Can I disable and re-enable tracing globally?",id:"q-can-i-disable-and-re-enable-tracing-globally",level:3},{value:"Q: How can I associate a trace with an MLflow Run?",id:"q-how-can-i-associate-a-trace-with-an-mlflow-run",level:3},{value:"Q: Can I use the fluent API and the client API together?",id:"q-can-i-use-the-fluent-api-and-the-client-api-together",level:3},{value:"Q: How can I add custom metadata to a span?",id:"q-how-can-i-add-custom-metadata-to-a-span",level:3},{value:"Fluent API",id:"fluent-api",level:4},{value:"Client API",id:"client-api",level:4},{value:"Q: How can I see the stack trace of a Span that captured an Exception?",id:"q-how-can-i-see-the-stack-trace-of-a-span-that-captured-an-exception",level:3},{value:"Q: I cannot open my trace in the MLflow UI. What should I do?",id:"q-i-cannot-open-my-trace-in-the-mlflow-ui-what-should-i-do",level:3}];function m(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"mlflow-tracing",children:"MLflow Tracing"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["MLflow Tracing is currently in ",(0,a.jsx)(n.strong,{children:"Experimental Status"})," and is subject to change without deprecation warning or notification."]})}),"\n",(0,a.jsxs)(r.AC,{isSmall:!0,children:[(0,a.jsx)(r.$3,{link:"/llms/langchain/autologging",children:(0,a.jsx)("span",{children:(0,a.jsx)(n.img,{alt:"LangChain Logo",src:t(8366).A+"",width:"783",height:"138"})})}),(0,a.jsx)(r.$3,{link:"/llms/langchain/autologging",children:(0,a.jsx)("span",{children:(0,a.jsx)(n.img,{alt:"LangGraph Logo",src:t(5648).A+"",width:"571",height:"88"})})}),(0,a.jsx)(r.$3,{link:"/llms/llama-index#enable-tracing",children:(0,a.jsx)("span",{children:(0,a.jsx)(n.img,{alt:"LlamaIndex Logo",src:t(2770).A+"",width:"406",height:"96"})})}),(0,a.jsx)(r.$3,{link:"#automatic-tracing",children:(0,a.jsx)("span",{children:(0,a.jsx)(n.img,{alt:"DSPy Logo",src:t(3684).A+"",width:"609",height:"196"})})}),(0,a.jsx)(r.$3,{link:"/llms/openai/autologging",children:(0,a.jsx)("span",{children:(0,a.jsx)(n.img,{alt:"OpenAI Logo",src:t(3228).A+"",width:"2200",height:"598"})})}),(0,a.jsx)(r.$3,{link:"/llms/openai/autologging#auto-tracing-for-openai-swarm",children:(0,a.jsx)("span",{children:(0,a.jsx)(n.img,{alt:"OpenAI Swarm Logo",src:t(4545).A+"",width:"2148",height:"544"})})}),(0,a.jsx)(r.$3,{link:"#automatic-tracing",children:(0,a.jsx)("span",{children:(0,a.jsx)(n.img,{alt:"AutoGen Logo",src:t(5184).A+"",width:"720",height:"720"})})}),(0,a.jsx)(r.$3,{link:"#automatic-tracing",children:(0,a.jsx)("span",{children:(0,a.jsx)(n.img,{alt:"Gemini Logo",src:t(1762).A+"",width:"344",height:"127"})})}),(0,a.jsx)(r.$3,{link:"#automatic-tracing",children:(0,a.jsx)("span",{children:(0,a.jsx)(n.img,{alt:"LiteLLM Logo",src:t(4855).A+"",width:"740",height:"257"})})})]}),"\n",(0,a.jsx)("br",{}),"\n",(0,a.jsx)(n.p,{children:"MLflow Tracing is a feature that enhances LLM observability in your Generative\nAI (GenAI) applications by capturing detailed information about the execution of\nyour application's services. Tracing provides a way to record the inputs,\noutputs, and metadata associated with each intermediate step of a request,\nenabling you to easily pinpoint the source of bugs and unexpected behaviors."}),"\n",(0,a.jsx)(n.p,{children:"MLflow offers a number of different options to enable tracing of your GenAI applications."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Automated tracing"}),": MLflow provides fully automated integrations with various GenAI libraries such as LangChain, OpenAI, LlamaIndex, DSPy, AutoGen, and more that can be activated by simply enabling ",(0,a.jsx)(n.code,{children:"mlflow.<library>.autolog()"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Manual trace instrumentation with high-level fluent APIs"}),": Decorators, function wrappers and context managers via the fluent API allow you to add tracing functionality with minor code modifications."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Low-level client APIs for tracing"}),": The MLflow client API provides a thread-safe way to handle trace implementations, even in aysnchronous modes of operation."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["To learn more about what tracing is, see our ",(0,a.jsx)(n.a,{href:"./overview",children:"Tracing Concepts Overview"})," guide."]}),"\n",(0,a.jsxs)(n.p,{children:["To explore the structure and schema of MLflow Tracing, please see the ",(0,a.jsx)(n.a,{href:"./tracing-schema",children:"Tracing Schema"})," guide."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["MLflow Tracing support is available with the ",(0,a.jsx)(n.strong,{children:"MLflow 2.14.0"})," release. Versions of MLflow prior to this release\ndo not contain the full set of features that are required for trace logging support."]})}),"\n",(0,a.jsx)(s.A,{toc:u,maxHeadingLevel:2,minHeadingLevel:2}),"\n",(0,a.jsx)(n.h2,{id:"automatic-tracing",children:"Automatic Tracing"}),"\n",(0,a.jsx)(n.admonition,{title:"Hint",type:"info",children:(0,a.jsxs)(n.p,{children:["Is your favorite library missing from the list? Consider ",(0,a.jsx)(n.a,{href:"./contribute",children:"contributing to MLflow Tracing"})," or ",(0,a.jsx)(n.a,{href:"https://github.com/mlflow/mlflow/issues/new?assignees=&labels=enhancement&projects=&template=feature_request_template.yaml&title=%5BFR%5D",children:"submitting a feature request"})," to our Github repository."]})}),"\n",(0,a.jsxs)(n.p,{children:["The easiest way to get started with MLflow Tracing is to leverage the built-in capabilities with MLflow's integrated libraries. MLflow provides automatic tracing capabilities for some of the integrated libraries such as\nLangChain, OpenAI, LlamaIndex, and AutoGen. For these libraries, you can instrument your code with\njust a single command ",(0,a.jsx)(n.code,{children:"mlflow.<library>.autolog()"})," and MLflow will automatically log traces\nfor model/API invocations to the active MLflow Experiment."]}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(c.A,{value:"langchain",label:"LangChain / LangGraph",default:!0,children:[(0,a.jsx)(n.h3,{id:"langchain-automatic-tracing",children:"LangChain Automatic Tracing"}),(0,a.jsxs)(n.p,{children:["As part of the LangChain autologging integration, traces are logged to the active MLflow Experiment when calling invocation APIs on chains. You can enable tracing\nfor LangChain by calling the ",(0,a.jsx)(l.B,{fn:"mlflow.langchain.autolog"})," function."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.langchain.autolog()\n"})}),(0,a.jsxs)(n.p,{children:["In the full example below, the model and its associated metadata will be logged as a run, while the traces are logged separately to the active experiment. To learn more, please visit ",(0,a.jsx)(n.a,{href:"../langchain/autologging",children:"LangChain Autologging documentation"}),"."]}),(0,a.jsxs)(n.admonition,{type:"note",children:[(0,a.jsx)(n.p,{children:"This example has been confirmed working with the following requirement versions:"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-shell",children:"pip install openai==1.30.5 langchain==0.2.1 langchain-openai==0.1.8 langchain-community==0.2.1 mlflow==2.14.0 tiktoken==0.7.0\n"})})]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import os\n\nfrom langchain.prompts import PromptTemplate\nfrom langchain_openai import OpenAI\n\nimport mlflow\n\nassert (\n    "OPENAI_API_KEY" in os.environ\n), "Please set your OPENAI_API_KEY environment variable."\n\n# Using a local MLflow tracking server\nmlflow.set_tracking_uri("http://localhost:5000")\n\n# Create a new experiment that the model and the traces will be logged to\nmlflow.set_experiment("LangChain Tracing")\n\n# Enable LangChain autologging\n# Note that models and examples are not required to be logged in order to log traces.\n# Simply enabling autolog for LangChain via mlflow.langchain.autolog() will enable trace logging.\nmlflow.langchain.autolog(log_models=True, log_input_examples=True)\n\nllm = OpenAI(temperature=0.7, max_tokens=1000)\n\nprompt_template = (\n    "Imagine that you are {person}, and you are embodying their manner of answering questions posed to them. "\n    "While answering, attempt to mirror their conversational style, their wit, and the habits of their speech "\n    "and prose. You will emulate them as best that you can, attempting to distill their quirks, personality, "\n    "and habits of engagement to the best of your ability. Feel free to fully embrace their personality, whether "\n    "aspects of it are not guaranteed to be productive or entirely constructive or inoffensive."\n    "The question you are asked, to which you will reply as that person, is: {question}"\n)\n\nchain = prompt_template | llm\n\n# Test the chain\nchain.invoke(\n    {\n        "person": "Richard Feynman",\n        "question": "Why should we colonize Mars instead of Venus?",\n    }\n)\n\n# Let\'s test another call\nchain.invoke(\n    {\n        "person": "Linus Torvalds",\n        "question": "Can I just set everyone\'s access to sudo to make things easier?",\n    }\n)\n'})}),(0,a.jsx)(n.p,{children:"If we navigate to the MLflow UI, we can see not only the model that has been auto-logged, but the traces as well, as shown in the below video:"}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"LangChain Tracing via autolog",src:t(9904).A+"",width:"2048",height:"1638"})}),(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:"The example above is purposely simple (a simple chat completions demonstration) for purposes of brevity. In real-world scenarios involving complex\nRAG chains, the trace that is recorded by MLflow will be significantly more complex and verbose."})})]}),(0,a.jsxs)(c.A,{value:"openai",label:"OpenAI",children:[(0,a.jsx)(n.h3,{id:"openai-automatic-tracing",children:"OpenAI Automatic Tracing"}),(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.a,{href:"../openai/",children:"MLflow OpenAI flavor"}),"'s autologging feature has a direct integration with MLflow tracing. When OpenAI autologging is enabled with ",(0,a.jsx)(l.B,{fn:"mlflow.openai.autolog"}),",\nusage of the OpenAI SDK will automatically record generated traces during interactive development."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.openai.autolog()\n"})}),(0,a.jsxs)(n.p,{children:["For example, the code below will log traces to the currently active experiment (in this case, the activated experiment ",(0,a.jsx)(n.code,{children:'"OpenAI"'}),", set through the use of the ",(0,a.jsx)(l.B,{fn:"mlflow.set_experiment"})," API).\nTo learn more about OpenAI autologging, you can ",(0,a.jsx)(n.a,{href:"../openai/autologging",children:"view the documentation here"}),"."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import os\nimport openai\nimport mlflow\n\n# Calling the autolog API will enable trace logging by default.\nmlflow.openai.autolog()\n\nmlflow.set_experiment("OpenAI")\n\nopenai_client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))\n\nmessages = [\n    {\n        "role": "user",\n        "content": "How can I improve my resting metabolic rate most effectively?",\n    }\n]\n\nresponse = openai_client.chat.completions.create(\n    model="gpt-4o",\n    messages=messages,\n    temperature=0.99,\n)\n\nprint(response)\n'})}),(0,a.jsxs)(n.p,{children:["The logged trace, associated with the ",(0,a.jsx)(n.code,{children:"OpenAI"})," experiment, can be seen in the MLflow UI, as shown below:"]}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"OpenAI Tracing",src:t(6062).A+"",width:"2022",height:"1201"})})]}),(0,a.jsxs)(c.A,{value:"swarm",label:"Swarm",children:[(0,a.jsx)(n.h3,{id:"openai-swarm-automatic-tracing",children:"OpenAI Swarm Automatic Tracing"}),(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.a,{href:"../openai/",children:"MLflow OpenAI flavor"})," supports automatic tracing for ",(0,a.jsx)(n.a,{href:"https://github.com/openai/swarm",children:"Swarm"}),", a multi-agent orchestration\nframework from OpenAI. To enable tracing for ",(0,a.jsx)(n.strong,{children:"Swarm"}),", just call ",(0,a.jsx)(l.B,{fn:"mlflow.openai.autolog"}),"\nbefore running your multi-agent interactions. MLflow will trace all LLM interactions, tool calls, and agent operations automatically."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.openai.autolog()\n"})}),(0,a.jsx)(n.p,{children:"For example, the code below will run the simplest example of multi-agent interaction using OpenAI Swarm."}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom swarm import Swarm, Agent\n\n# Calling the autolog API will enable trace logging by default.\nmlflow.openai.autolog()\n\nmlflow.set_experiment("OpenAI Swarm")\n\nclient = Swarm()\n\n\ndef transfer_to_agent_b():\n    return agent_b\n\n\nagent_a = Agent(\n    name="Agent A",\n    instructions="You are a helpful agent.",\n    functions=[transfer_to_agent_b],\n)\n\nagent_b = Agent(\n    name="Agent B",\n    instructions="Only speak in Haikus.",\n)\n\nresponse = client.run(\n    agent=agent_a,\n    messages=[{"role": "user", "content": "I want to talk to agent B."}],\n)\nprint(response)\n'})}),(0,a.jsxs)(n.p,{children:["The logged trace, associated with the ",(0,a.jsx)(n.code,{children:"OpenAI Swarm"})," experiment, can be seen in the MLflow UI, as shown below:"]}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"OpenAI Swarm Tracing",src:t(3169).A+"",width:"3414",height:"1714"})})]}),(0,a.jsxs)(c.A,{value:"llamaindex",label:"LlamaIndex",children:[(0,a.jsx)(n.h3,{id:"llamaindex-automatic-tracing",children:"LlamaIndex Automatic Tracing"}),(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.a,{href:"../llama-index/",children:"MLflow LlamaIndex flavor"}),"'s autologging feature has a direct integration with MLflow tracing. When LlamaIndex autologging is enabled with ",(0,a.jsx)(l.B,{fn:"mlflow.llama_index.autolog"}),", invocation of components\nsuch as LLMs, agents, and query/chat engines will automatically record generated traces during interactive development."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.llama_index.autolog()\n"})}),(0,a.jsxs)(n.p,{children:["To see the full example of tracing LlamaIndex, please visit ",(0,a.jsx)(n.a,{href:"../llama-index",children:"LLamaIndex Tracing documentation"}),"."]}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"LlamaIndex Tracing",src:t(7983).A+"",width:"1725",height:"832"})})]}),(0,a.jsxs)(c.A,{value:"dspy",label:"DSPy",children:[(0,a.jsx)(n.h3,{id:"dspy-automatic-tracing",children:"DSPy Automatic Tracing"}),(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.a,{href:"../dspy/",children:"MLflow DSPy flavor"}),"'s autologging feature has a direct integration with MLflow tracing. When DSPy autologging is enabled with ",(0,a.jsx)(l.B,{fn:"mlflow.dspy.autolog"}),", invocation of components\nsuch as LMs, Adapters and Modules, will automatically record generated traces during interactive development."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport dspy\n\n# Enable tracing for DSPy\nmlflow.dspy.autolog()\n\n# Set an experiment to log the traces to\nmlflow.set_experiment("DSPy Tracing")\n\n# Define a simple ChainOfThought model and run it\nlm = dspy.LM("openai/gpt-4o-mini")\ndspy.configure(lm=lm)\n\n\n# Define a simple summarizer model and run it\nclass SummarizeSignature(dspy.Signature):\n    """Given a passage, generate a summary."""\n\n    passage: str = dspy.InputField(desc="a passage to summarize")\n    summary: str = dspy.OutputField(desc="a one-line summary of the passage")\n\n\nclass Summarize(dspy.Module):\n    def __init__(self):\n        self.summarize = dspy.ChainOfThought(SummarizeSignature)\n\n    def forward(self, passage: str):\n        return self.summarize(passage=passage)\n\n\nsummarizer = Summarize()\nsummarizer(\n    passage=(\n        "MLflow Tracing is a feature that enhances LLM observability in your Generative AI (GenAI) applications "\n        "by capturing detailed information about the execution of your application\'s services. Tracing provides "\n        "a way to record the inputs, outputs, and metadata associated with each intermediate step of a request, "\n        "enabling you to easily pinpoint the source of bugs and unexpected behaviors."\n    )\n)\n'})}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"DSPy Tracing",src:t(54).A+"",width:"2862",height:"1416"})})]}),(0,a.jsxs)(c.A,{value:"autogen",label:"AutoGen",children:[(0,a.jsx)(n.h3,{id:"autogen-automatic-tracing",children:"AutoGen Automatic Tracing"}),(0,a.jsxs)(n.p,{children:["MLflow Tracing ensures observability for your AutoGen application that involves complex multi-agent interactions. You can enable auto-tracing by calling ",(0,a.jsx)(l.B,{fn:"mlflow.autogen.autolog"}),",\nthen the internal steps of the agents chat session will be logged to the active MLflow Experiment."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.autogen.autolog()\n"})}),(0,a.jsxs)(n.p,{children:["To see the full example of tracing AutoGen, please refer to the ",(0,a.jsx)(n.a,{href:"https://github.com/mlflow/mlflow/tree/master/examples/autogen/tracing.py",children:"AutoGen Tracing example"}),"."]}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"AutoGen Tracing",src:t(9255).A+"",width:"2880",height:"1746"})})]}),(0,a.jsxs)(c.A,{value:"gemini",label:"Gemini",children:[(0,a.jsx)(n.h3,{id:"gemini-automatic-tracing",children:"Gemini Automatic Tracing"}),(0,a.jsxs)(n.p,{children:["MLflow Tracing ensures observability for your interactions with Gemini AI models.\nWhen Gemini autologging is enabled with ",(0,a.jsx)(l.B,{fn:"mlflow.gemini.autolog"}),",\nusage of the Gemini SDK will automatically record generated traces during interactive development.\nNote that only synchronous calls for text interactions are supported. Asynchronous API is not traced, and full inputs cannnot be recorded for multi-modal inputs."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.gemini.autolog()\n"})}),(0,a.jsxs)(n.p,{children:["To see the full example of tracing Gemini, please refer to the ",(0,a.jsx)(n.a,{href:"https://github.com/mlflow/mlflow/tree/master/examples/gemini/tracing.py",children:"Gemini Tracing example"}),"."]}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"AutoGen Tracing",src:t(1658).A+"",width:"3018",height:"1704"})})]}),(0,a.jsxs)(c.A,{value:"litellm",label:"LiteLLM",children:[(0,a.jsx)(n.h3,{id:"litellm-automatic-tracing",children:"LiteLLM Automatic Tracing"}),(0,a.jsxs)(n.p,{children:["LiteLLM allows developers to call all LLM APIs using the OpenAI format. MLflow support auto-tracing for LiteLLM. You can enable it by calling ",(0,a.jsx)(l.B,{fn:"mlflow.litellm.autolog"}),", then any LLM interactions via LiteLLM will be recorded to the active MLflow Experiment, including various metadata such as token usage, cost, cache hit, and more."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nmlflow.litellm.autolog()\n\n# Call Anthropic API via LiteLLM\nresponse = litellm.completion(\n    model="claude-3-opus-20240229",\n    messages=[{"role": "system", "content": "Hey! how\'s it going?"}],\n)\n'})}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"LiteLLM Tracing",src:t(4006).A+"",width:"1586",height:"830"})})]})]}),"\n",(0,a.jsx)(n.h2,{id:"tracing-fluent-apis",children:"Tracing Fluent APIs"}),"\n",(0,a.jsxs)(n.p,{children:["MLflow's ",(0,a.jsx)(l.B,{fn:"mlflow.start_span",children:(0,a.jsx)(n.code,{children:"fluent APIs"})})," provide a straightforward way to add tracing to your functions and code blocks.\nBy using decorators, function wrappers, and context managers, you can easily capture detailed trace data with minimal code changes."]}),"\n",(0,a.jsx)(n.p,{children:"As a comparison between the fluent and the client APIs for tracing, the figure below illustrates the differences in complexity between the two APIs,\nwith the fluent API being more concise and the recommended approach if your tracing use case can support using the higher-level APIs."}),"\n",(0,a.jsx)("div",{class:"center-div",style:{width:"60%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Fluent vs Client APIs",src:t(9298).A+"",width:"894",height:"726"})})}),"\n",(0,a.jsx)(n.p,{children:"This section will cover how to initiate traces using these fluent APIs."}),"\n",(0,a.jsx)(n.h3,{id:"initiating-a-trace",children:"Initiating a Trace"}),"\n",(0,a.jsx)(n.p,{children:"In this section, we will explore different methods to initiate a trace using MLflow's fluent APIs. These methods allow you to add tracing\nfunctionality to your code with minimal modifications, enabling you to capture detailed information about the execution of your functions and workflows."}),"\n",(0,a.jsx)(n.h4,{id:"trace-decorator",children:"Trace Decorator"}),"\n",(0,a.jsxs)(n.p,{children:["The trace decorator allows you to automatically capture the inputs and outputs of a function by simply adding the ",(0,a.jsx)(l.B,{fn:"mlflow.trace",children:(0,a.jsx)(n.code,{children:"@mlflow.trace"})})," decorator\nto its definition. This approach is ideal for quickly adding tracing to individual functions without significant changes to your existing code."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n# Create a new experiment to log the trace to\nmlflow.set_experiment("Tracing Demo")\n\n\n# Mark any function with the trace decorator to automatically capture input(s) and output(s)\n@mlflow.trace\ndef some_function(x, y, z=2):\n    return x + (y - z)\n\n\n# Invoking the function will generate a trace that is logged to the active experiment\nsome_function(2, 4)\n'})}),"\n",(0,a.jsx)(n.p,{children:"You can add additional metadata to the tracing decorator as follows:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'@mlflow.trace(name="My Span", span_type="func", attributes={"a": 1, "b": 2})\ndef my_func(x, y):\n    return x + y\n'})}),"\n",(0,a.jsx)(n.p,{children:"When adding additional metadata to the trace decorator constructor, these additional components will be logged along with the span entry within\nthe trace that is stored within the active MLflow experiment."}),"\n",(0,a.jsx)(n.p,{children:"Since MLflow 2.16.0, the trace decorator also supports async functions:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openai import AsyncOpenAI\n\nclient = AsyncOpenAI()\n\n\n@mlflow.trace\nasync def async_func(message: str):\n    return await client.chat.completion.create(\n        model="gpt-4o", messages=[{"role": "user", "content": message}]\n    )\n\n\nawait async_func("What is MLflow Tracing?")\n'})}),"\n",(0,a.jsx)(n.h4,{id:"what-is-captured",children:"What is captured?"}),"\n",(0,a.jsx)(n.p,{children:"If we navigate to the MLflow UI, we can see that the trace decorator automatically captured the following information, in addition to the basic\nmetadata associated with any span (start time, end time, status, etc):"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Inputs"}),": In the case of our decorated function, this includes the state of all input arguments (including the default ",(0,a.jsx)(n.code,{children:"z"})," value that is applied)."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Response"}),": The output of the function is also captured, in this case the result of the addition and subtraction operations."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Trace Name"}),": The name of the decorated function."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Trace UI - simple use case",src:t(9054).A+"",width:"1460",height:"779"})}),"\n",(0,a.jsx)(n.h4,{id:"error-handling-with-traces",children:"Error Handling with Traces"}),"\n",(0,a.jsxs)(n.p,{children:["If an ",(0,a.jsx)(n.code,{children:"Exception"})," is raised during processing of a trace-instrumented operation, an indication will be shown within the UI that the invocation was not\nsuccessful and a partial capture of data will be available to aid in debugging. Additionally, details about the Exception that was raised will be included\nwithin the ",(0,a.jsx)(n.code,{children:"events"})," attribute of the partially completed span, further aiding the identification of where issues are occuring within your code."]}),"\n",(0,a.jsx)(n.p,{children:"An example of a trace that has been recorded from code that raised an Exception is shown below:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# This will raise an AttributeError exception\ndo_math(3, 2, "multiply")\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Trace Error",src:t(403).A+"",width:"1460",height:"905"})}),"\n",(0,a.jsx)(n.h4,{id:"how-to-handle-parent-child-relationships",children:"How to handle parent-child relationships"}),"\n",(0,a.jsx)(n.p,{children:'When using the trace decorator, each decorated function will be treated as a separate span within the trace. The relationship between dependent function calls\nis handled directly through the native call excecution order within Python. For example, the following code will introduce two "child" spans to the main\nparent span, all using decorators.'}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n\n@mlflow.trace(span_type="func", attributes={"key": "value"})\ndef add_1(x):\n    return x + 1\n\n\n@mlflow.trace(span_type="func", attributes={"key1": "value1"})\ndef minus_1(x):\n    return x - 1\n\n\n@mlflow.trace(name="Trace Test")\ndef trace_test(x):\n    step1 = add_1(x)\n    return minus_1(step1)\n\n\ntrace_test(4)\n'})}),"\n",(0,a.jsx)(n.p,{children:"If we look at this trace from within the MLflow UI, we can see the relationship of the call order shown in the structure of the trace."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Trace Decorator",src:t(9481).A+"",width:"2048",height:"1079"})}),"\n",(0,a.jsx)(n.h4,{id:"span-type",children:"Span Type"}),"\n",(0,a.jsxs)(n.p,{children:["Span types are a way to categorize spans within a trace. By default, the span type is set to ",(0,a.jsx)(n.code,{children:'"UNKNOWN"'})," when using the trace decorator. MLflow provides a set of predefined span types for common use cases, while also allowing you to setting custom span types."]}),"\n",(0,a.jsx)(n.p,{children:"The following span types are available:"}),"\n",(0,a.jsxs)("table",{children:[(0,a.jsx)("thead",{children:(0,a.jsxs)("tr",{children:[(0,a.jsx)("th",{children:(0,a.jsx)(n.strong,{children:"Span Type"})}),(0,a.jsx)("th",{children:(0,a.jsx)(n.strong,{children:"Description"})})]})}),(0,a.jsxs)("tbody",{children:[(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{children:(0,a.jsx)(n.code,{children:'"LLM"'})}),(0,a.jsx)("td",{children:"Represents a call to an LLM endpoint or a local model."})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{children:(0,a.jsx)(n.code,{children:'"CHAT_MODEL"'})}),(0,a.jsx)("td",{children:"Represents a query to a chat model. This is a special case of an LLM interaction."})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{children:(0,a.jsx)(n.code,{children:'"CHAIN"'})}),(0,a.jsx)("td",{children:"Represents a chain of operations."})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{children:(0,a.jsx)(n.code,{children:'"AGENT"'})}),(0,a.jsx)("td",{children:"Represents an autonomous agent operation."})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{children:(0,a.jsx)(n.code,{children:'"TOOL"'})}),(0,a.jsx)("td",{children:"Represents a tool execution (typically by an agent), such as querying a search engine."})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{children:(0,a.jsx)(n.code,{children:'"EMBEDDING"'})}),(0,a.jsx)("td",{children:"Represents a text embedding operation."})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{children:(0,a.jsx)(n.code,{children:'"RETRIEVER"'})}),(0,a.jsx)("td",{children:"Represents a context retrieval operation, such as querying a vector database."})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{children:(0,a.jsx)(n.code,{children:'"PARSER"'})}),(0,a.jsx)("td",{children:"Represents a parsing operation, transforming text into a structured format."})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{children:(0,a.jsx)(n.code,{children:'"RERANKER"'})}),(0,a.jsx)("td",{children:"Represents a re-ranking operation, ordering the retrieved contexts based on relevance."})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("td",{children:(0,a.jsx)(n.code,{children:'"UNKNOWN"'})}),(0,a.jsx)("td",{children:"A default span type that is used when no other span type is specified."})]})]})]}),"\n",(0,a.jsxs)(n.p,{children:["To set a span type, you can pass the ",(0,a.jsx)(n.code,{children:"span_type"})," parameter to the ",(0,a.jsx)(l.B,{fn:"mlflow.trace",children:(0,a.jsx)(n.code,{children:"@mlflow.trace"})})," decorator or ",(0,a.jsx)(l.B,{fn:"mlflow.start_span"}),"\ncontext manager. When you are using ",(0,a.jsx)(n.a,{href:"#automatic-tracing",children:"automatic tracing"}),", the span type is automatically set by MLflow."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.entities import SpanType\n\n\n# Using a built-in span type\n@mlflow.trace(span_type=SpanType.RETRIEVER)\ndef retrieve_documents(query: str):\n    ...\n\n\n# Setting a custom span type\nwith mlflow.start_span(name="add", span_type="MATH") as span:\n    span.set_inputs({"x": z, "y": y})\n    z = x + y\n    span.set_outputs({"z": z})\n\n    print(span.span_type)\n    # Output: MATH\n'})}),"\n",(0,a.jsx)(n.h4,{id:"context-handler",children:"Context Handler"}),"\n",(0,a.jsxs)(n.p,{children:["The context handler provides a way to create nested traces or spans, which can be useful for capturing complex interactions within your code.\nBy using the ",(0,a.jsx)(l.B,{fn:"mlflow.start_span"})," context manager, you can group multiple traced functions under a single parent span, making it easier to understand\nthe relationships between different parts of your code."]}),"\n",(0,a.jsx)(n.p,{children:"The context handler is recommended when you need to refine the scope of data capture for a given span. If your code is logically constructed such that\nindividual calls to services or models are contained within functions or methods, on the other hand, using the decorator approach is more straight-forward\nand less complex."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n\n@mlflow.trace\ndef first_func(x, y=2):\n    return x + y\n\n\n@mlflow.trace\ndef second_func(a, b=3):\n    return a * b\n\n\ndef do_math(a, x, operation="add"):\n    # Use the fluent API context handler to create a new span\n    with mlflow.start_span(name="Math") as span:\n        # Specify the inputs and attributes that will be associated with the span\n        span.set_inputs({"a": a, "x": x})\n        span.set_attributes({"mode": operation})\n\n        # Both of these functions are decorated for tracing and will be associated\n        # as \'children\' of the parent \'span\' defined with the context handler\n        first = first_func(x)\n        second = second_func(a)\n\n        result = None\n\n        if operation == "add":\n            result = first + second\n        elif operation == "subtract":\n            result = first - second\n        else:\n            raise ValueError(f"Unsupported Operation Mode: {operation}")\n\n        # Specify the output result to the span\n        span.set_outputs({"result": result})\n\n        return result\n'})}),"\n",(0,a.jsxs)(n.p,{children:["When calling the ",(0,a.jsx)(n.code,{children:"do_math"})," function, a trace will be generated that has the root span (parent) defined as the\ncontext handler ",(0,a.jsx)(n.code,{children:"with mlflow.start_span():"})," call. The ",(0,a.jsx)(n.code,{children:"first_func"})," and ",(0,a.jsx)(n.code,{children:"second_func"})," calls will be associated as child spans\nto this parent span due to the fact that they are both decorated functions (having ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," decorated on the function definition)."]}),"\n",(0,a.jsx)(n.p,{children:"Running the following code will generate a trace."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'do_math(8, 3, "add")\n'})}),"\n",(0,a.jsx)(n.p,{children:"This trace can be seen within the MLflow UI:"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Trace within the MLflow UI",src:t(4238).A+"",width:"1460",height:"907"})}),"\n",(0,a.jsx)(n.h4,{id:"function-wrapping",children:"Function wrapping"}),"\n",(0,a.jsxs)(n.p,{children:["Function wrapping provides a flexible way to add tracing to existing functions without modifying their definitions. This is particularly useful when\nyou want to add tracing to third-party functions or functions defined outside of your control. By wrapping an external function with ",(0,a.jsx)(l.B,{fn:"mlflow.trace"}),", you can\ncapture its inputs, outputs, and execution context."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import math\n\nimport mlflow\n\nmlflow.set_experiment("External Function Tracing")\n\n\ndef invocation(x, y=4, exp=2):\n    # Initiate a context handler for parent logging\n    with mlflow.start_span(name="Parent") as span:\n        span.set_attributes({"level": "parent", "override": y == 4})\n        span.set_inputs({"x": x, "y": y, "exp": exp})\n\n        # Wrap an external function instead of modifying\n        traced_pow = mlflow.trace(math.pow)\n\n        # Call the wrapped function as you would call it directly\n        raised = traced_pow(x, exp)\n\n        # Wrap another external function\n        traced_factorial = mlflow.trace(math.factorial)\n\n        factorial = traced_factorial(int(raised))\n\n        # Wrap another and call it directly\n        response = mlflow.trace(math.sqrt)(factorial)\n\n        # Set the outputs to the parent span prior to returning\n        span.set_outputs({"result": response})\n\n        return response\n\n\nfor i in range(8):\n    invocation(i)\n'})}),"\n",(0,a.jsx)(n.p,{children:"The video below shows our external function wrapping runs within the MLflow UI. Note that"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"External Function tracing",src:t(9963).A+"",width:"2048",height:"1079"})}),"\n",(0,a.jsx)(n.h2,{id:"tracing-client-apis",children:"Tracing Client APIs"}),"\n",(0,a.jsx)(n.p,{children:"The MLflow client API provides a comprehensive set of thread-safe methods for manually managing traces. These APIs allow for fine-grained\ncontrol over tracing, enabling you to create, manipulate, and retrieve traces programmatically. This section will cover how to use these APIs\nto manually trace a model, providing step-by-step instructions and examples."}),"\n",(0,a.jsx)(n.h3,{id:"starting-a-trace",children:"Starting a Trace"}),"\n",(0,a.jsx)(n.p,{children:"Unlike with the fluent API, the MLflow Trace Client API requires that you explicitly start a trace before adding child spans. This initial API call\nstarts the root span for the trace, providing a context request_id that is used for associating subsequent spans to the root span."}),"\n",(0,a.jsxs)(n.p,{children:["To start a new trace, use the ",(0,a.jsx)(l.B,{fn:"mlflow.client.MlflowClient.start_trace"})," method. This method creates a new trace and returns the root span object."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from mlflow import MlflowClient\n\nclient = MlflowClient()\n\n# Start a new trace\nroot_span = client.start_trace("my_trace")\n\n# The request_id is used for creating additional spans that have a hierarchical association to this root span\nrequest_id = root_span.request_id\n'})}),"\n",(0,a.jsx)(n.h3,{id:"adding-a-child-span",children:"Adding a Child Span"}),"\n",(0,a.jsxs)(n.p,{children:["Once a trace is started, you can add child spans to it with the ",(0,a.jsx)(l.B,{fn:"mlflow.client.MlflowClient.start_span"})," API. Child spans allow you to break down the trace into smaller, more manageable segments,\neach representing a specific operation or step within the overall process."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Create a child span\nchild_span = client.start_span(\n    name="child_span",\n    request_id=request_id,\n    parent_id=root_span.span_id,\n    inputs={"input_key": "input_value"},\n    attributes={"attribute_key": "attribute_value"},\n)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"ending-a-span",children:"Ending a Span"}),"\n",(0,a.jsxs)(n.p,{children:["After performing the operations associated with a span, you must end the span explicitly using the ",(0,a.jsx)(l.B,{fn:"mlflow.client.MlflowClient.end_span"})," method. Make note of the two required fields\nthat are in the API signature:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"request_id"}),": The identifier associated with the root span"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"span_id"}),": The identifier associated with the span that is being ended"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["In order to effectively end a particular span, both the root span (returned from calling ",(0,a.jsx)(n.code,{children:"start_trace"}),") and the targeted span (returned from calling ",(0,a.jsx)(n.code,{children:"start_span"}),")\nneed to be identified when calling the ",(0,a.jsx)(n.code,{children:"end_span"})," API.\nThe initiating ",(0,a.jsx)(n.code,{children:"request_id"})," can be accessed from any parent span object's properties."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Spans created via the Client API will need to be terminated manually. Ensure that all spans that have been started with the ",(0,a.jsx)(n.code,{children:"start_span"})," API\nhave been ended with the ",(0,a.jsx)(n.code,{children:"end_span"})," API."]})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# End the child span\nclient.end_span(\n    request_id=child_span.request_id,\n    span_id=child_span.span_id,\n    outputs={"output_key": "output_value"},\n    attributes={"custom_attribute": "value"},\n)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"ending-a-trace",children:"Ending a Trace"}),"\n",(0,a.jsxs)(n.p,{children:["To complete the trace, end the root span using the ",(0,a.jsx)(l.B,{fn:"mlflow.client.MlflowClient.end_trace"})," method. This will also ensure that all associated child\nspans are properly ended."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# End the root span (trace)\nclient.end_trace(\n    request_id=request_id,\n    outputs={"final_output_key": "final_output_value"},\n    attributes={"token_usage": "1174"},\n)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"searching-and-retrieving-traces",children:"Searching and Retrieving Traces"}),"\n",(0,a.jsx)(n.h3,{id:"searching-for-traces",children:"Searching for Traces"}),"\n",(0,a.jsxs)(n.p,{children:["You can search for traces based on various criteria using the ",(0,a.jsx)(l.B,{fn:"mlflow.client.MlflowClient.search_traces"})," method. This method allows you to filter traces by experiment IDs,\nfilter strings, and other parameters."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Search for traces in specific experiments\ntraces = client.search_traces(\n    experiment_ids=["1", "2"],\n    filter_string="attributes.status = \'OK\'",\n    max_results=5,\n)\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Alternatively, you can use fluent API ",(0,a.jsx)(l.B,{fn:"mlflow.search_traces"})," to search for traces, which returns a pandas DataFrame with each row containing a trace.\nThis method allows you to specify fields to extract from traces using the format ",(0,a.jsx)(n.code,{children:'"span_name.[inputs|outputs]"'})," or ",(0,a.jsx)(n.code,{children:'"span_name.[inputs|outputs].field_name"'}),".\nThe extracted fields are included as extra columns in the pandas DataFrame. This feature can be used to build evaluation datasets to further improve model and agent performance."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nwith mlflow.start_span(name="span1") as span:\n    span.set_inputs({"a": 1, "b": 2})\n    span.set_outputs({"c": 3, "d": 4})\n\n# Search for traces with specific fields extracted\ntraces = mlflow.search_traces(\n    extract_fields=["span1.inputs", "span1.outputs.c"],\n)\n\nprint(traces)\n'})}),"\n",(0,a.jsx)(n.p,{children:"This outputs:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"    request_id                              ...     span1.inputs        span1.outputs.c\n0   tr-97c4ef97c21f4348a5698f069c1320f1     ...     {'a': 1, 'b': 2}    3.0\n1   tr-4dc3cd5567764499b5532e3af61b9f78     ...     {'a': 1, 'b': 2}    3.0\n"})}),"\n",(0,a.jsx)(n.h3,{id:"retrieving-a-specific-trace",children:"Retrieving a Specific Trace"}),"\n",(0,a.jsxs)(n.p,{children:["To retrieve a specific trace by its request ID, use the ",(0,a.jsx)(l.B,{fn:"mlflow.client.MlflowClient.get_trace"})," method. This method returns the trace object corresponding to the given request ID."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Retrieve a trace by request ID\ntrace = client.get_trace(request_id="12345678")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"managing-trace-data",children:"Managing Trace Data"}),"\n",(0,a.jsx)(n.h3,{id:"deleting-traces",children:"Deleting Traces"}),"\n",(0,a.jsxs)(n.p,{children:["You can delete traces based on specific criteria using the ",(0,a.jsx)(l.B,{fn:"mlflow.client.MlflowClient.delete_traces"})," method. This method allows you to delete traces by ",(0,a.jsx)(n.strong,{children:"experiment ID"}),",\n",(0,a.jsx)(n.strong,{children:"maximum timestamp"}),", or ",(0,a.jsx)(n.strong,{children:"request IDs"}),"."]}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["Deleting a trace is an irreversible process. Ensure that the setting provided within the ",(0,a.jsx)(n.code,{children:"delete_traces"})," API meet the intended range for deletion."]})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import time\n\n# Get the current timestamp in milliseconds\ncurrent_time = int(time.time() * 1000)\n\n# Delete traces older than a specific timestamp\ndeleted_count = client.delete_traces(\n    experiment_id="1", max_timestamp_millis=current_time, max_traces=10\n)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"setting-and-deleting-trace-tags",children:"Setting and Deleting Trace Tags"}),"\n",(0,a.jsxs)(n.p,{children:["Tags can be added to traces to provide additional metadata. Use the ",(0,a.jsx)(l.B,{fn:"mlflow.client.MlflowClient.set_trace_tag"})," method to set a tag on a trace,\nand the ",(0,a.jsx)(l.B,{fn:"mlflow.client.MlflowClient.delete_trace_tag"})," method to remove a tag from a trace."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Set a tag on a trace\nclient.set_trace_tag(request_id="12345678", key="tag_key", value="tag_value")\n\n# Delete a tag from a trace\nclient.delete_trace_tag(request_id="12345678", key="tag_key")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"async-logging",children:"Async Logging"}),"\n",(0,a.jsxs)(n.p,{children:["By default, MLflow Traces are logged synchronously. This may introduce a performance overhead when logging Traces, especially when your MLflow Tracking Server is running on a remote server. If the performance overhead is a concern for you, you can enable ",(0,a.jsx)(n.strong,{children:"asynchronous logging"})," for tracing in MLflow 2.16.0 and later."]}),"\n",(0,a.jsxs)(n.p,{children:["To enable async logging for tracing, call ",(0,a.jsx)(l.B,{fn:"mlflow.config.enable_async_logging"})," in your code. This will make the trace logging operation non-blocking and reduce the performance overhead."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nmlflow.config.enable_async_logging()\n\n# Traces will be logged asynchronously\nwith mlflow.start_span(name="foo") as span:\n    span.set_inputs({"a": 1})\n    span.set_outputs({"b": 2})\n\n# If you don\'t see the traces in the UI after waiting for a while, you can manually flush the traces\n# mlflow.flush_trace_async_logging()\n'})}),"\n",(0,a.jsx)(n.p,{children:"Note that the async logging does not fully eliminate the performance overhead. Some backend calls still need to be made synchronously and there are other factors such as data serialization. However, async logging can significantly reduce the overall overhead of logging traces, empirically about ~80% for typical workloads."}),"\n",(0,a.jsx)(n.h2,{id:"using-opentelemetry-collector-for-exporting-traces",children:"Using OpenTelemetry Collector for Exporting Traces"}),"\n",(0,a.jsxs)(n.p,{children:["Traces generated by MLflow are compatible with the ",(0,a.jsx)(n.a,{href:"https://opentelemetry.io/docs/specs/otel/trace/api/#span",children:"OpenTelemetry trace specs"}),".\nTherefore, MLflow Tracing supports exporting traces to an OpenTelemetry Collector, which can then be used to export traces to various backends such as Jaeger, Zipkin, and AWS X-Ray."]}),"\n",(0,a.jsxs)(n.p,{children:["By default, MLflow exports traces to the MLflow Tracking Server. To enable exporting traces to an OpenTelemetry Collector, set the ",(0,a.jsx)(n.code,{children:"OTEL_EXPORTER_OTLP_ENDPOINT"})," environment variable (or ",(0,a.jsx)(n.code,{children:"OTEL_EXPORTER_OTLP_TRACES_ENDPOINT"}),") to the target URL of the OpenTelemetry Collector ",(0,a.jsx)(n.strong,{children:"before starting any trace"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport os\n\n# Set the endpoint of the OpenTelemetry Collector\nos.environ["OTEL_EXPORTER_OTLP_TRACES_ENDPOINT"] = "http://localhost:4317/v1/traces"\n# Optionally, set the service name to group traces\nos.environ["OTEL_SERVICE_NAME"] = "<your-service-name>"\n\n# Trace will be exported to the OTel collector at http://localhost:4317/v1/traces\nwith mlflow.start_span(name="foo") as span:\n    span.set_inputs({"a": 1})\n    span.set_outputs({"b": 2})\n'})}),"\n",(0,a.jsxs)(n.admonition,{type:"warning",children:[(0,a.jsxs)(n.p,{children:["MLflow only exports traces to a single destination. When the ",(0,a.jsx)(n.code,{children:"OTEL_EXPORTER_OTLP_ENDPOINT"})," environment variable is configured, MLflow will ",(0,a.jsx)(n.strong,{children:"not"})," export traces to the MLflow Tracking Server and you will not see traces in the MLflow UI."]}),(0,a.jsxs)(n.p,{children:["Similarly, if you deploy the model to the ",(0,a.jsx)(n.a,{href:"https://docs.databricks.com/en/mlflow/mlflow-tracing.html#use-mlflow-tracing-in-production",children:"Databricks Model Serving with tracing enabled"}),", using the OpenTelemetry Collector will result in traces not being recorded in the Inference Table."]})]}),"\n",(0,a.jsx)(n.h3,{id:"configurations",children:"Configurations"}),"\n",(0,a.jsxs)(n.p,{children:["MLflow uses the standard OTLP Exporter for exporting traces to OpenTelemetry Collector instances. Thereby, you can use ",(0,a.jsx)(n.a,{href:"https://opentelemetry.io/docs/languages/sdk-configuration/otlp-exporter/",children:"all of the configurations"})," supported by OpenTelemetry. The following example configures the OTLP Exporter to use HTTP protocol instead of the default gRPC and sets custom headers:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'export OTEL_EXPORTER_OTLP_TRACES_ENDPOINT="http://localhost:4317/v1/traces"\nexport OTEL_EXPORTER_OTLP_TRACES_PROTOCOL="http/protobuf"\nexport OTEL_EXPORTER_OTLP_TRACES_HEADERS="api_key=12345"\n'})}),"\n",(0,a.jsx)(n.h2,{id:"faq",children:"FAQ"}),"\n",(0,a.jsx)(n.h3,{id:"q-can-i-disable-and-re-enable-tracing-globally",children:"Q: Can I disable and re-enable tracing globally?"}),"\n",(0,a.jsx)(n.p,{children:"Yes."}),"\n",(0,a.jsx)(n.p,{children:"There are two fluent APIs that are used for blanket enablement or disablement of the MLflow Tracing feature in order to support\nusers who may not wish to record interactions with their trace-enabled models for a brief period, or if they have concerns about long-term storage\nof data that was sent along with a request payload to a model in interactive mode."}),"\n",(0,a.jsxs)(n.p,{children:["To ",(0,a.jsx)(n.strong,{children:"disable"})," tracing, the ",(0,a.jsx)(l.B,{fn:"mlflow.tracing.disable"})," API will cease the collection of trace data from within MLflow and will not log\nany data to the MLflow Tracking service regarding traces."]}),"\n",(0,a.jsxs)(n.p,{children:["To ",(0,a.jsx)(n.strong,{children:"enable"})," tracing (if it had been temporarily disabled), the ",(0,a.jsx)(l.B,{fn:"mlflow.tracing.enable"})," API will re-enable tracing functionality for instrumented models\nthat are invoked."]}),"\n",(0,a.jsx)(n.h3,{id:"q-how-can-i-associate-a-trace-with-an-mlflow-run",children:"Q: How can I associate a trace with an MLflow Run?"}),"\n",(0,a.jsx)(n.p,{children:"If a trace is generated within a run context, the recorded traces to an active Experiment will be associated with the active Run."}),"\n",(0,a.jsxs)(n.p,{children:["For example, in the following code, the traces are generated within the ",(0,a.jsx)(n.code,{children:"start_run"})," context."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n# Create and activate an Experiment\nmlflow.set_experiment("Run Associated Tracing")\n\n# Start a new MLflow Run\nwith mlflow.start_run() as run:\n    # Initiate a trace by starting a Span context from within the Run context\n    with mlflow.start_span(name="Run Span") as parent_span:\n        parent_span.set_inputs({"input": "a"})\n        parent_span.set_outputs({"response": "b"})\n        parent_span.set_attribute("a", "b")\n        # Initiate a child span from within the parent Span\'s context\n        with mlflow.start_span(name="Child Span") as child_span:\n            child_span.set_inputs({"input": "b"})\n            child_span.set_outputs({"response": "c"})\n            child_span.set_attributes({"b": "c", "c": "d"})\n'})}),"\n",(0,a.jsx)(n.p,{children:"When navigating to the MLflow UI and selecting the active Experiment, the trace display view will show the run that is associated with the trace, as\nwell as providing a link to navigate to the run within the MLflow UI. See the below video for an example of this in action."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Tracing within a Run Context",src:t(6333).A+"",width:"2048",height:"1079"})}),"\n",(0,a.jsxs)(n.p,{children:["You can also programmatically retrieve the traces associated to a particular Run by using the ",(0,a.jsx)(l.B,{fn:"mlflow.client.MlflowClient.search_traces"})," method."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from mlflow import MlflowClient\n\nclient = MlflowClient()\n\n# Retrieve traces associated with a specific Run\ntraces = client.search_traces(run_id=run.info.run_id)\n\nprint(traces)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"q-can-i-use-the-fluent-api-and-the-client-api-together",children:"Q: Can I use the fluent API and the client API together?"}),"\n",(0,a.jsx)(n.p,{children:"You definitely can. However, the Client API is much more verbose than the fluent API and is designed for more complex use cases where you need\nto control asynchronous tasks for which a context manager will not have the ability to handle an appropriate closure over the context."}),"\n",(0,a.jsx)(n.p,{children:"Mixing the two, while entirely possible, is not generally recommended."}),"\n",(0,a.jsx)(n.p,{children:"For example, the following will work:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n# Initiate a fluent span creation context\nwith mlflow.start_span(name="Testing!") as span:\n    # Use the client API to start a child span\n    child_span = client.start_span(\n        name="Child Span From Client",\n        request_id=span.request_id,\n        parent_id=span.span_id,\n        inputs={"request": "test input"},\n        attributes={"attribute1": "value1"},\n    )\n\n    # End the child span\n    client.end_span(\n        request_id=span.request_id,\n        span_id=child_span.span_id,\n        outputs={"response": "test output"},\n        attributes={"attribute2": "value2"},\n    )\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Using Client APIs within fluent context",src:t(4152).A+"",width:"1460",height:"640"})}),"\n",(0,a.jsx)(n.admonition,{type:"warning",children:(0,a.jsxs)(n.p,{children:["Using the fluent API to manage a child span of a client-initiated root span or child span is not possible.\nAttempting to start a ",(0,a.jsx)(n.code,{children:"start_span"})," context handler while using the client API will result in two traces being created,\none for the fluent API and one for the client API."]})}),"\n",(0,a.jsx)(n.h3,{id:"q-how-can-i-add-custom-metadata-to-a-span",children:"Q: How can I add custom metadata to a span?"}),"\n",(0,a.jsx)(n.p,{children:"There are several ways."}),"\n",(0,a.jsx)(n.h4,{id:"fluent-api",children:"Fluent API"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Within the ",(0,a.jsx)(l.B,{fn:"mlflow.start_span"})," constructor itself."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'with mlflow.start_span(\n    name="Parent", attributes={"attribute1": "value1", "attribute2": "value2"}\n) as span:\n    span.set_inputs({"input1": "value1", "input2": "value2"})\n    span.set_outputs({"output1": "value1", "output2": "value2"})\n'})}),"\n",(0,a.jsxs)(n.ol,{start:"2",children:["\n",(0,a.jsxs)(n.li,{children:["Using the ",(0,a.jsx)(n.code,{children:"set_attribute"})," or ",(0,a.jsx)(n.code,{children:"set_attributes"})," methods on the ",(0,a.jsx)(n.code,{children:"span"})," object returned from the ",(0,a.jsx)(n.code,{children:"start_span"})," returned object."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'with mlflow.start_span(name="Parent") as span:\n    # Set multiple attributes\n    span.set_attributes({"attribute1": "value1", "attribute2": "value2"})\n    # Set a single attribute\n    span.set_attribute("attribute3", "value3")\n'})}),"\n",(0,a.jsx)(n.h4,{id:"client-api",children:"Client API"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["When starting a span, you can pass in the attributes as part of the ",(0,a.jsx)(n.code,{children:"start_trace"})," and ",(0,a.jsx)(n.code,{children:"start_span"})," method calls."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'parent_span = client.start_trace(\n    name="Parent Span",\n    attributes={"attribute1": "value1", "attribute2": "value2"}\n)\n\nchild_span = client.start_span(\n    name="Child Span",\n    request_id=parent_span.request_id,\n    parent_id=parent_span.span_id,\n    attributes={"attribute1": "value1", "attribute2": "value2"}\n)\n'})}),"\n",(0,a.jsxs)(n.ol,{start:"2",children:["\n",(0,a.jsxs)(n.li,{children:["Utilize the ",(0,a.jsx)(n.code,{children:"set_attribute"})," or ",(0,a.jsx)(n.code,{children:"set_attributes"})," APIs directly on the ",(0,a.jsx)(n.code,{children:"Span"})," objects."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'parent_span = client.start_trace(\n    name="Parent Span", attributes={"attribute1": "value1", "attribute2": "value2"}\n)\n\n# Set a single attribute\nparent_span.set_attribute("attribute3", "value3")\n# Set multiple attributes\nparent_span.set_attributes({"attribute4": "value4", "attribute5": "value5"})\n'})}),"\n",(0,a.jsxs)(n.ol,{start:"3",children:["\n",(0,a.jsx)(n.li,{children:"Set attributes when ending a span or the entire trace."}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'client.end_span(\n    request_id=parent_span.request_id,\n    span_id=child_span.span_id,\n    attributes={"attribute1": "value1", "attribute2": "value2"},\n)\n\nclient.end_trace(\n    request_id=parent_span.request_id,\n    attributes={"attribute3": "value3", "attribute4": "value4"},\n)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"q-how-can-i-see-the-stack-trace-of-a-span-that-captured-an-exception",children:"Q: How can I see the stack trace of a Span that captured an Exception?"}),"\n",(0,a.jsx)(n.p,{children:"The MLflow UI does not display Exception types, messages, or stacktraces if faults occur while logging a trace.\nHowever, the trace does contain this critical debugging information as part of the Span objects that comprise the Trace."}),"\n",(0,a.jsx)(n.p,{children:"The simplest way to retrieve a particular stack trace information from a span that endured an exception is to retrieve the trace directly in\nan interactive environment (such as a Jupyter Notebook)."}),"\n",(0,a.jsx)(n.p,{children:"Here is an example of intentionally throwing an Exception while a trace is being collected and a simple way to view the exception details:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nexperiment = mlflow.set_experiment("Intentional Exception")\n\nwith mlflow.start_span(name="A Problematic Span") as span:\n    span.set_inputs({"input": "Exception should log as event"})\n    span.set_attribute("a", "b")\n    raise Exception("Intentionally throwing!")\n    span.set_outputs({"This": "should not be recorded"})\n'})}),"\n",(0,a.jsx)(n.p,{children:"When running this, an Exception will be thrown, as expected. However, a trace is still logged to the active experiment and can be retrieved as follows:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from pprint import pprint\n\ntrace = mlflow.get_trace(span.request_id)\ntrace_data = trace.data\npprint(trace_data.to_dict(), indent=1)  # Minimum indent due to depth of Span object\n"})}),"\n",(0,a.jsxs)(n.p,{children:["In an interactive environment, such as a Jupyter Notebook, the ",(0,a.jsx)(n.code,{children:"stdout"})," return will render an output like this:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"{'spans': [{'name': 'A Span',\n    'context': {'span_id': '0x896ff177c0942903',\n        'trace_id': '0xcae9cb08ec0a273f4c0aab36c484fe87'},\n    'parent_id': None,\n    'start_time': 1718063629190062000,\n    'end_time': 1718063629190595000,\n    'status_code': 'ERROR',\n    'status_message': 'Exception: Intentionally throwing!',\n    'attributes': {'mlflow.traceRequestId': '\"7d418211df5945fa94e5e39b8009039e\"',\n        'mlflow.spanType': '\"UNKNOWN\"',\n        'mlflow.spanInputs': '{\"input\": \"Exception should log as event\"}',\n        'a': '\"b\"'},\n    'events': [{'name': 'exception',\n        'timestamp': 1718063629190527000,\n        'attributes': {'exception.type': 'Exception',\n        'exception.message': 'Intentionally throwing!',\n        'exception.stacktrace': 'Traceback (most recent call last):\\n\n                                  File \"/usr/local/lib/python3.8/site-packages/opentelemetry/trace/__init__.py\",\n                                  line 573, in use_span\\n\n                                    yield span\\n  File \"/usr/local/mlflow/mlflow/tracing/fluent.py\",\n                                  line 241, in start_span\\n\n                                    yield mlflow_span\\n  File \"/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/ipykernel_9875/4089093747.py\",\n                                  line 4, in <cell line: 1>\\n\n                                    raise Exception(\"Intentionally throwing!\")\\nException: Intentionally throwing!\\n',\n        'exception.escaped': 'False'}}]}],\n  'request': '{\"input\": \"Exception should log as event\"}',\n  'response': None\n}\n"})}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"exception.stacktrace"})," attribute contains the full stack trace of the Exception that was raised during the span's execution."]}),"\n",(0,a.jsxs)(n.p,{children:["Alternatively, if you were to use the MLflowClient API to search traces, the access to retrieve the span's event data from the failure would be\nslightly different (due to the return value being a ",(0,a.jsx)(n.code,{children:"pandas"})," DataFrame). To use the ",(0,a.jsx)(n.code,{children:"search_traces"})," API to access the same exception data would\nbe as follows:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nclient = mlflow.MlflowClient()\n\ntraces = client.search_traces(\n    experiment_ids=[experiment.experiment_id]\n)  # This returns a pandas DataFrame\npprint(traces["trace"][0].data.spans[0].to_dict(), indent=1)\n'})}),"\n",(0,a.jsx)(n.p,{children:"The stdout values that will be rendered from this call are identical to those from the example span data above."}),"\n",(0,a.jsx)(n.h3,{id:"q-i-cannot-open-my-trace-in-the-mlflow-ui-what-should-i-do",children:"Q: I cannot open my trace in the MLflow UI. What should I do?"}),"\n",(0,a.jsx)(n.p,{children:"There are multiple possible reasons why a trace may not be viewable in the MLflow UI."}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"The trace is not completed yet"}),': If the trace is still being collected, MLflow cannot display spans in the UI. Ensure that all spans are properly ended with either "OK" or "ERROR" status.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"The browser cache is outdated"}),": When you upgrade MLflow to a new version, the browser cache may contain outdated data and prevent the UI from displaying traces correctly. Clear your browser cache (Shift+F5) and refresh the page."]}),"\n"]}),"\n"]})]})}function x(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}},9374:(e,n,t)=>{t.d(n,{B:()=>o});t(6540);const a=JSON.parse('{"mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.fastai":"api_reference/python_api/mlflow.fastai.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.gluon":"api_reference/python_api/mlflow.gluon.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mleap":"api_reference/python_api/mlflow.mleap.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow.recipes":"api_reference/python_api/mlflow.recipes.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html"}');var i=t(6025),l=t(8774),r=t(4848);const s=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(a[e])return e}return null};function o(e){let{fn:n,children:t}=e;const o=s(n);if(!o)return(0,r.jsx)(r.Fragment,{children:t});const c=(0,i.Ay)(`/${a[o]}#${n}`);return(0,r.jsx)(l.A,{to:c,target:"_blank",children:t??(0,r.jsxs)("code",{children:[n,"()"]})})}},493:(e,n,t)=>{t.d(n,{Zp:()=>o,AC:()=>s,WO:()=>d,_C:()=>c,$3:()=>h});var a=t(4164);const i={CardGroup:"CardGroup_P84T",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardImage:"SmallLogoCardImage_tPZl"};var l=t(8774),r=t(4848);const s=e=>{let{children:n,isSmall:t}=e;return(0,r.jsx)("div",{className:(0,a.A)(i.CardGroup,t?i.AutofillColumns:i.MaxThreeColumns),children:n})},o=e=>{let{children:n,link:t}=e;return(0,r.jsx)(l.A,{className:(0,a.A)(i.Link,i.Card,i.CardBordered),to:t,children:n})},c=e=>{let{headerText:n,link:t,text:l}=e;return(0,r.jsx)(o,{link:t,children:(0,r.jsxs)("span",{children:[(0,r.jsx)("div",{className:(0,a.A)(i.CardTitle,i.BoxRoot,i.PaddingBottom4),style:{pointerEvents:"none"},children:(0,r.jsx)("div",{className:(0,a.A)(i.BoxRoot,i.FlexFlex,i.FlexAlignItemsCenter,i.FlexDirectionRow,i.FlexJustifyContentFlexStart,i.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,r.jsx)("div",{className:(0,a.A)(i.BoxRoot,i.BoxHideIfEmpty,i.MarginTop4,i.MarginLeft4),style:{pointerEvents:"auto"},children:(0,r.jsx)("span",{className:"",children:n})})})}),(0,r.jsx)("span",{className:(0,a.A)(i.TextColor,i.CardBody),children:(0,r.jsx)("p",{children:l})})]})})},d=e=>{let{description:n,children:t,link:a}=e;return(0,r.jsx)(o,{link:a,children:(0,r.jsxs)("div",{className:i.LogoCardContent,children:[(0,r.jsx)("div",{className:i.LogoCardImage,children:t}),(0,r.jsx)("p",{className:i.TextColor,children:n})]})})},h=e=>{let{children:n,link:t}=e;return(0,r.jsx)(o,{link:t,children:(0,r.jsx)("div",{className:i.SmallLogoCardContent,children:(0,r.jsx)("div",{className:(0,a.A)("max-height-img-container",i.SmallLogoCardImage),children:n})})})}},9255:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/autogen-trace-4821a7b67f7408f5b2ffdbd622428b9e.png"},1658:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/gemini-tracing-5da6948a6306c4acdf208075d80dabbe.png"},4006:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/litellm-tracing-39a2a3e58fdb3d8cce0ecdba1f4f70e8.png"},7983:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/llama-index-trace-8e9b746ead572230580e2e7d09e6ee2e.png"},4152:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/client-with-fluent-3942c7c8e8e90d1688893287a735306d.png"},54:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/dspy-tracing-20104ac2646517e53018735b6a9aec4c.png"},9963:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/external-trace-185c193a8f5dd36afd1fbf86f46618fe.gif"},9298:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/fluent-vs-client-tracing-6f0684a2a5b90064356b8a62da7e5b93.png"},9904:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/langchain-tracing-ed6a7b37e685d14f90b4a6e14a332b87.gif"},3169:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/openai-swarm-tracing-7adc452fe09e3ec62852ca87a71f7ec2.png"},6062:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/openai-tracing-6270683b332e499615504de3ec4538fd.png"},6333:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/run-trace-cbe44f5add2e57d90cea039724a7dea0.gif"},9481:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/trace-decorator-311aea6596f30fde36545918597adf7f.gif"},9054:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/trace-demo-1-8c76e434c704ee1996bdee0b4d3eeab1.png"},403:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/trace-error-dc660716eac8871f4dd1c3cae3efd0ed.png"},4238:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/trace-view-4e4a4b56d5ea5202b9505e0dc445ff7f.png"},5184:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/autogen-logo-22aa43e29df211f6c4882a314136290f.svg"},3684:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/dspy-logo-b3072c635a8fbacb2c6f9336db69a704.png"},1762:(e,n,t)=>{t.d(n,{A:()=>a});const a="data:image/svg+xml;base64,<svg width="344" height="127" viewBox="0 0 344 127" fill="none" xmlns="http://www.w3.org/2000/svg">
<mask id="mask0_958_15881" style="mask-type:alpha" maskUnits="userSpaceOnUse" x="0" y="0" width="344" height="127">
<path fill-rule="evenodd" clip-rule="evenodd" d="M234.123 41.2204C235.489 44.3354 236.172 47.6638 236.172 51.2055C236.172 47.6638 236.833 44.3354 238.156 41.2204C239.521 38.1054 241.356 35.3958 243.66 33.0916C245.965 30.7873 248.674 28.9738 251.789 27.651C254.904 26.2855 258.233 25.6028 261.774 25.6028C258.233 25.6028 254.904 24.9414 251.789 23.6185C248.674 22.2531 245.965 20.4182 243.66 18.114C241.356 15.8097 239.521 13.1001 238.156 9.98507C236.833 6.87007 236.172 3.54171 236.172 0C236.172 3.54171 235.489 6.87007 234.123 9.98507C232.801 13.1001 230.987 15.8097 228.683 18.114C226.379 20.4182 223.669 22.2531 220.554 23.6185C217.439 24.9414 214.111 25.6028 210.569 25.6028C214.111 25.6028 217.439 26.2855 220.554 27.651C223.669 28.9738 226.379 30.7873 228.683 33.0916C230.987 35.3958 232.801 38.1054 234.123 41.2204ZM26.1532 123.14C31.3762 125.291 36.9448 126.366 42.859 126.366C48.8501 126.366 54.3035 125.406 59.2192 123.486C64.1349 121.566 68.3978 118.839 72.0078 115.306C75.6178 111.773 78.4213 107.587 80.4183 102.748C82.4153 97.8321 83.4138 92.4555 83.4138 86.6181V86.5029C83.4138 85.4276 83.337 84.429 83.1834 83.5073C83.1066 82.5856 82.9914 81.6255 82.8377 80.627H43.0895V90.1897H73.0447C72.7374 94.7982 71.6621 98.7922 69.8187 102.172C68.0521 105.475 65.7863 108.201 63.0212 110.352C60.3329 112.502 57.2222 114.115 53.689 115.191C50.2326 116.189 46.6226 116.689 42.859 116.689C38.7114 116.689 34.6789 115.92 30.7617 114.384C26.8445 112.848 23.3497 110.621 20.2774 107.702C17.2819 104.783 14.9008 101.288 13.1342 97.2176C11.3676 93.07 10.4843 88.4231 10.4843 83.2769C10.4843 78.1308 11.3292 73.5223 13.019 69.4514C14.7856 65.3038 17.1667 61.809 20.1622 58.9671C23.1577 56.0484 26.6141 53.8209 30.5313 52.2848C34.5253 50.7486 38.6346 49.9805 42.859 49.9805C46.0082 49.9805 49.0037 50.403 51.8456 51.2479C54.6875 52.0159 57.299 53.1297 59.68 54.589C62.1379 56.0484 64.2501 57.815 66.0167 59.8888L73.1599 52.5152C69.7035 48.598 65.287 45.564 59.9105 43.4134C54.6107 41.2628 48.9269 40.1875 42.859 40.1875C37.0216 40.1875 31.4914 41.2628 26.2684 43.4134C21.1223 45.564 16.5522 48.598 12.5582 52.5152C8.64093 56.4324 5.5686 61.0025 3.34116 66.2255C1.11372 71.4484 0 77.1323 0 83.2769C0 89.4216 1.11372 95.1054 3.34116 100.328C5.5686 105.551 8.64093 110.121 12.5582 114.039C16.4754 117.956 21.0071 120.99 26.1532 123.14ZM104.058 122.334C108.512 125.022 113.582 126.366 119.266 126.366C125.717 126.366 131.132 124.907 135.511 121.988C139.889 119.07 143.23 115.383 145.534 110.928L136.778 106.78C135.165 109.699 132.937 112.157 130.096 114.154C127.33 116.151 123.874 117.149 119.726 117.149C116.5 117.149 113.39 116.343 110.394 114.73C107.399 113.117 104.941 110.697 103.021 107.472C101.362 104.684 100.419 101.266 100.194 97.2176H146.456C146.533 96.8336 146.571 96.3343 146.571 95.7199C146.648 95.1054 146.686 94.5293 146.686 93.9917C146.686 88.1542 145.534 82.9697 143.23 78.438C141.002 73.9063 137.776 70.3731 133.552 67.8385C129.327 65.227 124.297 63.9212 118.459 63.9212C112.698 63.9212 107.668 65.3806 103.366 68.2993C99.065 71.1412 95.7238 74.9432 93.3428 79.7053C91.0385 84.4674 89.8864 89.652 89.8864 95.259C89.8864 101.25 91.1153 106.588 93.5732 111.274C96.1079 115.959 99.6027 119.646 104.058 122.334ZM100.781 88.8071C101.143 87.0971 101.66 85.4841 102.329 83.9682C103.789 80.6654 105.901 78.054 108.666 76.1338C111.508 74.1367 114.811 73.1382 118.574 73.1382C121.723 73.1382 124.373 73.6759 126.524 74.7512C128.675 75.7497 130.441 77.0554 131.824 78.6684C133.206 80.2814 134.205 82.0096 134.819 83.853C135.434 85.6196 135.779 87.271 135.856 88.8071H100.781ZM155.497 65.7646V124.523H165.866V91.8026C165.866 88.5767 166.519 85.5428 167.825 82.7009C169.131 79.859 170.936 77.5931 173.24 75.9033C175.544 74.1367 178.156 73.2534 181.074 73.2534C185.145 73.2534 188.294 74.444 190.522 76.825C192.826 79.1293 193.978 83.0849 193.978 88.6919V124.523H204.232V91.5722C204.232 88.3463 204.885 85.3507 206.191 82.5856C207.496 79.7437 209.301 77.4779 211.606 75.7881C213.91 74.0983 216.521 73.2534 219.44 73.2534C223.588 73.2534 226.775 74.4056 229.003 76.7098C231.307 79.0141 232.459 82.9697 232.459 88.5767V124.523H242.713V86.8485C242.713 80.0126 241.023 74.4824 237.644 70.2579C234.341 66.0335 229.156 63.9212 222.09 63.9212C217.405 63.9212 213.372 64.9965 209.993 67.1472C206.613 69.2978 203.925 72.0245 201.928 75.3273C200.545 71.9477 198.279 69.221 195.13 67.1472C192.058 64.9965 188.333 63.9212 183.955 63.9212C181.497 63.9212 179.039 64.4205 176.581 65.419C174.2 66.3407 172.088 67.608 170.244 69.221C168.401 70.7572 166.942 72.4854 165.866 74.4056H165.405V65.7646H155.497ZM252.045 65.7646V124.523H262.299V65.7646H252.045ZM251.93 53.3217C253.389 54.7042 255.118 55.3955 257.115 55.3955C259.188 55.3955 260.917 54.7042 262.299 53.3217C263.682 51.8623 264.373 50.1341 264.373 48.1371C264.373 46.0633 263.682 44.3351 262.299 42.9526C260.917 41.4932 259.188 40.7635 257.115 40.7635C255.118 40.7635 253.389 41.4932 251.93 42.9526C250.547 44.3351 249.856 46.0633 249.856 48.1371C249.856 50.1341 250.547 51.8623 251.93 53.3217ZM271.929 65.7646V124.523H282.298V91.8026C282.298 88.6535 282.951 85.6964 284.257 82.9313C285.64 80.0894 287.521 77.7851 289.902 76.0185C292.283 74.1751 295.087 73.2534 298.313 73.2534C302.614 73.2534 306.071 74.444 308.682 76.825C311.293 79.1293 312.599 83.0849 312.599 88.6919V124.523H322.968V86.8485C322.968 79.9358 321.125 74.4056 317.438 70.2579C313.751 66.0335 308.336 63.9212 301.193 63.9212C296.969 63.9212 293.128 64.9581 289.672 67.032C286.216 69.1058 283.719 71.5637 282.183 74.4056H281.722V65.7646H271.929ZM331.672 65.7646V124.523H341.926V65.7646H331.672ZM331.557 53.3217C333.016 54.7042 334.745 55.3955 336.742 55.3955C338.815 55.3955 340.544 54.7042 341.926 53.3217C343.309 51.8623 344 50.1341 344 48.1371C344 46.0633 343.309 44.3351 341.926 42.9526C340.544 41.4932 338.815 40.7635 336.742 40.7635C334.745 40.7635 333.016 41.4932 331.557 42.9526C330.175 44.3351 329.483 46.0633 329.483 48.1371C329.483 50.1341 330.175 51.8623 331.557 53.3217Z" fill="white"/>
</mask>
<g mask="url(#mask0_958_15881)">
<rect x="-158.25" y="-455.443" width="832.09" height="685.324" fill="url(#paint0_linear_958_15881)"/>
</g>
<defs>
<linearGradient id="paint0_linear_958_15881" x1="-57.4049" y1="130.441" x2="354.97" y2="30.369" gradientUnits="userSpaceOnUse">
<stop stop-color="#439DDF"/>
<stop offset="0.524208" stop-color="#4F87ED"/>
<stop offset="0.781452" stop-color="#9476C5"/>
<stop offset="0.888252" stop-color="#BC688E"/>
<stop offset="1" stop-color="#D6645D"/>
</linearGradient>
</defs>
</svg>
"},8366:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/langchain-logo-39d51f94cc9aebac2c191cca0e8189de.png"},5648:(e,n,t)=>{t.d(n,{A:()=>a});const a="data:image/png;base64,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"},4855:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/litellm-logo-1fefb225fdc0242ddbc86baccd42282c.jpg"},2770:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/llamaindex-logo-dd13e5b1cfc2b77ac4bcd5a6a1d2b5af.svg"},3228:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/openai-logo-84ce36fa9f59f4df880cee88c0335586.png"},4545:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/openai-swarm-logo-12f7fbc12799c549c31261070b03cffe.png"}}]);