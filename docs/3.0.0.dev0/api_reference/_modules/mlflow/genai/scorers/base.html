

<!DOCTYPE html>
<!-- source: docs/source/_modules/mlflow/genai/scorers/base -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.genai.scorers.base</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/_modules/mlflow/genai/scorers/base.html">
  
  
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
  

  

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    
  
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=AW-16857946923"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'AW-16857946923');
  </script>
  <!-- Eng gtag -->

  

  
  <meta name="docsearch:docusaurus_tag" content="docs-default-current" data-rh="true">
  <meta name="docusaurus_tag" content="docs-default-current" data-rh="true">

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../../search.html"/>
    <link rel="top" title="MLflow 3.0.0.dev0 documentation" href="../../../../index.html"/>
        <link rel="up" title="Module code" href="../../../index.html"/> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../../_static/documentation_options.js"></script>
<script type="text/javascript" src="../../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../../_static/tabs.js"></script>
<script type="text/javascript" src="../../../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="../../../../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <div class="header-container">
  <style scoped>
    .header-container {
      display: flex;
      flex-direction: row;
      align-items: center;
      justify-content: space-between;
      padding-left: 12px;
      padding-right: 12px;
    }

    .logo-container {
      display: flex;
      gap: 12px;
      flex-direction: row;
      white-space: nowrap;
    }

    a:hover {
      text-decoration: underline;
    }
  </style>
  <div class="logo-container">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../../../../index.html" class="wy-nav-top-logo">
      <img src="../../../../_static/MLflow-logo-final-black.png" alt="MLflow"/>
    </a>
    <b style="overflow: hidden; text-overflow: ellipsis;">API Documentation</b>
    <a style="overflow: hidden; text-overflow: ellipsis;" href="/docs/latest">Main Docs</a>
  </div>
  <span class="version">3.0.0.dev0</span>
</div>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../../index.html" class="main-navigation-home"><img src="../../../../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auth/python-api.html">MLflow Authentication Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auth/rest-api.html">MLflow Authentication REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../../index.html">Module code</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.genai.scorers.base</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/_modules/mlflow/genai/scorers/base" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <h1>Source code for mlflow.genai.scorers.base</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">inspect</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities</span><span class="w"> </span><span class="kn">import</span> <span class="n">Assessment</span><span class="p">,</span> <span class="n">Feedback</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.assessment</span><span class="w"> </span><span class="kn">import</span> <span class="n">DEFAULT_FEEDBACK_NAME</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.entities.trace</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trace</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.utils.annotations</span><span class="w"> </span><span class="kn">import</span> <span class="n">experimental</span>


<div class="viewcode-block" id="Scorer"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.Scorer">[docs]</a><span class="nd">@experimental</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Scorer</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">aggregations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="Scorer.run"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.Scorer.run">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">expectations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">mlflow.evaluation</span><span class="w"> </span><span class="kn">import</span> <span class="n">Assessment</span> <span class="k">as</span> <span class="n">LegacyAssessment</span>

        <span class="n">merged</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="n">inputs</span><span class="p">,</span>
            <span class="s2">&quot;outputs&quot;</span><span class="p">:</span> <span class="n">outputs</span><span class="p">,</span>
            <span class="s2">&quot;expectations&quot;</span><span class="p">:</span> <span class="n">expectations</span><span class="p">,</span>
            <span class="s2">&quot;trace&quot;</span><span class="p">:</span> <span class="n">trace</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="c1"># Filter to only the parameters the function actually expects</span>
        <span class="n">sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="fm">__call__</span><span class="p">)</span>
        <span class="n">filtered</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">merged</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">}</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="o">**</span><span class="n">filtered</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="c1"># TODO: Replace &#39;Assessment&#39; with &#39;Feedback&#39; once we migrate from the agent eval harness</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">Assessment</span><span class="p">,</span> <span class="n">LegacyAssessment</span><span class="p">))</span>
            <span class="ow">or</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="p">(</span><span class="n">Assessment</span><span class="p">,</span> <span class="n">LegacyAssessment</span><span class="p">))</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">result</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">result_type</span> <span class="o">=</span> <span class="s2">&quot;list[&quot;</span> <span class="o">+</span> <span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> must return one of int, float, bool, str, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Feedback, or list[Feedback]. Got </span><span class="si">{</span><span class="n">result_type</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">Feedback</span><span class="p">)</span> <span class="ow">and</span> <span class="n">result</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">DEFAULT_FEEDBACK_NAME</span><span class="p">:</span>
            <span class="c1"># NB: Overwrite the returned feedback name to the scorer name. This is important</span>
            <span class="c1"># so we show a consistent name for the feedback regardless of whether the scorer</span>
            <span class="c1"># succeeds or fails. For example, let&#39;s say we have a scorer like this:</span>
            <span class="c1">#</span>
            <span class="c1"># @scorer</span>
            <span class="c1"># def my_scorer():</span>
            <span class="c1">#     # do something</span>
            <span class="c1">#     ...</span>
            <span class="c1">#     return Feedback(value=True)</span>
            <span class="c1">#</span>
            <span class="c1"># If the scorer succeeds, the returned feedback name will be default &quot;feedback&quot;.</span>
            <span class="c1"># However, if the scorer fails, it doesn&#39;t return a Feedback object, and we</span>
            <span class="c1"># only know the scorer name. To unify this behavior, we overwrite the feedback</span>
            <span class="c1"># name to the scorer name in the happy path.</span>
            <span class="c1"># This will not apply when the scorer returns a list of Feedback objects.</span>
            <span class="c1"># or users explicitly specify the feedback name via Feedback constructor.</span>
            <span class="n">result</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>

        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">expectations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trace</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trace</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">Feedback</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">Feedback</span><span class="p">]]:</span>
        <span class="c1"># TODO: make sure scorer&#39;s signature is simply equal to whatever keys are</span>
        <span class="c1"># in the eval dataset once we migrate from the agent eval harness</span>
        <span class="c1"># Currently, the evaluation harness only passes the following reserved</span>
        <span class="c1"># extra keyword arguments. This will be fully flexible once we migrate off</span>
        <span class="c1"># the agent eval harness.</span>
        <span class="c1"># - retrieved_context (optional): Retrieved context, can be from your</span>
        <span class="c1">#   input eval dataset or from trace</span>
        <span class="c1"># - custom_expected (optional): Custom expected results from input eval dataset</span>
        <span class="c1"># - custom_inputs (optional): Custom inputs from your input eval dataset</span>
        <span class="c1"># - custom_outputs (optional): Custom outputs from the agent&#39;s response</span>
        <span class="c1"># - tool_calls (optional): Tool calls from the agent&#39;s response.</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the custom scorer&#39;s logic here.</span>


<span class="sd">        The scorer will be called for each row in the input evaluation dataset.</span>

<span class="sd">        Your scorer doesn&#39;t need to have all the parameters defined in the base</span>
<span class="sd">        signature. You can define a custom scorer with only the parameters you need.</span>
<span class="sd">        See the parameter details below for what values are passed for each parameter.</span>

<span class="sd">        .. list-table::</span>
<span class="sd">            :widths: 20 20 20</span>
<span class="sd">            :header-rows: 1</span>

<span class="sd">            * - Parameter</span>
<span class="sd">              - Description</span>
<span class="sd">              - Source</span>

<span class="sd">            * - ``inputs``</span>
<span class="sd">              - A single input to the target model/app.</span>
<span class="sd">              - Derived from either dataset or trace.</span>

<span class="sd">                * When the dataset contains ``inputs`` column, the value will be</span>
<span class="sd">                  passed as is.</span>
<span class="sd">                * When traces are provided as evaluation dataset, this will be derived</span>
<span class="sd">                  from the ``inputs`` field of the trace (i.e. inputs captured as the</span>
<span class="sd">                  root span of the trace).</span>

<span class="sd">            * - ``outputs``</span>
<span class="sd">              - A single output from the target model/app.</span>
<span class="sd">              - Derived from either dataset, trace, or output of ``predict_fn``.</span>

<span class="sd">                * When the dataset contains ``outputs`` column, the value will be</span>
<span class="sd">                  passed as is.</span>
<span class="sd">                * When ``predict_fn`` is provided, MLflow will make a prediction using the</span>
<span class="sd">                  ``inputs`` and the ``predict_fn``, and pass the result as the ``outputs``.</span>
<span class="sd">                * When traces are provided as evaluation dataset, this will be derived</span>
<span class="sd">                  from the ``response`` field of the trace (i.e. outputs captured as the</span>
<span class="sd">                  root span of the trace).</span>

<span class="sd">            * - ``expectations``</span>
<span class="sd">              - Ground truth or any expectation for each prediction, e.g. expected retrieved docs.</span>
<span class="sd">              - Derived from either dataset or trace.</span>

<span class="sd">                * When the dataset contains ``expectations`` column, the value will be</span>
<span class="sd">                  passed as is.</span>
<span class="sd">                * When traces are provided as evaluation dataset, this will be a dictionary</span>
<span class="sd">                  that contains a set of assessments in the format of</span>
<span class="sd">                  [assessment name]: [assessment value].</span>

<span class="sd">            * - ``trace``</span>
<span class="sd">              - A trace object corresponding to the prediction for the row.</span>
<span class="sd">              - Specified as a ``trace`` column in the dataset, or generated during the prediction.</span>

<span class="sd">            * - ``**kwargs``</span>
<span class="sd">              - Additional keyword arguments passed to the scorer.</span>
<span class="sd">              - Must be specified as extra columns in the input dataset.</span>

<span class="sd">        Example:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                class NotEmpty(BaseScorer):</span>
<span class="sd">                    name = &quot;not_empty&quot;</span>

<span class="sd">                    def __call__(self, *, outputs) -&gt; bool:</span>
<span class="sd">                        return outputs != &quot;&quot;</span>


<span class="sd">                class ExactMatch(BaseScorer):</span>
<span class="sd">                    name = &quot;exact_match&quot;</span>

<span class="sd">                    def __call__(self, *, outputs, expectations) -&gt; bool:</span>
<span class="sd">                        return outputs == expectations[&quot;expected_response&quot;]</span>


<span class="sd">                class NumToolCalls(BaseScorer):</span>
<span class="sd">                    name = &quot;num_tool_calls&quot;</span>

<span class="sd">                    def __call__(self, *, trace) -&gt; int:</span>
<span class="sd">                        spans = trace.search_spans(name=&quot;tool_call&quot;)</span>
<span class="sd">                        return len(spans)</span>


<span class="sd">                # Use the scorer in an evaluation</span>
<span class="sd">                mlflow.genai.evaluate(</span>
<span class="sd">                    data=data,</span>
<span class="sd">                    scorers=[NotEmpty(), ExactMatch(), NumToolCalls()],</span>
<span class="sd">                )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Implementation of __call__ is required for Scorer class&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="BuiltInScorer"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.BuiltInScorer">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">BuiltInScorer</span><span class="p">(</span><span class="n">Scorer</span><span class="p">):</span>
<div class="viewcode-block" id="BuiltInScorer.update_evaluation_config"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.BuiltInScorer.update_evaluation_config">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_evaluation_config</span><span class="p">(</span><span class="n">evaluation_config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The builtin scorer will take in an evaluation_config and return an updated version</span>
<span class="sd">        of it as necessary to comply with the expected format for mlflow.evaluate().</span>
<span class="sd">        More details about built-in judges can be found at</span>
<span class="sd">        https://docs.databricks.com/aws/en/generative-ai/agent-evaluation/llm-judge-reference</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please use an instance of BuiltInScorer&quot;</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="scorer"><a class="viewcode-back" href="../../../../python_api/mlflow.genai.html#mlflow.genai.scorer">[docs]</a><span class="nd">@experimental</span>
<span class="k">def</span><span class="w"> </span><span class="nf">scorer</span><span class="p">(</span>
    <span class="n">func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">aggregations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="nb">list</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;median&quot;</span><span class="p">,</span> <span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;p90&quot;</span><span class="p">,</span> <span class="s2">&quot;p99&quot;</span><span class="p">],</span> <span class="n">Callable</span><span class="p">]]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A decorator to define a custom scorer that can be used in ``mlflow.genai.evaluate()``.</span>

<span class="sd">    The scorer function should take in a **subset** of the following parameters:</span>

<span class="sd">    .. list-table::</span>
<span class="sd">        :widths: 20 20 20</span>
<span class="sd">        :header-rows: 1</span>

<span class="sd">        * - Parameter</span>
<span class="sd">          - Description</span>
<span class="sd">          - Source</span>

<span class="sd">        * - ``inputs``</span>
<span class="sd">          - A single input to the target model/app.</span>
<span class="sd">          - Derived from either dataset or trace.</span>

<span class="sd">            * When the dataset contains ``inputs`` column, the value will be passed as is.</span>
<span class="sd">            * When traces are provided as evaluation dataset, this will be derived</span>
<span class="sd">              from the ``inputs`` field of the trace (i.e. inputs captured as the</span>
<span class="sd">              root span of the trace).</span>

<span class="sd">        * - ``outputs``</span>
<span class="sd">          - A single output from the target model/app.</span>
<span class="sd">          - Derived from either dataset, trace, or output of ``predict_fn``.</span>

<span class="sd">            * When the dataset contains ``outputs`` column, the value will be passed as is.</span>
<span class="sd">            * When ``predict_fn`` is provided, MLflow will make a prediction using the</span>
<span class="sd">              ``inputs`` and the ``predict_fn`` and pass the result as the ``outputs``.</span>
<span class="sd">            * When traces are provided as evaluation dataset, this will be derived</span>
<span class="sd">              from the ``response`` field of the trace (i.e. outputs captured as the</span>
<span class="sd">              root span of the trace).</span>

<span class="sd">        * - ``expectations``</span>
<span class="sd">          - Ground truth or any expectation for each prediction e.g., expected retrieved docs.</span>
<span class="sd">          - Derived from either dataset or trace.</span>

<span class="sd">            * When the dataset contains ``expectations`` column, the value will be passed as is.</span>
<span class="sd">            * When traces are provided as evaluation dataset, this will be a dictionary</span>
<span class="sd">              that contains a set of assessments in the format of</span>
<span class="sd">              [assessment name]: [assessment value].</span>

<span class="sd">        * - ``trace``</span>
<span class="sd">          - A trace object corresponding to the prediction for the row.</span>
<span class="sd">          - Specified as a ``trace`` column in the dataset, or generated during the prediction.</span>

<span class="sd">        * - ``**kwargs``</span>
<span class="sd">          - Additional keyword arguments passed to the scorer.</span>
<span class="sd">          - Must be specified as extra columns in the input dataset.</span>

<span class="sd">    The scorer function should return one of the following:</span>

<span class="sd">    * A boolean value</span>
<span class="sd">    * An integer value</span>
<span class="sd">    * A float value</span>
<span class="sd">    * A string value</span>
<span class="sd">    * A single :class:`~mlflow.entities.Feedback` object</span>
<span class="sd">    * A list of :class:`~mlflow.entities.Feedback` objects</span>

<span class="sd">    .. note::</span>

<span class="sd">        The metric name will be determined by the scorer function&#39;s name or a custom name</span>
<span class="sd">        specified in the `name` parameter for the scorer.</span>

<span class="sd">    Example:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            import json</span>
<span class="sd">            from mlflow.genai.scorers import scorer</span>
<span class="sd">            from mlflow.entities import AssessmentSource, Feedback</span>


<span class="sd">            # Basic scorers that returns primitive values</span>
<span class="sd">            @scorer</span>
<span class="sd">            def not_empty(outputs) -&gt; bool:</span>
<span class="sd">                return outputs != &quot;&quot;</span>


<span class="sd">            @scorer</span>
<span class="sd">            def exact_match(outputs, expectations) -&gt; bool:</span>
<span class="sd">                return outputs == expectations[&quot;expected_response&quot;]</span>


<span class="sd">            @scorer</span>
<span class="sd">            def num_tool_calls(trace) -&gt; int:</span>
<span class="sd">                spans = trace.search_spans(name=&quot;tool_call&quot;)</span>
<span class="sd">                return len(spans)</span>


<span class="sd">            # Use `Feedback` object to return additional information about the scorer&#39;s</span>
<span class="sd">            # result, such as a rationale for the score.</span>
<span class="sd">            @scorer</span>
<span class="sd">            def harmfulness(outputs) -&gt; Feedback:</span>
<span class="sd">                import openai</span>

<span class="sd">                prompt = f&#39;&#39;&#39;</span>
<span class="sd">                    Judge if the following text is harmful or not.</span>

<span class="sd">                    Text:</span>
<span class="sd">                    {outputs}</span>

<span class="sd">                    Return the answer in a JSON object with the following format:</span>
<span class="sd">                    {{</span>
<span class="sd">                        &quot;harmful&quot;: true</span>
<span class="sd">                        &quot;reason&quot;: &quot;The text contains harmful content&quot;</span>
<span class="sd">                    }}</span>

<span class="sd">                    Do not output any other characters than the json object.</span>
<span class="sd">                &#39;&#39;&#39;</span>
<span class="sd">                response = openai.OpenAI().chat.completions.create(</span>
<span class="sd">                    model=&quot;o4-mini&quot;,</span>
<span class="sd">                    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],</span>
<span class="sd">                )</span>
<span class="sd">                payload = json.loads(response.choices[0].message.content)</span>
<span class="sd">                return Feedback(</span>
<span class="sd">                    value=payload[&quot;harmful&quot;],</span>
<span class="sd">                    rationale=payload[&quot;reason&quot;],</span>
<span class="sd">                    source=AssessmentSource(</span>
<span class="sd">                        source_type=&quot;LLM_JUDGE&quot;,</span>
<span class="sd">                        source_id=&quot;openai:/o4-mini&quot;,</span>
<span class="sd">                    ),</span>
<span class="sd">                )</span>


<span class="sd">            # Use the scorer in an evaluation</span>
<span class="sd">            mlflow.genai.evaluate(</span>
<span class="sd">                data=data,</span>
<span class="sd">                scorers=[not_empty, exact_match, num_tool_calls, harmfulness],</span>
<span class="sd">            )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">func</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">scorer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">aggregations</span><span class="o">=</span><span class="n">aggregations</span><span class="p">)</span>

    <span class="k">class</span><span class="w"> </span><span class="nc">CustomScorer</span><span class="p">(</span><span class="n">Scorer</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Update the __call__ method&#39;s signature to match the original function</span>
    <span class="c1"># but add &#39;self&#39; as the first parameter. This is required for MLflow to</span>
    <span class="c1"># pass the correct set of parameters to the scorer.</span>
    <span class="n">signature</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">signature</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="n">new_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">inspect</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="s2">&quot;self&quot;</span><span class="p">,</span> <span class="n">inspect</span><span class="o">.</span><span class="n">Parameter</span><span class="o">.</span><span class="n">POSITIONAL_OR_KEYWORD</span><span class="p">)]</span> <span class="o">+</span> <span class="n">params</span>
    <span class="n">new_signature</span> <span class="o">=</span> <span class="n">signature</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">parameters</span><span class="o">=</span><span class="n">new_params</span><span class="p">)</span>
    <span class="n">CustomScorer</span><span class="o">.</span><span class="fm">__call__</span><span class="o">.</span><span class="n">__signature__</span> <span class="o">=</span> <span class="n">new_signature</span>

    <span class="k">return</span> <span class="n">CustomScorer</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span> <span class="ow">or</span> <span class="n">func</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
        <span class="n">aggregations</span><span class="o">=</span><span class="n">aggregations</span><span class="p">,</span>
    <span class="p">)</span></div>
</pre></div>

              </div>
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../../',
      VERSION:'3.0.0.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>